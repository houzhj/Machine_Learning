{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fddef8d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import collections\n",
    "from collections import Counter\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2a2f0873",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all = pd.read_csv('surnames_with_splits.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c5e82b8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of the data:  (10980, 4)\n",
      "------------------------------------------------------------\n",
      "  nationality  nationality_index  split   surname\n",
      "0      Arabic                 15  train     Totah\n",
      "1      Arabic                 15  train    Abboud\n",
      "2      Arabic                 15  train  Fakhoury\n",
      "3      Arabic                 15  train     Srour\n",
      "4      Arabic                 15  train    Sayegh\n"
     ]
    }
   ],
   "source": [
    "print(\"shape of the data: \", df_all.shape)\n",
    "print('-'*60)\n",
    "print(df_all.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d804fc58",
   "metadata": {},
   "source": [
    "# 1. Vocabulary class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ebd1f64a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Vocabulary(object):\n",
    "    \n",
    "    def __init__(self, token_to_idx=None, add_unk=True, unk_token=\"<UNK>\"):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            token_to_idx (dict): a pre-existing map of tokens to indices\n",
    "            add_unk (bool): a flag that indicates whether to add the UNK token\n",
    "            unk_token (str): the UNK token to add into the Vocabulary\n",
    "        \"\"\"\n",
    "        if token_to_idx is None:\n",
    "            token_to_idx = {}\n",
    "        self._token_to_idx = token_to_idx\n",
    "        self._idx_to_token = {idx: token \n",
    "                              for token, idx in self._token_to_idx.items()}\n",
    "        \n",
    "        self._add_unk   = add_unk\n",
    "        self._unk_token = unk_token      \n",
    "        self.unk_index  = -999\n",
    "        ### the unk_token, i.e, \"<UNK>\" is the first added token if add_unk=True\n",
    "        ### self.unk_index is changed from -999 to 0\n",
    "        if add_unk:\n",
    "            self.unk_index = self.add_token(unk_token) \n",
    "\n",
    "    def add_token(self, token):\n",
    "        \"\"\"Update mapping dicts based on the token.\n",
    "\n",
    "        Args:\n",
    "            token (str): the item to add into the Vocabulary\n",
    "        Returns:\n",
    "            index (int): the integer corresponding to the token\n",
    "        \"\"\"\n",
    "        if token in self._token_to_idx:\n",
    "            index = self._token_to_idx[token]\n",
    "        else:\n",
    "            index = len(self._token_to_idx)\n",
    "            ### add a new element to _token_to_idx\n",
    "            self._token_to_idx[token] = index\n",
    "            ### add a new element to _idx_to_token\n",
    "            self._idx_to_token[index] = token\n",
    "        return index\n",
    "   \n",
    "    def lookup_token(self, token):\n",
    "        \"\"\"Retrieve the index associated with the token \n",
    "          or the UNK index if token isn't present.\n",
    "        \n",
    "        Args:\n",
    "            token (str): the token to look up \n",
    "        Returns:\n",
    "            index (int): the index corresponding to the token\n",
    "        Notes:\n",
    "            `unk_index` needs to be >=0 (having been added into the Vocabulary) \n",
    "              for the UNK functionality \n",
    "        \"\"\"\n",
    "        if self.unk_index >= 0:\n",
    "            ### .get(): return self.unk_index if the key \"token\" does not exist. \n",
    "            return self._token_to_idx.get(token, self.unk_index)\n",
    "        else:\n",
    "            return self._token_to_idx[token]\n",
    "    \n",
    "    def lookup_index(self, index):\n",
    "        \"\"\"Return the token associated with the index\n",
    "        \n",
    "        Args: \n",
    "            index (int): the index to look up\n",
    "        Returns:\n",
    "            token (str): the token corresponding to the index\n",
    "        Raises:\n",
    "            KeyError: if the index is not in the Vocabulary\n",
    "        \"\"\"\n",
    "        if index not in self._idx_to_token:\n",
    "            raise KeyError(\"the index (%d) is not in the Vocabulary\" % index)\n",
    "        return self._idx_to_token[index]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self._token_to_idx)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41ba2ede",
   "metadata": {},
   "source": [
    "# 2. Instantiate the Vocabulary from the training data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d40957aa",
   "metadata": {},
   "source": [
    "## (1) The vocabulary for the nationality - nationality_vocab"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c270d79f",
   "metadata": {},
   "source": [
    "### The corpus of nationality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "694a8632",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "corpus\n",
      "['Arabic' 'Chinese' 'Czech' 'Dutch' 'English' 'French' 'German' 'Greek'\n",
      " 'Irish' 'Italian' 'Japanese' 'Korean' 'Polish' 'Portuguese' 'Russian'\n",
      " 'Scottish' 'Spanish' 'Vietnamese']\n",
      "--------------------------------------------------------------------------------\n",
      "counts\n",
      "English       2972\n",
      "Russian       2373\n",
      "Arabic        1603\n",
      "Japanese       775\n",
      "Italian        600\n",
      "German         576\n",
      "Czech          414\n",
      "Spanish        258\n",
      "Dutch          236\n",
      "French         229\n",
      "Chinese        220\n",
      "Irish          183\n",
      "Greek          156\n",
      "Polish         120\n",
      "Korean          77\n",
      "Scottish        75\n",
      "Vietnamese      58\n",
      "Portuguese      55\n",
      "Name: nationality, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print('corpus')\n",
    "print(df_all.nationality.unique())\n",
    "print('-'*80)\n",
    "print('counts')\n",
    "print(df_all.nationality.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80367acb",
   "metadata": {},
   "source": [
    "### Initializing nationality_vocab.\n",
    "### The unk_token, i.e,  \"UNK\" (unknown word), is the first added token if add_unk=True. \n",
    "### After the initialization, there is only one token stored in the object - UNK, and the index of this token in nationality_vocab is 0 (changed from -999 to 0). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b322bc24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'_token_to_idx': {'<UNK>': 0},\n",
       " '_idx_to_token': {0: '<UNK>'},\n",
       " '_add_unk': True,\n",
       " '_unk_token': '<UNK>',\n",
       " 'unk_index': 0}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nationality_vocab = Vocabulary(add_unk=True)\n",
    "vars(nationality_vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5446e44",
   "metadata": {},
   "source": [
    "### Add tokens appear in the nationality to nationality_vocab. \n",
    "### There are 18 tokens in the corpus of nationality. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d4b6546b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Arabic',\n",
       " 'Chinese',\n",
       " 'Czech',\n",
       " 'Dutch',\n",
       " 'English',\n",
       " 'French',\n",
       " 'German',\n",
       " 'Greek',\n",
       " 'Irish',\n",
       " 'Italian',\n",
       " 'Japanese',\n",
       " 'Korean',\n",
       " 'Polish',\n",
       " 'Portuguese',\n",
       " 'Russian',\n",
       " 'Scottish',\n",
       " 'Spanish',\n",
       " 'Vietnamese']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(set(df_all.nationality))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f88bea55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'_token_to_idx': {'<UNK>': 0,\n",
       "  'Arabic': 1,\n",
       "  'Chinese': 2,\n",
       "  'Czech': 3,\n",
       "  'Dutch': 4,\n",
       "  'English': 5,\n",
       "  'French': 6,\n",
       "  'German': 7,\n",
       "  'Greek': 8,\n",
       "  'Irish': 9,\n",
       "  'Italian': 10,\n",
       "  'Japanese': 11,\n",
       "  'Korean': 12,\n",
       "  'Polish': 13,\n",
       "  'Portuguese': 14,\n",
       "  'Russian': 15,\n",
       "  'Scottish': 16,\n",
       "  'Spanish': 17,\n",
       "  'Vietnamese': 18},\n",
       " '_idx_to_token': {0: '<UNK>',\n",
       "  1: 'Arabic',\n",
       "  2: 'Chinese',\n",
       "  3: 'Czech',\n",
       "  4: 'Dutch',\n",
       "  5: 'English',\n",
       "  6: 'French',\n",
       "  7: 'German',\n",
       "  8: 'Greek',\n",
       "  9: 'Irish',\n",
       "  10: 'Italian',\n",
       "  11: 'Japanese',\n",
       "  12: 'Korean',\n",
       "  13: 'Polish',\n",
       "  14: 'Portuguese',\n",
       "  15: 'Russian',\n",
       "  16: 'Scottish',\n",
       "  17: 'Spanish',\n",
       "  18: 'Vietnamese'},\n",
       " '_add_unk': True,\n",
       " '_unk_token': '<UNK>',\n",
       " 'unk_index': 0}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nationality_vocab = Vocabulary(add_unk=True)\n",
    "for n in sorted(set(df_all.nationality)):\n",
    "    nationality_vocab.add_token(n)\n",
    "vars(nationality_vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92ef8138",
   "metadata": {},
   "source": [
    "### Another way to add tokens to nationality_vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "85f01a60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'_token_to_idx': {'<UNK>': 0,\n",
       "  'Arabic': 1,\n",
       "  'Chinese': 2,\n",
       "  'Czech': 3,\n",
       "  'Dutch': 4,\n",
       "  'English': 5,\n",
       "  'French': 6,\n",
       "  'German': 7,\n",
       "  'Greek': 8,\n",
       "  'Irish': 9,\n",
       "  'Italian': 10,\n",
       "  'Japanese': 11,\n",
       "  'Korean': 12,\n",
       "  'Polish': 13,\n",
       "  'Portuguese': 14,\n",
       "  'Russian': 15,\n",
       "  'Scottish': 16,\n",
       "  'Spanish': 17,\n",
       "  'Vietnamese': 18},\n",
       " '_idx_to_token': {0: '<UNK>',\n",
       "  1: 'Arabic',\n",
       "  2: 'Chinese',\n",
       "  3: 'Czech',\n",
       "  4: 'Dutch',\n",
       "  5: 'English',\n",
       "  6: 'French',\n",
       "  7: 'German',\n",
       "  8: 'Greek',\n",
       "  9: 'Irish',\n",
       "  10: 'Italian',\n",
       "  11: 'Japanese',\n",
       "  12: 'Korean',\n",
       "  13: 'Polish',\n",
       "  14: 'Portuguese',\n",
       "  15: 'Russian',\n",
       "  16: 'Scottish',\n",
       "  17: 'Spanish',\n",
       "  18: 'Vietnamese'},\n",
       " '_add_unk': True,\n",
       " '_unk_token': '<UNK>',\n",
       " 'unk_index': 0}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nationality_vocab = Vocabulary(add_unk=True)\n",
    "for index, row in df_all.iterrows():\n",
    "    nationality_vocab.add_token(row.nationality)\n",
    "vars(nationality_vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af07dc34",
   "metadata": {},
   "source": [
    "### (2) The vocabulary for the surnames"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80af11a3",
   "metadata": {},
   "source": [
    "### The corpus - the difference between nationality and surname is that in the corpus of nationality, each word is treated as a token, whereas in the corpus of surname, each character is treated as a token.\n",
    "### - Tokens in \"surname_vocab\": 'Arabic', 'Chinese', 'Czech', 'Dutch', 'English', ...\n",
    "### - Tokens in \"nationality_vocab\": 'T', 'a', 't', 'V', ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "42de8ea3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0           Totah\n",
       "1          Abboud\n",
       "2        Fakhoury\n",
       "3           Srour\n",
       "4          Sayegh\n",
       "           ...   \n",
       "10975        Dinh\n",
       "10976       Phung\n",
       "10977       Quang\n",
       "10978          Vu\n",
       "10979          Ha\n",
       "Name: surname, Length: 10980, dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all.surname"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74b45019",
   "metadata": {},
   "source": [
    "### Initializing surname_vocab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8b6a7413",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'_token_to_idx': {'<UNK>': 0},\n",
       " '_idx_to_token': {0: '<UNK>'},\n",
       " '_add_unk': True,\n",
       " '_unk_token': '<UNK>',\n",
       " 'unk_index': 0}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "surname_vocab = Vocabulary(add_unk=True)\n",
    "vars(surname_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "adb3e839",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of tokens in \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "85"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for index, row in df_all.iterrows():\n",
    "    for letter in row.surname:\n",
    "        surname_vocab.add_token(letter)\n",
    "print('The number of tokens in ')\n",
    "len(surname_vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93527692",
   "metadata": {},
   "source": [
    "# 3. Attributes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0537983",
   "metadata": {},
   "source": [
    "### ._token_to_idx: a mapping of index and token added to the Vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "39830ded",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Print out 20 tokens in the vocabulary\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('<UNK>', 0),\n",
       " ('T', 1),\n",
       " ('o', 2),\n",
       " ('t', 3),\n",
       " ('a', 4),\n",
       " ('h', 5),\n",
       " ('A', 6),\n",
       " ('b', 7),\n",
       " ('u', 8),\n",
       " ('d', 9),\n",
       " ('F', 10),\n",
       " ('k', 11),\n",
       " ('r', 12),\n",
       " ('y', 13),\n",
       " ('S', 14),\n",
       " ('e', 15),\n",
       " ('g', 16),\n",
       " ('C', 17),\n",
       " ('m', 18),\n",
       " ('H', 19)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Print out 20 tokens in the vocabulary\")\n",
    "list(surname_vocab._token_to_idx.items())[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7417ec4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Print a few elements in surname_vocab._token_to_idx\n",
      "The index for \"a\" is 4\n",
      "The index for \"b\" is 7\n",
      "The index for \"c\" is 40\n",
      "The index for \"A\" is 6\n",
      "The index for \"B\" is 29\n",
      "The index for \"C\" is 17\n"
     ]
    }
   ],
   "source": [
    "tokens  = ['a','b','c','A','B','C']\n",
    "mapping = surname_vocab._token_to_idx\n",
    "print(\"Print a few elements in surname_vocab._token_to_idx\")\n",
    "for i in tokens:\n",
    "    print(f'The index for \"{i}\" is {mapping.get(i,0)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db5ad486",
   "metadata": {},
   "source": [
    "### ._idx_to_token: a mapping of index and token added to the Vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "64b0569c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Print out 20 tokens in the vocabulary\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(0, '<UNK>'),\n",
       " (1, 'T'),\n",
       " (2, 'o'),\n",
       " (3, 't'),\n",
       " (4, 'a'),\n",
       " (5, 'h'),\n",
       " (6, 'A'),\n",
       " (7, 'b'),\n",
       " (8, 'u'),\n",
       " (9, 'd'),\n",
       " (10, 'F'),\n",
       " (11, 'k'),\n",
       " (12, 'r'),\n",
       " (13, 'y'),\n",
       " (14, 'S'),\n",
       " (15, 'e'),\n",
       " (16, 'g'),\n",
       " (17, 'C'),\n",
       " (18, 'm'),\n",
       " (19, 'H')]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Print out 20 tokens in the vocabulary\")\n",
    "list(surname_vocab._idx_to_token.items())[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c97b0252",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Print a few elements in surname_vocab._idx_to_token\n",
      "The token for index=0 is <UNK>\n",
      "The token for index=2 is o\n",
      "The token for index=6 is A\n",
      "The token for index=100 is 0\n"
     ]
    }
   ],
   "source": [
    "indices  = [0,2,6,100]\n",
    "mapping = surname_vocab._idx_to_token\n",
    "print(\"Print a few elements in surname_vocab._idx_to_token\")\n",
    "for i in indices:\n",
    "    print(f'The token for index={i} is {mapping.get(i,0)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c66cef5",
   "metadata": {},
   "source": [
    "# 4. Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f5cdc72",
   "metadata": {},
   "source": [
    "### add_token(token): Update mapping dicts based on the token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "40e60fe5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'_token_to_idx': {'<UNK>': 0},\n",
       " '_idx_to_token': {0: '<UNK>'},\n",
       " '_add_unk': True,\n",
       " '_unk_token': '<UNK>',\n",
       " 'unk_index': 0}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_vocab = Vocabulary(add_unk=True)\n",
    "vars(example_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "176db67a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Add one token apple\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'_token_to_idx': {'<UNK>': 0, 'apple': 1},\n",
       " '_idx_to_token': {0: '<UNK>', 1: 'apple'},\n",
       " '_add_unk': True,\n",
       " '_unk_token': '<UNK>',\n",
       " 'unk_index': 0}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_token = 'apple'\n",
    "example_vocab.add_token(new_token)\n",
    "print(f\"Add one token {new_token}\")\n",
    "print('-'*60)\n",
    "vars(example_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c1ce9533",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Add one token banana\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'_token_to_idx': {'<UNK>': 0, 'apple': 1, 'banana': 2},\n",
       " '_idx_to_token': {0: '<UNK>', 1: 'apple', 2: 'banana'},\n",
       " '_add_unk': True,\n",
       " '_unk_token': '<UNK>',\n",
       " 'unk_index': 0}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_token = 'banana'\n",
    "example_vocab.add_token(new_token)\n",
    "print(f\"Add one token {new_token}\")\n",
    "print('-'*60)\n",
    "vars(example_vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbec5871",
   "metadata": {},
   "source": [
    "### lookup_token(token): Retrieve the index associated with the token or the UNK index if token isn't present."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d1b5cb1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'_token_to_idx': {'<UNK>': 0},\n",
       " '_idx_to_token': {0: '<UNK>'},\n",
       " '_add_unk': True,\n",
       " '_unk_token': '<UNK>',\n",
       " 'unk_index': 0}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_vocab = Vocabulary(add_unk=True)\n",
    "vars(example_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7fe5e79a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "apple added\n",
      "banana added\n",
      "peach added\n",
      "orange added\n",
      "coconut added\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'_token_to_idx': {'<UNK>': 0,\n",
       "  'apple': 1,\n",
       "  'banana': 2,\n",
       "  'peach': 3,\n",
       "  'orange': 4,\n",
       "  'coconut': 5},\n",
       " '_idx_to_token': {0: '<UNK>',\n",
       "  1: 'apple',\n",
       "  2: 'banana',\n",
       "  3: 'peach',\n",
       "  4: 'orange',\n",
       "  5: 'coconut'},\n",
       " '_add_unk': True,\n",
       " '_unk_token': '<UNK>',\n",
       " 'unk_index': 0}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens_to_add = ['apple','banana','peach','orange','coconut']\n",
    "for i in tokens_to_add:\n",
    "    example_vocab.add_token(i)\n",
    "    print(i + ' added')\n",
    "vars(example_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7634d002",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The index for orange is 4\n",
      "The index for rice is 0\n"
     ]
    }
   ],
   "source": [
    "tokens_list = ['orange','rice']\n",
    "for i in tokens_list:\n",
    "    print(f\"The index for {i} is {example_vocab.lookup_token(i)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4d2166ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The index for orange is 4\n",
      "The index for rice is 0\n"
     ]
    }
   ],
   "source": [
    "### Equivalent codes\n",
    "for i in tokens_list:\n",
    "    print(f\"The index for {i} is {Vocabulary.lookup_token(example_vocab,i)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13f5e2f7",
   "metadata": {},
   "source": [
    "### lookup_index(index): Return the token associated with the index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fc06f521",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The token with index=1 is apple\n",
      "The token with index=4 is orange\n"
     ]
    }
   ],
   "source": [
    "indices_list = [1,4]\n",
    "for i in indices_list:\n",
    "    print(f\"The token with index={i} is {example_vocab.lookup_index(i)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9b8800d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The token with index=1 is apple\n",
      "The token with index=4 is orange\n"
     ]
    }
   ],
   "source": [
    "### Equivalent codes\n",
    "for i in indices_list:\n",
    "    print(f\"The token with index={i} is {Vocabulary.lookup_index(example_vocab,i)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28a1a705",
   "metadata": {},
   "source": [
    "### \\_\\_len\\_\\_(): Return the length of _token_to_idx (i.e, the number of tokens in the vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "84349006",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: '<UNK>', 1: 'token1', 2: 'token2', 3: 'token3', 4: 'token4'}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_vocab = Vocabulary(add_unk=True)\n",
    "tokens_to_add = ['token1','token2','token3','token4']\n",
    "for i in tokens_to_add:\n",
    "    example_vocab.add_token(i)\n",
    "example_vocab._idx_to_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "af5eee36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(example_vocab)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
