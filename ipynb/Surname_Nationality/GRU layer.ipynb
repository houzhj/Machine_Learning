{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "24c9b0e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm_notebook\n",
    "\n",
    "from argparse import Namespace\n",
    "import os\n",
    "import collections\n",
    "from collections import Counter\n",
    "\n",
    "import string\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48939c32",
   "metadata": {},
   "source": [
    "### Save parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bc44a650",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_torch_to_csv(torch_data,filename):\n",
    "    pd.DataFrame(torch_data.detach().numpy()).to_csv(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7776072",
   "metadata": {},
   "source": [
    "### Set random seeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e8316180",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seed: 42\n"
     ]
    }
   ],
   "source": [
    "def seed_everything(seed):\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    print(f\"seed: {seed}\")\n",
    "    \n",
    "seed_everything(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f265065f",
   "metadata": {},
   "source": [
    "# 1. SurnameGenerationModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c85753d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SurnameGenerationModel(nn.Module):\n",
    "    \n",
    "    def __init__(self, \n",
    "                 embedding_dim, \n",
    "                 num_embeddings,\n",
    "                 rnn_hidden_size, \n",
    "                 batch_first = True, \n",
    "                 padding_idx = 0,\n",
    "                 dropout_p   = 0.5\n",
    "                ):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            For embedding\n",
    "            embedding_dim (int)  : The size of the character embeddings\n",
    "            num_embeddings (int) : The number of characters to embed\n",
    "                                   len(surname_vocab)\n",
    "            padding_idx (int)    : The index for the tensor padding\n",
    "            \n",
    "            For RNN\n",
    "            rnn_hidden_size (int): The size of the RNN's hidden state\n",
    "            batch_first (bool)   : Informs whether the input tensors will \n",
    "                                   have batch or the sequence on the 0th dimension\n",
    "            For dropout\n",
    "            dropout_p (float)    : The probability of zeroing activations using \n",
    "                                   the dropout method. Higher means more likely to zero.\n",
    "            \n",
    "        \"\"\"\n",
    "        super(SurnameGenerationModel, self).__init__()\n",
    "\n",
    "        self.emb = nn.Embedding(num_embeddings = num_embeddings,\n",
    "                                embedding_dim  = embedding_dim,\n",
    "                                padding_idx    = padding_idx)\n",
    "        self.rnn = nn.GRU(input_size   = embedding_dim,\n",
    "                          hidden_size  = rnn_hidden_size,\n",
    "                          batch_first  = batch_first)\n",
    "        self.fc  = nn.Linear(in_features  = rnn_hidden_size,\n",
    "                             out_features = num_embeddings)\n",
    "        \n",
    "    def forward(self, x_in, apply_softmax=False):\n",
    "        \"\"\"The forward pass of the model\n",
    "        \n",
    "        Args:\n",
    "            x_in (torch.Tensor): an input data tensor. \n",
    "                x_in.shape should be (batch, input_dim)\n",
    "            apply_softmax (bool): a flag for the softmax activation\n",
    "                should be false if used with the Cross Entropy losses\n",
    "        Returns:\n",
    "            the resulting tensor. tensor.shape should be (batch, num_embeddings)\n",
    "        \"\"\"\n",
    "        x_embedded = self.emb(x_in)\n",
    "        y_out = self.rnn(x_embedded)\n",
    "\n",
    "        batch_size, seq_size, feat_size = y_out.shape\n",
    "        y_out = y_out.contiguous().view(batch_size * seq_size, feat_size)\n",
    "\n",
    "        y_out = self.fc(F.dropout(y_out, p=self._dropout_p))\n",
    "                         \n",
    "        if apply_softmax:\n",
    "            y_out = F.softmax(y_out, dim=1)\n",
    "            \n",
    "        new_feat_size = y_out.shape[-1]\n",
    "        y_out = y_out.view(batch_size, seq_size, new_feat_size)\n",
    "            \n",
    "        return y_out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fa2b766",
   "metadata": {},
   "source": [
    "# 2. The Embedding layer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5b70b26",
   "metadata": {},
   "source": [
    "### The x input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0d0fccb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seed: 42\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ 2,  7, 16, 14,  6, 15,  0],\n",
       "        [ 4, 10, 13, 18, 14, 10, 14]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seed_everything(42)\n",
    "batch_size     = 2\n",
    "length_of_text = 7\n",
    "my_input = torch.randint(0,20,[batch_size, length_of_text])\n",
    "my_input"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6ea7c23",
   "metadata": {},
   "source": [
    "### The nn.Embedding layer\n",
    "#### More details [Embedding](https://github.com/houzhj/Machine_Learning/blob/main/ipynb/Frankenstein/Embedding_layer.ipynb), [Embedding+CNN](https://github.com/houzhj/Machine_Learning/blob/main/ipynb/AGNews/NewsClassifier.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cd2e0dbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the number of embeddings (the number of vocabulary items)\n",
    "n_tokens_in_vocabulary = 20\n",
    "# size of the embeddings (embedding dimension)\n",
    "dimension_embedding    = 4\n",
    "# If one specifies padding_idx=0 every input where the value is equal to padding_idx will \n",
    "# be zero-ed out \n",
    "padding_idx            = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dff47bd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seed: 42\n"
     ]
    }
   ],
   "source": [
    "seed_everything(42)\n",
    "my_emb = nn.Embedding(num_embeddings = n_tokens_in_vocabulary, \n",
    "                      embedding_dim  = dimension_embedding,\n",
    "                      padding_idx    = padding_idx)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "14491314",
   "metadata": {},
   "outputs": [],
   "source": [
    "### The output of the nn.Embedding layer (i.e.,the input of the RNNCell layer)\n",
    "x_in = my_emb(my_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9f037d78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For the nn.Embedding Layer\n",
      "Shape of input:  torch.Size([2, 7])\n",
      "Shape of output:  torch.Size([2, 7, 4])\n",
      "torch.Size([2, 7, 4])\n",
      "------------------------------------------------------------\n",
      "x_in, the input to the next step\n",
      "tensor([[[-0.7521,  1.6487, -0.3925, -1.4036],\n",
      "         [-0.2316,  0.0418, -0.2516,  0.8599],\n",
      "         [ 1.4451,  0.8564,  2.2181,  0.5232],\n",
      "         [-1.4032,  0.0360, -0.0635,  0.6756],\n",
      "         [ 1.2791,  1.2964,  0.6105,  1.3347],\n",
      "         [-0.0978,  1.8446, -1.1845,  1.3835],\n",
      "         [ 0.0000,  0.0000,  0.0000,  0.0000]],\n",
      "\n",
      "        [[ 1.6423, -0.1596, -0.4974,  0.4396],\n",
      "         [-1.5576,  0.9956, -0.8798, -0.6011],\n",
      "         [-0.4880,  1.1914, -0.8140, -0.7360],\n",
      "         [-0.1722,  0.5238,  0.0566,  0.4263],\n",
      "         [-1.4032,  0.0360, -0.0635,  0.6756],\n",
      "         [-1.5576,  0.9956, -0.8798, -0.6011],\n",
      "         [-1.4032,  0.0360, -0.0635,  0.6756]]], grad_fn=<EmbeddingBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(\"For the nn.Embedding Layer\")\n",
    "print(\"Shape of input: \", my_input.shape)\n",
    "print(\"Shape of output: \", x_in.shape)\n",
    "print(x_in.shape)\n",
    "print(\"-\"*60)\n",
    "print(\"x_in, the input to the next step\")\n",
    "print(x_in)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a2972dc",
   "metadata": {},
   "source": [
    "# 3.  The GRU layer\n",
    "## [torch.nn.GRU](https://pytorch.org/docs/stable/generated/torch.nn.GRU.html)\n",
    "### AS shown above, the output of the emdedding layer is a tensor with dimension = [2,7,4]. \n",
    "### In this context, the three dimensions could be \n",
    "- batch_first = True: [batch_size, sequence_size, feature_size]\n",
    "- batch_first = False: [sequence_size, batch_size, feature_size]\n",
    "\n",
    "###  The meaning of the three sizes are below:\n",
    "#### - sequence_size: The length of the sequence, representing the number of time steps in the input sequence. In NLP, this typically corresponds to the number of words (or other basic units) in the input sentence or document. Each time step usually represents one word (or word vector). In this case, sequence_size = 7, meaning that there are seven words in each sentence input, or there are seven characters in each word input. \n",
    "#### - batch_size: The size of the batch, indicating the number of samples processed simultaneously during a single training or inference process. A larger batch size can utilize parallel computation to improve efficiency. In NLP, batch size often corresponds to processing multiple sentences or documents in a single input. In this case, batch_size = 2, meaning that there are 2 sentence inputs, or 2 word inputs. \n",
    "#### feature_size: The input dimension, representing the number of input features at each time step. In NLP, this typically corresponds to the dimensionality of word embeddings. For example, if each word is represented using 300-dimensional word vectors, then the input_size would be 300. In this case, feature_size = 4, meaning that the embedding dimension is 4, and each word in a sentence of each character in a word is represented by a vector of legnth 4. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d70f180b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of x_in(output of the embedding layer): torch.Size([2, 7, 4])\n",
      "batch_size: 2\n",
      "seq_size: 7\n",
      "feat_size: 4\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape of x_in(output of the embedding layer):\", x_in.size())\n",
    "batch_size, seq_size, feat_size = x_in.size()\n",
    "print(\"batch_size:\", batch_size)\n",
    "print(\"seq_size:\", seq_size)\n",
    "print(\"feat_size:\", feat_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "eac59f0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note that batch_first=False, i.e, the first dimension is the batch_size=2\n",
      "Shape: torch.Size([2, 7, 4])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.7521,  1.6487, -0.3925, -1.4036],\n",
       "         [-0.2316,  0.0418, -0.2516,  0.8599],\n",
       "         [ 1.4451,  0.8564,  2.2181,  0.5232],\n",
       "         [-1.4032,  0.0360, -0.0635,  0.6756],\n",
       "         [ 1.2791,  1.2964,  0.6105,  1.3347],\n",
       "         [-0.0978,  1.8446, -1.1845,  1.3835],\n",
       "         [ 0.0000,  0.0000,  0.0000,  0.0000]],\n",
       "\n",
       "        [[ 1.6423, -0.1596, -0.4974,  0.4396],\n",
       "         [-1.5576,  0.9956, -0.8798, -0.6011],\n",
       "         [-0.4880,  1.1914, -0.8140, -0.7360],\n",
       "         [-0.1722,  0.5238,  0.0566,  0.4263],\n",
       "         [-1.4032,  0.0360, -0.0635,  0.6756],\n",
       "         [-1.5576,  0.9956, -0.8798, -0.6011],\n",
       "         [-1.4032,  0.0360, -0.0635,  0.6756]]], grad_fn=<EmbeddingBackward0>)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Note that batch_first=False, i.e, the first dimension is the batch_size=2\")\n",
    "print(\"Shape:\", x_in.shape)\n",
    "x_in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c9808cfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seed: 42\n"
     ]
    }
   ],
   "source": [
    "rnn_hidden_size = 3\n",
    "seed_everything(42)\n",
    "my_GRU = nn.GRU(input_size   = dimension_embedding,\n",
    "                hidden_size  = rnn_hidden_size,\n",
    "                batch_first  = True)\n",
    "\n",
    "W_i  = list(my_GRU.named_parameters())[0]\n",
    "W_ir = W_i[1][0:3,]\n",
    "W_iz = W_i[1][3:6,]\n",
    "W_in = W_i[1][6:9,]\n",
    "\n",
    "W_h  = list(my_GRU.named_parameters())[1]\n",
    "W_hr = W_h[1][0:3,]\n",
    "W_hz = W_h[1][3:6,]\n",
    "W_hn = W_h[1][6:9,]\n",
    "\n",
    "\n",
    "b_i  = list(my_GRU.named_parameters())[2]\n",
    "b_ir = b_i[1][0:3,]\n",
    "b_iz = b_i[1][3:6,]\n",
    "b_in = b_i[1][6:9,]\n",
    "\n",
    "b_h  = list(my_GRU.named_parameters())[3]\n",
    "b_hr = b_h[1][0:3,]\n",
    "b_hz = b_h[1][3:6,]\n",
    "b_hn = b_h[1][6:9,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6077ba9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0., 0., 0.],\n",
       "         [0., 0., 0.]]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "initial_hidden = torch.zeros((1, batch_size, rnn_hidden_size))\n",
    "initial_hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "82aed897",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.1172,  0.1572, -0.2561],\n",
       "         [-0.1366,  0.2296,  0.0123],\n",
       "         [-0.2915,  0.6269,  0.2816],\n",
       "         [ 0.0353,  0.4332,  0.0559],\n",
       "         [-0.2430,  0.1105,  0.4706],\n",
       "         [-0.4794, -0.5260,  0.5597],\n",
       "         [-0.3822,  0.2125,  0.4188]],\n",
       "\n",
       "        [[-0.2737,  0.1863,  0.4307],\n",
       "         [ 0.2448, -0.0473,  0.0761],\n",
       "         [ 0.1612, -0.0539,  0.0057],\n",
       "         [-0.1260,  0.1383,  0.1138],\n",
       "         [ 0.0743,  0.2793, -0.0166],\n",
       "         [ 0.3817,  0.0793, -0.2301],\n",
       "         [ 0.2545,  0.2858, -0.2370]]], grad_fn=<TransposeBackward1>)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output, h_final = my_GRU(x_in,initial_hidden)\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f7bb49ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time Step  0\n",
      "r(reset)\n",
      "tensor([[0.5308, 0.4066, 0.1069],\n",
      "        [0.7868, 0.4410, 0.5021]], grad_fn=<SqueezeBackward1>)\n",
      "z(update)\n",
      "tensor([[0.4602, 0.2640, 0.3852],\n",
      "        [0.6320, 0.5462, 0.4374]], grad_fn=<SqueezeBackward1>)\n",
      "n(new gates)\n",
      "tensor([[ 0.2171,  0.2136, -0.4165],\n",
      "        [-0.7439,  0.4107,  0.7655]], grad_fn=<SqueezeBackward1>)\n",
      "h(hidden state)\n",
      "tensor([[ 0.1172,  0.1572, -0.2561],\n",
      "        [-0.2737,  0.1863,  0.4307]], grad_fn=<SqueezeBackward1>)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Time Step  1\n",
      "r(reset)\n",
      "tensor([[0.6968, 0.5349, 0.3020],\n",
      "        [0.5090, 0.5171, 0.0962]], grad_fn=<SqueezeBackward1>)\n",
      "z(update)\n",
      "tensor([[0.4472, 0.3751, 0.5298],\n",
      "        [0.3590, 0.1705, 0.5975]], grad_fn=<SqueezeBackward1>)\n",
      "n(new gates)\n",
      "tensor([[-0.3418,  0.2731,  0.3148],\n",
      "        [ 0.5352, -0.0953, -0.4503]], grad_fn=<SqueezeBackward1>)\n",
      "h(hidden state)\n",
      "tensor([[-0.1366,  0.2296,  0.0123],\n",
      "        [ 0.2448, -0.0473,  0.0761]], grad_fn=<SqueezeBackward1>)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Time Step  2\n",
      "r(reset)\n",
      "tensor([[0.8143, 0.3165, 0.7188],\n",
      "        [0.6075, 0.4542, 0.1331]], grad_fn=<SqueezeBackward1>)\n",
      "z(update)\n",
      "tensor([[0.8018, 0.3401, 0.2813],\n",
      "        [0.4197, 0.3340, 0.4626]], grad_fn=<SqueezeBackward1>)\n",
      "n(new gates)\n",
      "tensor([[-0.9182,  0.8315,  0.3870],\n",
      "        [ 0.1007, -0.0572, -0.0548]], grad_fn=<SqueezeBackward1>)\n",
      "h(hidden state)\n",
      "tensor([[-0.2915,  0.6269,  0.2816],\n",
      "        [ 0.1612, -0.0539,  0.0057]], grad_fn=<SqueezeBackward1>)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Time Step  3\n",
      "r(reset)\n",
      "tensor([[0.6000, 0.5586, 0.2621],\n",
      "        [0.6770, 0.4684, 0.2861]], grad_fn=<SqueezeBackward1>)\n",
      "z(update)\n",
      "tensor([[0.4183, 0.1541, 0.6118],\n",
      "        [0.4794, 0.3425, 0.5101]], grad_fn=<SqueezeBackward1>)\n",
      "n(new gates)\n",
      "tensor([[ 0.2703,  0.3979, -0.2997],\n",
      "        [-0.3905,  0.2384,  0.2262]], grad_fn=<SqueezeBackward1>)\n",
      "h(hidden state)\n",
      "tensor([[ 0.0353,  0.4332,  0.0559],\n",
      "        [-0.1260,  0.1383,  0.1138]], grad_fn=<SqueezeBackward1>)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Time Step  4\n",
      "r(reset)\n",
      "tensor([[0.9150, 0.5057, 0.5275],\n",
      "        [0.5453, 0.5388, 0.2137]], grad_fn=<SqueezeBackward1>)\n",
      "z(update)\n",
      "tensor([[0.7061, 0.4519, 0.4149],\n",
      "        [0.3655, 0.2000, 0.6352]], grad_fn=<SqueezeBackward1>)\n",
      "n(new gates)\n",
      "tensor([[-0.9115, -0.1555,  0.7647],\n",
      "        [ 0.1897,  0.3145, -0.2437]], grad_fn=<SqueezeBackward1>)\n",
      "h(hidden state)\n",
      "tensor([[-0.2430,  0.1105,  0.4706],\n",
      "        [ 0.0743,  0.2793, -0.0166]], grad_fn=<SqueezeBackward1>)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Time Step  5\n",
      "r(reset)\n",
      "tensor([[0.8958, 0.6721, 0.1402],\n",
      "        [0.5206, 0.5223, 0.0947]], grad_fn=<SqueezeBackward1>)\n",
      "z(update)\n",
      "tensor([[0.4586, 0.3839, 0.6956],\n",
      "        [0.3357, 0.2215, 0.5161]], grad_fn=<SqueezeBackward1>)\n",
      "n(new gates)\n",
      "tensor([[-0.6796, -0.9226,  0.7634],\n",
      "        [ 0.5370,  0.0224, -0.4577]], grad_fn=<SqueezeBackward1>)\n",
      "h(hidden state)\n",
      "tensor([[-0.4794, -0.5260,  0.5597],\n",
      "        [ 0.3817,  0.0793, -0.2301]], grad_fn=<SqueezeBackward1>)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Time Step  6\n",
      "r(reset)\n",
      "tensor([[0.5259, 0.4058, 0.2903],\n",
      "        [0.5445, 0.5269, 0.2101]], grad_fn=<SqueezeBackward1>)\n",
      "z(update)\n",
      "tensor([[0.5077, 0.2678, 0.6212],\n",
      "        [0.3241, 0.2650, 0.5756]], grad_fn=<SqueezeBackward1>)\n",
      "n(new gates)\n",
      "tensor([[-0.2821,  0.4826,  0.1876],\n",
      "        [ 0.1935,  0.3603, -0.2464]], grad_fn=<SqueezeBackward1>)\n",
      "h(hidden state)\n",
      "tensor([[-0.3822,  0.2125,  0.4188],\n",
      "        [ 0.2545,  0.2858, -0.2370]], grad_fn=<SqueezeBackward1>)\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "mannual_output = []\n",
    "\n",
    "h = initial_hidden\n",
    "for t in range(seq_size):\n",
    "    x_t = x_in[:,t,:]\n",
    "    print(\"Time Step \", t)\n",
    "    print(\"r(reset)\")\n",
    "    r = torch.sigmoid(torch.matmul(x_t, W_ir.T)+b_ir+torch.matmul(h, W_hr.T)+b_hr).squeeze(0)\n",
    "    print(r)\n",
    "    print(\"z(update)\")\n",
    "    z = torch.sigmoid(torch.matmul(x_t, W_iz.T)+b_iz + torch.matmul(h, W_hz.T)+b_hz).squeeze(0)\n",
    "    print(z)\n",
    "    print(\"n(new gates)\")\n",
    "    n = (torch.matmul(h, W_hn.T)+b_hn)*r+torch.matmul(x_t, W_in.T)+b_in\n",
    "    n = torch.tanh(n).squeeze(0)\n",
    "    print(n)\n",
    "    print(\"h(hidden state)\")\n",
    "    h = (1-z)*n+z*h\n",
    "    h = h.squeeze(0)\n",
    "    print(h)\n",
    "    mannual_output.append(h)\n",
    "    print(\"-\"*100)\n",
    "\n",
    "mannual_h_final = h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9cbdcbd3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.1172,  0.1572, -0.2561],\n",
       "         [-0.1366,  0.2296,  0.0123],\n",
       "         [-0.2915,  0.6269,  0.2816],\n",
       "         [ 0.0353,  0.4332,  0.0559],\n",
       "         [-0.2430,  0.1105,  0.4706],\n",
       "         [-0.4794, -0.5260,  0.5597],\n",
       "         [-0.3822,  0.2125,  0.4188]],\n",
       "\n",
       "        [[-0.2737,  0.1863,  0.4307],\n",
       "         [ 0.2448, -0.0473,  0.0761],\n",
       "         [ 0.1612, -0.0539,  0.0057],\n",
       "         [-0.1260,  0.1383,  0.1138],\n",
       "         [ 0.0743,  0.2793, -0.0166],\n",
       "         [ 0.3817,  0.0793, -0.2301],\n",
       "         [ 0.2545,  0.2858, -0.2370]]], grad_fn=<PermuteBackward0>)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mannual_output = torch.stack(mannual_output).permute(1,0,2)\n",
    "mannual_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "786e5cca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.1172,  0.1572, -0.2561],\n",
       "         [-0.1366,  0.2296,  0.0123],\n",
       "         [-0.2915,  0.6269,  0.2816],\n",
       "         [ 0.0353,  0.4332,  0.0559],\n",
       "         [-0.2430,  0.1105,  0.4706],\n",
       "         [-0.4794, -0.5260,  0.5597],\n",
       "         [-0.3822,  0.2125,  0.4188]],\n",
       "\n",
       "        [[-0.2737,  0.1863,  0.4307],\n",
       "         [ 0.2448, -0.0473,  0.0761],\n",
       "         [ 0.1612, -0.0539,  0.0057],\n",
       "         [-0.1260,  0.1383,  0.1138],\n",
       "         [ 0.0743,  0.2793, -0.0166],\n",
       "         [ 0.3817,  0.0793, -0.2301],\n",
       "         [ 0.2545,  0.2858, -0.2370]]], grad_fn=<TransposeBackward1>)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "91cc3380",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.3822,  0.2125,  0.4188],\n",
       "        [ 0.2545,  0.2858, -0.2370]], grad_fn=<SqueezeBackward1>)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mannual_h_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "be63f2fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.3822,  0.2125,  0.4188],\n",
       "         [ 0.2545,  0.2858, -0.2370]]], grad_fn=<StackBackward0>)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h_final"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
