{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1e9e6e31",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import collections\n",
    "from collections import Counter\n",
    "import string\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "50d09f9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all = pd.read_csv(\"reviews_with_splits_lite.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "52785cb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of the data:  (56000, 3)\n",
      "------------------------------------------------------------\n",
      "     rating                                             review  split\n",
      "0  negative  terrible place to work for i just heard a stor...  train\n",
      "1  negative   hours , minutes total time for an extremely s...  train\n",
      "2  negative  my less than stellar review is for service . w...  train\n",
      "3  negative  i m granting one star because there s no way t...  train\n",
      "4  negative  the food here is mediocre at best . i went aft...  train\n"
     ]
    }
   ],
   "source": [
    "print(\"shape of the data: \", df_all.shape)\n",
    "print('-'*60)\n",
    "print(df_all.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "afde8402",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Vocabulary(object):\n",
    "    \"\"\"Class to process text and extract vocabulary for mapping\"\"\"\n",
    "    def __init__(self, token_to_idx=None, add_unk=True, unk_token=\"<UNK>\"):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            token_to_idx (dict): a pre-existing map of tokens to indices\n",
    "            add_unk (bool): a flag that indicates whether to add the UNK token\n",
    "            unk_token (str): the UNK token to add into the Vocabulary\n",
    "        \"\"\"\n",
    "        if token_to_idx is None:\n",
    "            token_to_idx = {}\n",
    "        self._token_to_idx = token_to_idx\n",
    "        self._idx_to_token = {idx: token \n",
    "                              for token, idx in self._token_to_idx.items()}\n",
    "        \n",
    "        self._add_unk   = add_unk\n",
    "        self._unk_token = unk_token      \n",
    "        self.unk_index  = -999\n",
    "        ### the unk_token, i.e, \"<UNK>\" is the first added token if add_unk=True\n",
    "        ### self.unk_index is changed from -999 to 0\n",
    "        if add_unk:\n",
    "            self.unk_index = self.add_token(unk_token) \n",
    "\n",
    "    def add_token(self, token):\n",
    "        \"\"\"Update mapping dicts based on the token.\n",
    "\n",
    "        Args:\n",
    "            token (str): the item to add into the Vocabulary\n",
    "        Returns:\n",
    "            index (int): the integer corresponding to the token\n",
    "        \"\"\"\n",
    "        if token in self._token_to_idx:\n",
    "            index = self._token_to_idx[token]\n",
    "        else:\n",
    "            index = len(self._token_to_idx)\n",
    "            ### add a new element to _token_to_idx\n",
    "            self._token_to_idx[token] = index\n",
    "            ### add a new element to _idx_to_token\n",
    "            self._idx_to_token[index] = token\n",
    "        return index\n",
    "   \n",
    "    def lookup_token(self, token):\n",
    "        \"\"\"Retrieve the index associated with the token \n",
    "          or the UNK index if token isn't present.\n",
    "        \n",
    "        Args:\n",
    "            token (str): the token to look up \n",
    "        Returns:\n",
    "            index (int): the index corresponding to the token\n",
    "        Notes:\n",
    "            `unk_index` needs to be >=0 (having been added into the Vocabulary) \n",
    "              for the UNK functionality \n",
    "        \"\"\"\n",
    "        if self.unk_index >= 0:\n",
    "            ### .get(): return self.unk_index if the key \"token\" does not exist. \n",
    "            return self._token_to_idx.get(token, self.unk_index)\n",
    "        else:\n",
    "            return self._token_to_idx[token]\n",
    "    \n",
    "    def lookup_index(self, index):\n",
    "        \"\"\"Return the token associated with the index\n",
    "        \n",
    "        Args: \n",
    "            index (int): the index to look up\n",
    "        Returns:\n",
    "            token (str): the token corresponding to the index\n",
    "        Raises:\n",
    "            KeyError: if the index is not in the Vocabulary\n",
    "        \"\"\"\n",
    "        if index not in self._idx_to_token:\n",
    "            raise KeyError(\"the index (%d) is not in the Vocabulary\" % index)\n",
    "        return self._idx_to_token[index]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self._token_to_idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fbdb2b7",
   "metadata": {},
   "source": [
    "# 1. ReviewVectorizer class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7e2aadac",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReviewVectorizer(object):\n",
    "    \"\"\" The Vectorizer which coordinates the Vocabularies and puts them to use\"\"\"\n",
    "    def __init__(self, review_vocab, rating_vocab):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            review_vocab (Vocabulary): maps words to integers\n",
    "            rating_vocab (Vocabulary): maps class labels to integers\n",
    "        \"\"\"\n",
    "        self.review_vocab = review_vocab\n",
    "        self.rating_vocab = rating_vocab\n",
    "         \n",
    "    @classmethod\n",
    "    def from_dataframe(cls, review_df, cutoff):\n",
    "        \"\"\"Instantiate the vectorizer from the dataset dataframe\n",
    "        \n",
    "        Args:\n",
    "            review_df (pandas.DataFrame): the review dataset\n",
    "            cutoff (int): the parameter for frequency-based filtering\n",
    "        Returns:\n",
    "            an instance of the ReviewVectorizer\n",
    "        \"\"\"\n",
    "        review_vocab = Vocabulary(add_unk=True)\n",
    "        rating_vocab = Vocabulary(add_unk=False)\n",
    "        \n",
    "        ########## Add tokens to rating_vocab ('positive' and 'negative')\n",
    "        for rating in sorted(set(review_df.rating)):\n",
    "            rating_vocab.add_token(rating)\n",
    "            \n",
    "        ########## Add tokens to review_vocab\n",
    "        ### Create a Counter() to count all tokens appears in review_df.review\n",
    "        word_counts = Counter()\n",
    "        for review in review_df.review:\n",
    "            for word in review.split(\" \"):\n",
    "                if word not in string.punctuation:\n",
    "                    word_counts[word] += 1\n",
    "        ### execute add_token if a word appears more than \"cutoff\" times\n",
    "        for word, count in word_counts.items():\n",
    "            if count > cutoff:\n",
    "                review_vocab.add_token(word)\n",
    "        return cls(review_vocab, rating_vocab)\n",
    "\n",
    "    ### This is the key functionality of the Vectorizer.\n",
    "    ### It takes as an argument a string representing a review,\n",
    "    ### and returns a vectorized representation of the review.\n",
    "    def vectorize(self, review):\n",
    "        \"\"\"\n",
    "        Create a collapsed one-hot representation vector for the review\n",
    "        Limitations of the one-hot method:\n",
    "        1 - Sparseness, n_unique_words in a review << n_unique_words in a vocabulary\n",
    "        2 - Discarding the order of the words' appearance\n",
    "        \n",
    "        Args:\n",
    "            review (str): the review \n",
    "        Returns:\n",
    "            one_hot (np.ndarray): the collapsed one-hot encoding \n",
    "        \"\"\"\n",
    "        ### Create an array where each element corresponds to each word in the vocabulary\n",
    "        one_hot = np.zeros(len(self.review_vocab), dtype=np.float32)\n",
    "        ### Run lookup_token() for each word in the review sequentially, return an index\n",
    "        ### Assign the corresponding element in the array to 1.\n",
    "        for token in review.split(\" \"):\n",
    "            if token not in string.punctuation:\n",
    "                one_hot[self.review_vocab.lookup_token(token)] = 1\n",
    "        return one_hot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f268a8b6",
   "metadata": {},
   "source": [
    "# 2. Instantiate the ReviewVectorizer from the training data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1558ed85",
   "metadata": {},
   "source": [
    "### First draw a (static, fixed random seed) from the entire dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "667e8d04",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sample = df_all.sample(100,random_state=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "81a4d269",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rating</th>\n",
       "      <th>review</th>\n",
       "      <th>split</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1834</th>\n",
       "      <td>negative</td>\n",
       "      <td>we re not fans . the cake itself is nothing sp...</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12249</th>\n",
       "      <td>negative</td>\n",
       "      <td>service at the bar was good , food not so good...</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31400</th>\n",
       "      <td>positive</td>\n",
       "      <td>this place is just great ! we have been here f...</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49759</th>\n",
       "      <td>positive</td>\n",
       "      <td>had some time to kill between the chandler bbq...</td>\n",
       "      <td>val</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7228</th>\n",
       "      <td>negative</td>\n",
       "      <td>i m disappointed that people actually go here ...</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         rating                                             review  split\n",
       "1834   negative  we re not fans . the cake itself is nothing sp...  train\n",
       "12249  negative  service at the bar was good , food not so good...  train\n",
       "31400  positive  this place is just great ! we have been here f...  train\n",
       "49759  positive  had some time to kill between the chandler bbq...    val\n",
       "7228   negative  i m disappointed that people actually go here ...  train"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sample.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2041ed49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>split</th>\n",
       "      <th>test</th>\n",
       "      <th>train</th>\n",
       "      <th>val</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rating</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>negative</th>\n",
       "      <td>6</td>\n",
       "      <td>34</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>positive</th>\n",
       "      <td>11</td>\n",
       "      <td>29</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "split     test  train  val\n",
       "rating                    \n",
       "negative     6     34    9\n",
       "positive    11     29   11"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.crosstab(df_sample['rating'], df_sample['split'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1d526fa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "### A Vectorizer with cutoff = 8 \n",
    "### i.e., only add tokens that have appeared 8 times or more in the reviews\n",
    "vectorizer_cutoff_8 = ReviewVectorizer.from_dataframe(df_sample,8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "378100ce",
   "metadata": {},
   "source": [
    "### A vectorizer has two vocabularies(attributes), one for review, one for rating "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3621bd23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'review_vocab': <__main__.Vocabulary at 0x7f99c4ded4c0>,\n",
       " 'rating_vocab': <__main__.Vocabulary at 0x7f99c4deda60>}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vars(vectorizer_cutoff_8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ad80b5c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rating_vocab\n",
      "{'negative': 0, 'positive': 1}\n",
      "{0: 'negative', 1: 'positive'}\n",
      "------------------------------------------------------------\n",
      "review_vocab\n",
      "Includes 207 tokens\n"
     ]
    }
   ],
   "source": [
    "print('rating_vocab')\n",
    "print(vectorizer_cutoff_8.rating_vocab._token_to_idx)\n",
    "print(vectorizer_cutoff_8.rating_vocab._idx_to_token)\n",
    "print('-'*60)\n",
    "print('review_vocab')\n",
    "print(f\"Includes {len(vectorizer_cutoff_8.review_vocab)} tokens\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68b2486c",
   "metadata": {},
   "source": [
    "# 3. Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "225f78a7",
   "metadata": {},
   "source": [
    "### (classmethod) from_dataframe(review_df, cutoff): Instantiate the vectorizer from the dataset dataframe.\n",
    "1. First instantiate two Vocabularies based on the input data \"review_df\". [See a walkthrough of Vocabulary class here](https://github.com/houzhj/Machine_Learning/blob/main/ipynb/Yelp_Reviews/class_Vocabulary.ipynb).\n",
    "2. Use the review_vocab and rating_vocab as inputs to instantiate a vectorizer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "144b5097",
   "metadata": {},
   "source": [
    "### vectorize(review): It takes as an argument a string representing a review, and returns a vectorized representation of the review. This is the key functionality of the Vectorizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3aecb11c",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_text = \"the sun is shining and it is a beautiful day\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "45e3d27a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cutoff=10\n",
      "Review Vocabulary: the words appear >10 times\n",
      "{0: '<UNK>', 1: 'we', 2: 're', 3: 'not', 4: 'the', 5: 'is', 6: 'and', 7: 'to', 8: 'be', 9: 'on', 10: 'for', 11: 'us', 12: 'that', 13: 'or', 14: 's', 15: 'have', 16: 'n', 17: 'should', 18: 'a', 19: 'will', 20: 'but', 21: 'this', 22: 'like', 23: 'of', 24: 'nthe', 25: 'has', 26: 'much', 27: 'better', 28: 'than', 29: 'it', 30: 'what', 31: 'as', 32: 'in', 33: 'too', 34: 'time', 35: 'service', 36: 'at', 37: 'bar', 38: 'was', 39: 'good', 40: 'food', 41: 'so', 42: 'my', 43: 'restaurant', 44: 'very', 45: 'place', 46: 'just', 47: 'great', 48: 'been', 49: 'here', 50: 'lunch', 51: 'you', 52: 'always', 53: 'get', 54: 'they', 55: 'menu', 56: 'which', 57: 'are', 58: 'take', 59: 'nice', 60: 'had', 61: 'some', 62: 'night', 63: 'when', 64: 'i', 65: 'all', 66: 'before', 67: 'after', 68: 'can', 69: 'way', 70: 'out', 71: 'sure', 72: 'your', 73: 'still', 74: 'decent', 75: 'ordered', 76: 'chicken', 77: 'their', 78: 'our', 79: 'were', 80: 'if', 81: 'by', 82: 'would', 83: 'me', 84: 'm', 85: 'people', 86: 'actually', 87: 'go', 88: 'with', 89: 'other', 90: 'around', 91: 've', 92: 'don', 93: 't', 94: 'eat', 95: 'one', 96: 'them', 97: 'also', 98: 'an', 99: 'while', 100: 'up', 101: 'little', 102: 'there', 103: 'over', 104: 'even', 105: 'come', 106: 'looking', 107: 'wrong', 108: 'these', 109: 'really', 110: 'free', 111: 'line', 112: 'see', 113: 'didn', 114: 'find', 115: 'how', 116: 'never', 117: 'no', 118: 'made', 119: 'long', 120: 'two', 121: 'about', 122: 'because', 123: 'another', 124: 'check', 125: 'back', 126: 'he', 127: 'again', 128: 'could', 129: 'from', 130: 'more', 131: 'ever', 132: 'experience', 133: 'do', 134: 'know', 135: 'going', 136: 'only', 137: 'work', 138: 'last', 139: 'am', 140: 'friendly', 141: 'any', 142: 'day', 143: 'order', 144: 'ni', 145: 'who', 146: 'her', 147: 'bit', 148: 'first', 149: 'car', 150: 'customer', 151: 'something', 152: 'got', 153: 'best', 154: 'she', 155: 'feel', 156: 'did', 157: 'love', 158: 'family', 159: 'said', 160: 'fried', 161: 'where', 162: 'try', 163: 'came', 164: 'make', 165: 'asked', 166: 'staff', 167: 'well', 168: 'however', 169: 'mora'}\n",
      "One-hot representation: [1. 0. 0. 0. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0.]\n",
      "----------------------------------------------------------------------------------------------------\n",
      "cutoff=50\n",
      "Review Vocabulary: the words appear >50 times\n",
      "{0: '<UNK>', 1: 'we', 2: 'not', 3: 'the', 4: 'is', 5: 'and', 6: 'to', 7: 'be', 8: 'on', 9: 'for', 10: 'that', 11: 's', 12: 'have', 13: 'n', 14: 'a', 15: 'but', 16: 'this', 17: 'of', 18: 'it', 19: 'in', 20: 'at', 21: 'was', 22: 'so', 23: 'my', 24: 'place', 25: 'you', 26: 'they', 27: 'are', 28: 'had', 29: 'i', 30: 'out', 31: 'with', 32: 't', 33: 'there'}\n",
      "One-hot representation: [1. 0. 0. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "----------------------------------------------------------------------------------------------------\n",
      "cutoff=100\n",
      "Review Vocabulary: the words appear >100 times\n",
      "{0: '<UNK>', 1: 'the', 2: 'is', 3: 'and', 4: 'to', 5: 'for', 6: 'that', 7: 'have', 8: 'n', 9: 'a', 10: 'this', 11: 'of', 12: 'it', 13: 'in', 14: 'was', 15: 'my', 16: 'you', 17: 'they', 18: 'i', 19: 'with'}\n",
      "One-hot representation: [1. 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "cut_off_list = [10,50,100]\n",
    "for c in cut_off_list:\n",
    "    vectorizer = ReviewVectorizer.from_dataframe(df_sample,c)\n",
    "    one_hot    = vectorizer.vectorize(example_text)\n",
    "    print(f\"cutoff={c}\")\n",
    "    print(f'Review Vocabulary: the words appear >{c} times')\n",
    "    print(vectorizer.review_vocab._idx_to_token)\n",
    "    print('One-hot representation:', one_hot)\n",
    "    print('-'*100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
