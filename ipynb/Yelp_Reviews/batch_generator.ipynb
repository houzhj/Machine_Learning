{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2f5f7245",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import collections\n",
    "from collections import Counter\n",
    "import string\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "131f15e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of the data:  (56000, 3)\n",
      "------------------------------------------------------------\n",
      "     rating                                             review  split\n",
      "0  negative  terrible place to work for i just heard a stor...  train\n",
      "1  negative   hours , minutes total time for an extremely s...  train\n",
      "2  negative  my less than stellar review is for service . w...  train\n",
      "3  negative  i m granting one star because there s no way t...  train\n",
      "4  negative  the food here is mediocre at best . i went aft...  train\n"
     ]
    }
   ],
   "source": [
    "df_all = pd.read_csv(\"reviews_with_splits_lite.csv\")\n",
    "print(\"shape of the data: \", df_all.shape)\n",
    "print('-'*60)\n",
    "print(df_all.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4efaabca",
   "metadata": {},
   "source": [
    "# Define two relevent classes\n",
    "### - Vocabulary ([see a walkthrough here](https://github.com/houzhj/Machine_Learning/blob/main/ipynb/Yelp_Reviews/class_Vocabulary.ipynb))\n",
    "### - ReviewVectorizer ([see a walkthrough here](https://github.com/houzhj/Machine_Learning/blob/main/ipynb/Yelp_Reviews/class_Vectorizer.ipynb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b2f2753b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Vocabulary(object):\n",
    "    \"\"\"Class to process text and extract vocabulary for mapping\"\"\"\n",
    "    def __init__(self, token_to_idx=None, add_unk=True, unk_token=\"<UNK>\"):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            token_to_idx (dict): a pre-existing map of tokens to indices\n",
    "            add_unk (bool): a flag that indicates whether to add the UNK token\n",
    "            unk_token (str): the UNK token to add into the Vocabulary\n",
    "        \"\"\"\n",
    "        if token_to_idx is None:\n",
    "            token_to_idx = {}\n",
    "        self._token_to_idx = token_to_idx\n",
    "        self._idx_to_token = {idx: token \n",
    "                              for token, idx in self._token_to_idx.items()}\n",
    "        \n",
    "        self._add_unk   = add_unk\n",
    "        self._unk_token = unk_token      \n",
    "        self.unk_index  = -999\n",
    "        ### the unk_token, i.e, \"<UNK>\" is the first added token if add_unk=True\n",
    "        ### self.unk_index is changed from -999 to 0\n",
    "        if add_unk:\n",
    "            self.unk_index = self.add_token(unk_token) \n",
    "\n",
    "    def add_token(self, token):\n",
    "        \"\"\"Update mapping dicts based on the token.\n",
    "\n",
    "        Args:\n",
    "            token (str): the item to add into the Vocabulary\n",
    "        Returns:\n",
    "            index (int): the integer corresponding to the token\n",
    "        \"\"\"\n",
    "        if token in self._token_to_idx:\n",
    "            index = self._token_to_idx[token]\n",
    "        else:\n",
    "            index = len(self._token_to_idx)\n",
    "            ### add a new element to _token_to_idx\n",
    "            self._token_to_idx[token] = index\n",
    "            ### add a new element to _idx_to_token\n",
    "            self._idx_to_token[index] = token\n",
    "        return index\n",
    "   \n",
    "    def lookup_token(self, token):\n",
    "        \"\"\"Retrieve the index associated with the token \n",
    "          or the UNK index if token isn't present.\n",
    "        \n",
    "        Args:\n",
    "            token (str): the token to look up \n",
    "        Returns:\n",
    "            index (int): the index corresponding to the token\n",
    "        Notes:\n",
    "            `unk_index` needs to be >=0 (having been added into the Vocabulary) \n",
    "              for the UNK functionality \n",
    "        \"\"\"\n",
    "        if self.unk_index >= 0:\n",
    "            ### .get(): return self.unk_index if the key \"token\" does not exist. \n",
    "            return self._token_to_idx.get(token, self.unk_index)\n",
    "        else:\n",
    "            return self._token_to_idx[token]\n",
    "    \n",
    "    def lookup_index(self, index):\n",
    "        \"\"\"Return the token associated with the index\n",
    "        \n",
    "        Args: \n",
    "            index (int): the index to look up\n",
    "        Returns:\n",
    "            token (str): the token corresponding to the index\n",
    "        Raises:\n",
    "            KeyError: if the index is not in the Vocabulary\n",
    "        \"\"\"\n",
    "        if index not in self._idx_to_token:\n",
    "            raise KeyError(\"the index (%d) is not in the Vocabulary\" % index)\n",
    "        return self._idx_to_token[index]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self._token_to_idx)\n",
    "    \n",
    "class ReviewVectorizer(object):\n",
    "    \"\"\" The Vectorizer which coordinates the Vocabularies and puts them to use\"\"\"\n",
    "    def __init__(self, review_vocab, rating_vocab):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            review_vocab (Vocabulary): maps words to integers\n",
    "            rating_vocab (Vocabulary): maps class labels to integers\n",
    "        \"\"\"\n",
    "        self.review_vocab = review_vocab\n",
    "        self.rating_vocab = rating_vocab\n",
    "         \n",
    "    @classmethod\n",
    "    def from_dataframe(cls, review_df, cutoff):\n",
    "        \"\"\"Instantiate the vectorizer from the dataset dataframe\n",
    "        \n",
    "        Args:\n",
    "            review_df (pandas.DataFrame): the review dataset\n",
    "            cutoff (int): the parameter for frequency-based filtering\n",
    "        Returns:\n",
    "            an instance of the ReviewVectorizer\n",
    "        \"\"\"\n",
    "        review_vocab = Vocabulary(add_unk=True)\n",
    "        rating_vocab = Vocabulary(add_unk=False)\n",
    "        \n",
    "        ########## Add tokens to rating_vocab ('positive' and 'negative')\n",
    "        for rating in sorted(set(review_df.rating)):\n",
    "            rating_vocab.add_token(rating)\n",
    "            \n",
    "        ########## Add tokens to review_vocab\n",
    "        ### Create a Counter() to count all tokens appears in review_df.review\n",
    "        word_counts = Counter()\n",
    "        for review in review_df.review:\n",
    "            for word in review.split(\" \"):\n",
    "                if word not in string.punctuation:\n",
    "                    word_counts[word] += 1\n",
    "        ### execute add_token if a word appears more than \"cutoff\" times\n",
    "        for word, count in word_counts.items():\n",
    "            if count > cutoff:\n",
    "                review_vocab.add_token(word)\n",
    "        return cls(review_vocab, rating_vocab)\n",
    "\n",
    "    ### This is the key functionality of the Vectorizer.\n",
    "    ### It takes as an argument a string representing a review,\n",
    "    ### and returns a vectorized representation of the review.\n",
    "    def vectorize(self, review):\n",
    "        \"\"\"\n",
    "        Create a collapsed one-hot representation vector for the review\n",
    "        Limitations of the one-hot method:\n",
    "        1 - Sparseness, n_unique_words in a review << n_unique_words in a vocabulary\n",
    "        2 - Discarding the order of the words' appearance\n",
    "        \n",
    "        Args:\n",
    "            review (str): the review \n",
    "        Returns:\n",
    "            one_hot (np.ndarray): the collapsed one-hot encoding \n",
    "        \"\"\"\n",
    "        ### Create an array where each element corresponds to each word in the vocabulary\n",
    "        one_hot = np.zeros(len(self.review_vocab), dtype=np.float32)\n",
    "        ### Run lookup_token() for each word in the review sequentially, return an index\n",
    "        ### Assign the corresponding element in the array to 1.\n",
    "        for token in review.split(\" \"):\n",
    "            if token not in string.punctuation:\n",
    "                one_hot[self.review_vocab.lookup_token(token)] = 1\n",
    "        return one_hot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7d61628",
   "metadata": {},
   "source": [
    "# 1. ReviewDataset class\n",
    "### - The Dataset class will characterize the key features of the dataset.\n",
    "### - In the initialization function of the class, make the class inherit the properties of torch.utils.data.Dataset so that we can later leverage its functionalities.\n",
    "### - In the \\_\\_init\\_\\_() function and the set_split() function, store important information such as labels and the features that we wish to generate at each pass.\n",
    "### - Each call requests a sample index for which the upperbound is specified in the \\_\\_len\\_\\_() method.\n",
    "### - When the sample corresponding to a given index is called, the generator executes the \\_\\_getitem\\_\\_() method to generate it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "336ed30c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReviewDataset(Dataset):\n",
    "    def __init__(self,review_df,vectorizer):\n",
    "        self.review_df   = review_df\n",
    "        self._vectorizer = vectorizer\n",
    "        \n",
    "        self.train_df    = self.review_df[self.review_df.split=='train']\n",
    "        self.train_size  = len(self.train_df)\n",
    "\n",
    "        self.val_df      = self.review_df[self.review_df.split=='val']\n",
    "        self.validation_size = len(self.val_df)\n",
    "\n",
    "        self.test_df     = self.review_df[self.review_df.split=='test']\n",
    "        self.test_size   = len(self.test_df)\n",
    "        \n",
    "        self._lookup_dict = {'train': (self.train_df, self.train_size),\n",
    "                             'val': (self.val_df, self.validation_size),\n",
    "                             'test': (self.test_df, self.test_size)}\n",
    "        self.set_split('train')\n",
    "        \n",
    "    @classmethod\n",
    "    def load_csv_and_make_vectorizer(cls,review_csv,cut_off):\n",
    "        \"\"\"Load dataset and make a new vectorizer from scratch\n",
    "        Args:\n",
    "            review_csv (str): location of the dataset\n",
    "        Returns:\n",
    "            an instance of ReviewDataset\n",
    "        \"\"\"\n",
    "        review_df = pd.read_csv(review_csv)\n",
    "        ### make vectorizer using training dataset\n",
    "        train_review_df = review_df[review_df.split=='train']\n",
    "        new_vectorizer  = ReviewVectorizer.from_dataframe(train_review_df,cut_off)\n",
    "        return cls(review_df,new_vectorizer)\n",
    "    \n",
    "    @classmethod\n",
    "    def load_df_and_make_vectorizer(cls,review_df,cut_off):\n",
    "        \"\"\"Load dataset and make a new vectorizer from scratch\n",
    "        Args:\n",
    "            review_df: dataset\n",
    "        Returns:\n",
    "            an instance of ReviewDataset\n",
    "        \"\"\"\n",
    "        ### make vectorizer using training dataset\n",
    "        train_review_df = review_df[review_df.split=='train']\n",
    "        new_vectorizer  = ReviewVectorizer.from_dataframe(train_review_df,cut_off)\n",
    "        return cls(review_df,new_vectorizer)\n",
    "    \n",
    "    def set_split(self, split=\"train\"):\n",
    "        \"\"\" selects the splits in the dataset using a column in the dataframe \n",
    "        Args:\n",
    "            split (str): one of \"train\", \"val\", or \"test\"\n",
    "        \"\"\"\n",
    "        self._target_split = split\n",
    "        ### when split = 'train', _target_df means the training set\n",
    "        self._target_df, self._target_size = self._lookup_dict[split]\n",
    "        \n",
    "    def __len__(self):\n",
    "        ### _target_size is defined in set_split() \n",
    "        return self._target_size        \n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"the primary entry point method for PyTorch datasets\n",
    "        \n",
    "        Args:\n",
    "            index (int): the index to the data point \n",
    "        Returns:\n",
    "            a dictionary holding the data point's features (x_data) and label (y_target)\n",
    "        \"\"\"\n",
    "        \n",
    "        row = self._target_df.iloc[index]\n",
    "\n",
    "        review_vector = \\\n",
    "            self._vectorizer.vectorize(row.review)\n",
    "\n",
    "        rating_index = \\\n",
    "            self._vectorizer.rating_vocab.lookup_token(row.rating)\n",
    "\n",
    "        return {'x_data': review_vector,\n",
    "                'y_target': rating_index}\n",
    "\n",
    "    def get_vectorizer(self):\n",
    "        \"\"\" returns the vectorizer \"\"\"\n",
    "        return self._vectorizer\n",
    "    \n",
    "    def get_num_batches(self, batch_size):\n",
    "        \"\"\"Given a batch size, return the number of batches in the dataset\n",
    "        Args:\n",
    "            batch_size (int)\n",
    "        Returns:\n",
    "            number of batches in the dataset\n",
    "        \"\"\"\n",
    "        return len(self) // batch_size  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11eeb7c0",
   "metadata": {},
   "source": [
    "# 2. Instantiate a ReviewDataset from the training data\n",
    "### There are two classmethods can be used to instantiate a ReviewDataset: load_csv_and_make_vectorizer() and load_df_and_make_vectorizer(). The difference is whether the input data is from a csv file or a pd.DataFrame file. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f851359a",
   "metadata": {},
   "source": [
    "### First draw a (static, fixed random seed) from the entire datas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6784708b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sample = df_all.sample(100,random_state=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "064517be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rating</th>\n",
       "      <th>review</th>\n",
       "      <th>split</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1834</th>\n",
       "      <td>negative</td>\n",
       "      <td>we re not fans . the cake itself is nothing sp...</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12249</th>\n",
       "      <td>negative</td>\n",
       "      <td>service at the bar was good , food not so good...</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31400</th>\n",
       "      <td>positive</td>\n",
       "      <td>this place is just great ! we have been here f...</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49759</th>\n",
       "      <td>positive</td>\n",
       "      <td>had some time to kill between the chandler bbq...</td>\n",
       "      <td>val</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7228</th>\n",
       "      <td>negative</td>\n",
       "      <td>i m disappointed that people actually go here ...</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         rating                                             review  split\n",
       "1834   negative  we re not fans . the cake itself is nothing sp...  train\n",
       "12249  negative  service at the bar was good , food not so good...  train\n",
       "31400  positive  this place is just great ! we have been here f...  train\n",
       "49759  positive  had some time to kill between the chandler bbq...    val\n",
       "7228   negative  i m disappointed that people actually go here ...  train"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sample.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ef53e322",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>split</th>\n",
       "      <th>test</th>\n",
       "      <th>train</th>\n",
       "      <th>val</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rating</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>negative</th>\n",
       "      <td>6</td>\n",
       "      <td>34</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>positive</th>\n",
       "      <td>11</td>\n",
       "      <td>29</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "split     test  train  val\n",
       "rating                    \n",
       "negative     6     34    9\n",
       "positive    11     29   11"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.crosstab(df_sample['rating'], df_sample['split'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f3c98b6",
   "metadata": {},
   "source": [
    "### Create a ReviewDataset, with a cutoff = 50 (i.e., add a token to the revew_vocab if the tokan appears more than 50 times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9c111ab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_sample = ReviewDataset.load_df_and_make_vectorizer(df_sample,50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d0225ae",
   "metadata": {},
   "source": [
    "## 2.1 - Attributes of a ReviewDataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbc92dc7",
   "metadata": {},
   "source": [
    "### .review_df: the input dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0ecf3088",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rating</th>\n",
       "      <th>review</th>\n",
       "      <th>split</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1834</th>\n",
       "      <td>negative</td>\n",
       "      <td>we re not fans . the cake itself is nothing sp...</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12249</th>\n",
       "      <td>negative</td>\n",
       "      <td>service at the bar was good , food not so good...</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31400</th>\n",
       "      <td>positive</td>\n",
       "      <td>this place is just great ! we have been here f...</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49759</th>\n",
       "      <td>positive</td>\n",
       "      <td>had some time to kill between the chandler bbq...</td>\n",
       "      <td>val</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7228</th>\n",
       "      <td>negative</td>\n",
       "      <td>i m disappointed that people actually go here ...</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39446</th>\n",
       "      <td>positive</td>\n",
       "      <td>my favorite place to park as they have great r...</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55650</th>\n",
       "      <td>positive</td>\n",
       "      <td>jenni at the southwest airlines helping my dau...</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55382</th>\n",
       "      <td>positive</td>\n",
       "      <td>always pleased . good portions of fish in roll...</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38349</th>\n",
       "      <td>positive</td>\n",
       "      <td>we had our year anniversary dinner at differen...</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31507</th>\n",
       "      <td>positive</td>\n",
       "      <td>the chicken bryan is one of my favorite dishes...</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         rating                                             review  split\n",
       "1834   negative  we re not fans . the cake itself is nothing sp...  train\n",
       "12249  negative  service at the bar was good , food not so good...  train\n",
       "31400  positive  this place is just great ! we have been here f...  train\n",
       "49759  positive  had some time to kill between the chandler bbq...    val\n",
       "7228   negative  i m disappointed that people actually go here ...  train\n",
       "...         ...                                                ...    ...\n",
       "39446  positive  my favorite place to park as they have great r...  train\n",
       "55650  positive  jenni at the southwest airlines helping my dau...   test\n",
       "55382  positive  always pleased . good portions of fish in roll...   test\n",
       "38349  positive  we had our year anniversary dinner at differen...  train\n",
       "31507  positive  the chicken bryan is one of my favorite dishes...  train\n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_sample.review_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "177ca416",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_sample.review_df.equals(df_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26d7ee85",
   "metadata": {},
   "source": [
    "### ._vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3387bde1",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Note that the vectorizer is derived from the training split. \n",
    "v = dataset_sample._vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2ea070b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_text = \"the sun is shining and it is a beautiful day\"\n",
    "one_hot      = v.vectorize(example_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c34c23dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review Vocabulary: the words appear >50 times\n",
      "------------------------------------------------------------\n",
      "_idx_to_token:  {0: '<UNK>', 1: 'not', 2: 'the', 3: 'is', 4: 'and', 5: 'to', 6: 'on', 7: 'for', 8: 'that', 9: 's', 10: 'have', 11: 'n', 12: 'a', 13: 'this', 14: 'of', 15: 'it', 16: 'in', 17: 'at', 18: 'was', 19: 'my', 20: 'you', 21: 'they', 22: 'are', 23: 'i', 24: 'with', 25: 'had', 26: 't', 27: 'there'}\n",
      "------------------------------------------------------------\n",
      "One-hot representation: [1. 0. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "print(f'Review Vocabulary: the words appear >50 times')\n",
    "print('-'*60)\n",
    "print(\"_idx_to_token: \", v.review_vocab._idx_to_token)\n",
    "print('-'*60)\n",
    "print('One-hot representation:', one_hot)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75f76a9b",
   "metadata": {},
   "source": [
    "### ._target_df, _target_size\n",
    "**Defined by method set_split()**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7c526883",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rating</th>\n",
       "      <th>review</th>\n",
       "      <th>split</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1834</th>\n",
       "      <td>negative</td>\n",
       "      <td>we re not fans . the cake itself is nothing sp...</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12249</th>\n",
       "      <td>negative</td>\n",
       "      <td>service at the bar was good , food not so good...</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31400</th>\n",
       "      <td>positive</td>\n",
       "      <td>this place is just great ! we have been here f...</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7228</th>\n",
       "      <td>negative</td>\n",
       "      <td>i m disappointed that people actually go here ...</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42913</th>\n",
       "      <td>positive</td>\n",
       "      <td>after the construction completed , this hyatt ...</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9245</th>\n",
       "      <td>negative</td>\n",
       "      <td>my job forced me to spend long summer days in ...</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11195</th>\n",
       "      <td>negative</td>\n",
       "      <td>horrible service . nobody to even help find ou...</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39446</th>\n",
       "      <td>positive</td>\n",
       "      <td>my favorite place to park as they have great r...</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38349</th>\n",
       "      <td>positive</td>\n",
       "      <td>we had our year anniversary dinner at differen...</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31507</th>\n",
       "      <td>positive</td>\n",
       "      <td>the chicken bryan is one of my favorite dishes...</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>63 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         rating                                             review  split\n",
       "1834   negative  we re not fans . the cake itself is nothing sp...  train\n",
       "12249  negative  service at the bar was good , food not so good...  train\n",
       "31400  positive  this place is just great ! we have been here f...  train\n",
       "7228   negative  i m disappointed that people actually go here ...  train\n",
       "42913  positive  after the construction completed , this hyatt ...  train\n",
       "...         ...                                                ...    ...\n",
       "9245   negative  my job forced me to spend long summer days in ...  train\n",
       "11195  negative  horrible service . nobody to even help find ou...  train\n",
       "39446  positive  my favorite place to park as they have great r...  train\n",
       "38349  positive  we had our year anniversary dinner at differen...  train\n",
       "31507  positive  the chicken bryan is one of my favorite dishes...  train\n",
       "\n",
       "[63 rows x 3 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_sample._target_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "30bb66b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "63"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_sample._target_size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c952364c",
   "metadata": {},
   "source": [
    "### ._lookup_dict - will be used in the method set_split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ec3860e8",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': (         rating                                             review  split\n",
       "  1834   negative  we re not fans . the cake itself is nothing sp...  train\n",
       "  12249  negative  service at the bar was good , food not so good...  train\n",
       "  31400  positive  this place is just great ! we have been here f...  train\n",
       "  7228   negative  i m disappointed that people actually go here ...  train\n",
       "  42913  positive  after the construction completed , this hyatt ...  train\n",
       "  ...         ...                                                ...    ...\n",
       "  9245   negative  my job forced me to spend long summer days in ...  train\n",
       "  11195  negative  horrible service . nobody to even help find ou...  train\n",
       "  39446  positive  my favorite place to park as they have great r...  train\n",
       "  38349  positive  we had our year anniversary dinner at differen...  train\n",
       "  31507  positive  the chicken bryan is one of my favorite dishes...  train\n",
       "  \n",
       "  [63 rows x 3 columns],\n",
       "  63),\n",
       " 'val': (         rating                                             review split\n",
       "  49759  positive  had some time to kill between the chandler bbq...   val\n",
       "  48068  positive  love it here ! family favorite , we always mee...   val\n",
       "  20434  negative  the associates are slow and rude . one time i ...   val\n",
       "  49390  positive  sarah is one of the best stylists around vegas...   val\n",
       "  22769  negative  worst service ever . walked in and the woman r...   val\n",
       "  47653  positive  i seriously love this store . i wish i didn t ...   val\n",
       "  23209  negative  this place needs a minus nbecause i so have a ...   val\n",
       "  21945  negative  it was okay , but meh , i ve experienced bette...   val\n",
       "  50744  positive  great place . perfect service . can t wait to ...   val\n",
       "  47945  positive  i ve been going to this same shop for about yr...   val\n",
       "  48055  positive  great comfort food . i ordered a veggie omelet...   val\n",
       "  20481  negative  great customer service and a cheap price for a...   val\n",
       "  49512  positive  after living within walking distance of this n...   val\n",
       "  49764  positive  dude their salads are awesome that s all i get...   val\n",
       "  21003  negative  horrible phone service from janae , and very o...   val\n",
       "  19749  negative  cheap breakfast that is mediocre . the service...   val\n",
       "  22098  negative  ah , the dreaded worst experience of my life ,...   val\n",
       "  48754  positive  great place to experience home cooked style so...   val\n",
       "  48969  positive  the staff here is awesome ! ! the store is spo...   val\n",
       "  22804  negative  this is my regular stop coming from phl to sfo...   val,\n",
       "  20),\n",
       " 'test': (         rating                                             review split\n",
       "  55330  positive  this place is obscene . grandiose . excessive ...  test\n",
       "  55928  positive  this is my go to place when in charlotte i hav...  test\n",
       "  54191  positive  over the last couple of years i have made seve...  test\n",
       "  53923  positive  fun place overall . looks like it s gonna be a...  test\n",
       "  52744  positive  this is my rd year in uc and cu mtd is a life ...  test\n",
       "  25558  negative  i am beyond irate with this business ! ! they ...  test\n",
       "  53373  positive  yes , their prices are a little high compared ...  test\n",
       "  53218  positive  shea was great ! fast , friendly and honest se...  test\n",
       "  54574  positive  decent pizza . decent prices . great place for...  test\n",
       "  51812  positive  so happy i found this place , great family own...  test\n",
       "  24736  negative  monkeys could do a better job . the staff do n...  test\n",
       "  25599  negative  i came in with no expectations , and thank goo...  test\n",
       "  27125  negative  it s hit and miss with their service . i m not...  test\n",
       "  27524  negative  this particular bucks seems to be hit or miss ...  test\n",
       "  25057  negative  i have a misleading cited to shop at best buy ...  test\n",
       "  55650  positive  jenni at the southwest airlines helping my dau...  test\n",
       "  55382  positive  always pleased . good portions of fish in roll...  test,\n",
       "  17)}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_sample._lookup_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "57c0d32e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(         rating                                             review  split\n",
       " 1834   negative  we re not fans . the cake itself is nothing sp...  train\n",
       " 12249  negative  service at the bar was good , food not so good...  train\n",
       " 31400  positive  this place is just great ! we have been here f...  train\n",
       " 7228   negative  i m disappointed that people actually go here ...  train\n",
       " 42913  positive  after the construction completed , this hyatt ...  train\n",
       " ...         ...                                                ...    ...\n",
       " 9245   negative  my job forced me to spend long summer days in ...  train\n",
       " 11195  negative  horrible service . nobody to even help find ou...  train\n",
       " 39446  positive  my favorite place to park as they have great r...  train\n",
       " 38349  positive  we had our year anniversary dinner at differen...  train\n",
       " 31507  positive  the chicken bryan is one of my favorite dishes...  train\n",
       " \n",
       " [63 rows x 3 columns],\n",
       " 63)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### A dictionary which contains a df and a scalar\n",
    "dataset_sample._lookup_dict['train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8fdc9532",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rating</th>\n",
       "      <th>review</th>\n",
       "      <th>split</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1834</th>\n",
       "      <td>negative</td>\n",
       "      <td>we re not fans . the cake itself is nothing sp...</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12249</th>\n",
       "      <td>negative</td>\n",
       "      <td>service at the bar was good , food not so good...</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31400</th>\n",
       "      <td>positive</td>\n",
       "      <td>this place is just great ! we have been here f...</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7228</th>\n",
       "      <td>negative</td>\n",
       "      <td>i m disappointed that people actually go here ...</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42913</th>\n",
       "      <td>positive</td>\n",
       "      <td>after the construction completed , this hyatt ...</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9245</th>\n",
       "      <td>negative</td>\n",
       "      <td>my job forced me to spend long summer days in ...</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11195</th>\n",
       "      <td>negative</td>\n",
       "      <td>horrible service . nobody to even help find ou...</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39446</th>\n",
       "      <td>positive</td>\n",
       "      <td>my favorite place to park as they have great r...</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38349</th>\n",
       "      <td>positive</td>\n",
       "      <td>we had our year anniversary dinner at differen...</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31507</th>\n",
       "      <td>positive</td>\n",
       "      <td>the chicken bryan is one of my favorite dishes...</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>63 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         rating                                             review  split\n",
       "1834   negative  we re not fans . the cake itself is nothing sp...  train\n",
       "12249  negative  service at the bar was good , food not so good...  train\n",
       "31400  positive  this place is just great ! we have been here f...  train\n",
       "7228   negative  i m disappointed that people actually go here ...  train\n",
       "42913  positive  after the construction completed , this hyatt ...  train\n",
       "...         ...                                                ...    ...\n",
       "9245   negative  my job forced me to spend long summer days in ...  train\n",
       "11195  negative  horrible service . nobody to even help find ou...  train\n",
       "39446  positive  my favorite place to park as they have great r...  train\n",
       "38349  positive  we had our year anniversary dinner at differen...  train\n",
       "31507  positive  the chicken bryan is one of my favorite dishes...  train\n",
       "\n",
       "[63 rows x 3 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### the dataframe\n",
    "dataset_sample._lookup_dict['train'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2ea4c33b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "63"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### the sample size\n",
    "dataset_sample._lookup_dict['train'][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b4b974f",
   "metadata": {},
   "source": [
    "## 2.2 - Methods of a ReviewDataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c014c440",
   "metadata": {},
   "source": [
    "### \\_\\_len()\\_\\_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e2a9ee4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "63"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6cd9617",
   "metadata": {},
   "source": [
    "### \\_\\_getitem()\\_\\_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c81d7520",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'x_data': array([1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32),\n",
       " 'y_target': 0}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### The 4th element in the \"train\" split\n",
    "### In the __init__ function, self.set_split('train') defines ._target_df\n",
    "dataset_sample[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a3f8e011",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rating</th>\n",
       "      <th>review</th>\n",
       "      <th>split</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1834</th>\n",
       "      <td>negative</td>\n",
       "      <td>we re not fans . the cake itself is nothing sp...</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12249</th>\n",
       "      <td>negative</td>\n",
       "      <td>service at the bar was good , food not so good...</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31400</th>\n",
       "      <td>positive</td>\n",
       "      <td>this place is just great ! we have been here f...</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49759</th>\n",
       "      <td>positive</td>\n",
       "      <td>had some time to kill between the chandler bbq...</td>\n",
       "      <td>val</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7228</th>\n",
       "      <td>negative</td>\n",
       "      <td>i m disappointed that people actually go here ...</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         rating                                             review  split\n",
       "1834   negative  we re not fans . the cake itself is nothing sp...  train\n",
       "12249  negative  service at the bar was good , food not so good...  train\n",
       "31400  positive  this place is just great ! we have been here f...  train\n",
       "49759  positive  had some time to kill between the chandler bbq...    val\n",
       "7228   negative  i m disappointed that people actually go here ...  train"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sample.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85b3eb72",
   "metadata": {},
   "source": [
    "### set_split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bd13cd3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_sample = ReviewDataset.load_df_and_make_vectorizer(df_sample,50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3f0c92fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rating</th>\n",
       "      <th>review</th>\n",
       "      <th>split</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1834</th>\n",
       "      <td>negative</td>\n",
       "      <td>we re not fans . the cake itself is nothing sp...</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12249</th>\n",
       "      <td>negative</td>\n",
       "      <td>service at the bar was good , food not so good...</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31400</th>\n",
       "      <td>positive</td>\n",
       "      <td>this place is just great ! we have been here f...</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7228</th>\n",
       "      <td>negative</td>\n",
       "      <td>i m disappointed that people actually go here ...</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42913</th>\n",
       "      <td>positive</td>\n",
       "      <td>after the construction completed , this hyatt ...</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9245</th>\n",
       "      <td>negative</td>\n",
       "      <td>my job forced me to spend long summer days in ...</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11195</th>\n",
       "      <td>negative</td>\n",
       "      <td>horrible service . nobody to even help find ou...</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39446</th>\n",
       "      <td>positive</td>\n",
       "      <td>my favorite place to park as they have great r...</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38349</th>\n",
       "      <td>positive</td>\n",
       "      <td>we had our year anniversary dinner at differen...</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31507</th>\n",
       "      <td>positive</td>\n",
       "      <td>the chicken bryan is one of my favorite dishes...</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>63 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         rating                                             review  split\n",
       "1834   negative  we re not fans . the cake itself is nothing sp...  train\n",
       "12249  negative  service at the bar was good , food not so good...  train\n",
       "31400  positive  this place is just great ! we have been here f...  train\n",
       "7228   negative  i m disappointed that people actually go here ...  train\n",
       "42913  positive  after the construction completed , this hyatt ...  train\n",
       "...         ...                                                ...    ...\n",
       "9245   negative  my job forced me to spend long summer days in ...  train\n",
       "11195  negative  horrible service . nobody to even help find ou...  train\n",
       "39446  positive  my favorite place to park as they have great r...  train\n",
       "38349  positive  we had our year anniversary dinner at differen...  train\n",
       "31507  positive  the chicken bryan is one of my favorite dishes...  train\n",
       "\n",
       "[63 rows x 3 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Now the split for ._target_df and _target_size is 'train'\n",
    "dataset_sample._target_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "27626144",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "63"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "14848e6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'x_data': array([1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32),\n",
       " 'y_target': 0}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_sample[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a931c936",
   "metadata": {},
   "outputs": [],
   "source": [
    "### run set_split, switch the split to 'val'\n",
    "dataset_sample.set_split('val')\n",
    "# or \n",
    "# ReviewDataset.set_split(dataset_sample,'val')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f847e938",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rating</th>\n",
       "      <th>review</th>\n",
       "      <th>split</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>49759</th>\n",
       "      <td>positive</td>\n",
       "      <td>had some time to kill between the chandler bbq...</td>\n",
       "      <td>val</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48068</th>\n",
       "      <td>positive</td>\n",
       "      <td>love it here ! family favorite , we always mee...</td>\n",
       "      <td>val</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20434</th>\n",
       "      <td>negative</td>\n",
       "      <td>the associates are slow and rude . one time i ...</td>\n",
       "      <td>val</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49390</th>\n",
       "      <td>positive</td>\n",
       "      <td>sarah is one of the best stylists around vegas...</td>\n",
       "      <td>val</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22769</th>\n",
       "      <td>negative</td>\n",
       "      <td>worst service ever . walked in and the woman r...</td>\n",
       "      <td>val</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47653</th>\n",
       "      <td>positive</td>\n",
       "      <td>i seriously love this store . i wish i didn t ...</td>\n",
       "      <td>val</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23209</th>\n",
       "      <td>negative</td>\n",
       "      <td>this place needs a minus nbecause i so have a ...</td>\n",
       "      <td>val</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21945</th>\n",
       "      <td>negative</td>\n",
       "      <td>it was okay , but meh , i ve experienced bette...</td>\n",
       "      <td>val</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50744</th>\n",
       "      <td>positive</td>\n",
       "      <td>great place . perfect service . can t wait to ...</td>\n",
       "      <td>val</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47945</th>\n",
       "      <td>positive</td>\n",
       "      <td>i ve been going to this same shop for about yr...</td>\n",
       "      <td>val</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48055</th>\n",
       "      <td>positive</td>\n",
       "      <td>great comfort food . i ordered a veggie omelet...</td>\n",
       "      <td>val</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20481</th>\n",
       "      <td>negative</td>\n",
       "      <td>great customer service and a cheap price for a...</td>\n",
       "      <td>val</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49512</th>\n",
       "      <td>positive</td>\n",
       "      <td>after living within walking distance of this n...</td>\n",
       "      <td>val</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49764</th>\n",
       "      <td>positive</td>\n",
       "      <td>dude their salads are awesome that s all i get...</td>\n",
       "      <td>val</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21003</th>\n",
       "      <td>negative</td>\n",
       "      <td>horrible phone service from janae , and very o...</td>\n",
       "      <td>val</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19749</th>\n",
       "      <td>negative</td>\n",
       "      <td>cheap breakfast that is mediocre . the service...</td>\n",
       "      <td>val</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22098</th>\n",
       "      <td>negative</td>\n",
       "      <td>ah , the dreaded worst experience of my life ,...</td>\n",
       "      <td>val</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48754</th>\n",
       "      <td>positive</td>\n",
       "      <td>great place to experience home cooked style so...</td>\n",
       "      <td>val</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48969</th>\n",
       "      <td>positive</td>\n",
       "      <td>the staff here is awesome ! ! the store is spo...</td>\n",
       "      <td>val</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22804</th>\n",
       "      <td>negative</td>\n",
       "      <td>this is my regular stop coming from phl to sfo...</td>\n",
       "      <td>val</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         rating                                             review split\n",
       "49759  positive  had some time to kill between the chandler bbq...   val\n",
       "48068  positive  love it here ! family favorite , we always mee...   val\n",
       "20434  negative  the associates are slow and rude . one time i ...   val\n",
       "49390  positive  sarah is one of the best stylists around vegas...   val\n",
       "22769  negative  worst service ever . walked in and the woman r...   val\n",
       "47653  positive  i seriously love this store . i wish i didn t ...   val\n",
       "23209  negative  this place needs a minus nbecause i so have a ...   val\n",
       "21945  negative  it was okay , but meh , i ve experienced bette...   val\n",
       "50744  positive  great place . perfect service . can t wait to ...   val\n",
       "47945  positive  i ve been going to this same shop for about yr...   val\n",
       "48055  positive  great comfort food . i ordered a veggie omelet...   val\n",
       "20481  negative  great customer service and a cheap price for a...   val\n",
       "49512  positive  after living within walking distance of this n...   val\n",
       "49764  positive  dude their salads are awesome that s all i get...   val\n",
       "21003  negative  horrible phone service from janae , and very o...   val\n",
       "19749  negative  cheap breakfast that is mediocre . the service...   val\n",
       "22098  negative  ah , the dreaded worst experience of my life ,...   val\n",
       "48754  positive  great place to experience home cooked style so...   val\n",
       "48969  positive  the staff here is awesome ! ! the store is spo...   val\n",
       "22804  negative  this is my regular stop coming from phl to sfo...   val"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Now the split for ._target_df and _target_size is 'val'\n",
    "dataset_sample._target_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5fef7f02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "04955d02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'x_data': array([1., 0., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0.,\n",
       "        0., 0., 1., 1., 0., 0., 1., 0., 0., 0., 0.], dtype=float32),\n",
       " 'y_target': 1}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_sample[3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "000f2c3f",
   "metadata": {},
   "source": [
    "### get_vectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b7d3c839",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.ReviewVectorizer at 0x7fe1e3730460>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_sample.get_vectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5e427ab9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.ReviewVectorizer at 0x7fe1e3730460>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Equivalently\n",
    "dataset_sample._vectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6750f609",
   "metadata": {},
   "source": [
    "### get_num_batches()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0f2dacf7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_sample.get_num_batches(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c5bff7a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.0"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset_sample._target_df)/10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f88d7ae0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.0"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset_sample)/10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "278b79c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Switch the split to 'train'\n",
    "dataset_sample.set_split('train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d697ed6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_sample.get_num_batches(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "62c67788",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.3"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset_sample._target_df)/10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7464e8e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset_sample._target_df)//10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eedca03f",
   "metadata": {},
   "source": [
    "# 3. Define a batch generator\n",
    "### - Wrap the DataLoader\n",
    "### - Switch the data between the CPU and the GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "255860b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_batches(dataset, batch_size, shuffle=True,\n",
    "                     drop_last=True, device='cpu'):\n",
    "    \"\"\"\n",
    "    A generator function which wraps the PyTorch DataLoader. It will \n",
    "      ensure each tensor is on the write device location.\n",
    "    \"\"\"\n",
    "    dataloader = DataLoader(dataset=dataset, batch_size=batch_size,\n",
    "                            shuffle=shuffle, drop_last=drop_last)\n",
    "\n",
    "    for data_dict in dataloader:\n",
    "        out_data_dict = {}\n",
    "        for name, tensor in data_dict.items():\n",
    "            out_data_dict[name] = data_dict[name].to(device)\n",
    "        yield out_data_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "275d4140",
   "metadata": {},
   "source": [
    "## 3.1 Dataset Class\n",
    "### - The Dataset class characterizes the key features of the dataset you want to generate.\n",
    "### - The class uses \\_\\_init\\_\\_(), \\_\\_len\\_\\_(), and \\_\\_getitem\\_\\_() to store important information, and generate samples. \n",
    "### - The Dataset class is an important argument of the DataLoader class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "9cb9f686",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data: {'x1': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12], 'x2': [13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24], 'y': [0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0]}\n",
      "------------------------------------------------------------\n",
      "df:     x1  x2  y\n",
      "0    1  13  0\n",
      "1    2  14  1\n",
      "2    3  15  0\n",
      "3    4  16  1\n",
      "4    5  17  1\n",
      "5    6  18  0\n",
      "6    7  19  0\n",
      "7    8  20  1\n",
      "8    9  21  1\n",
      "9   10  22  0\n",
      "10  11  23  1\n",
      "11  12  24  0\n"
     ]
    }
   ],
   "source": [
    "data = {'x1': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12],\n",
    "        'x2': [13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24],\n",
    "        'y': [0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0]}\n",
    "data\n",
    "df = pd.DataFrame(data)\n",
    "print(\"data:\" ,data)\n",
    "print(\"-\"*60)\n",
    "print(\"df:\",df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ffe2a0dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 0\n",
      "[tensor([[ 1., 13.],\n",
      "        [ 2., 14.],\n",
      "        [ 3., 15.]]), tensor([0., 1., 0.])]\n",
      "------------------------------------------------------------\n",
      "Batch 1\n",
      "[tensor([[ 4., 16.],\n",
      "        [ 5., 17.],\n",
      "        [ 6., 18.]]), tensor([1., 1., 0.])]\n",
      "------------------------------------------------------------\n",
      "Batch 2\n",
      "[tensor([[ 7., 19.],\n",
      "        [ 8., 20.],\n",
      "        [ 9., 21.]]), tensor([0., 1., 1.])]\n",
      "------------------------------------------------------------\n",
      "Batch 3\n",
      "[tensor([[10., 22.],\n",
      "        [11., 23.],\n",
      "        [12., 24.]]), tensor([0., 1., 0.])]\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "##### Define Dataset class\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, dataframe):\n",
    "        self.data = dataframe\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        sample = torch.tensor(self.data.iloc[index, :-1].values, dtype=torch.float32)\n",
    "        target = torch.tensor(self.data.iloc[index, -1], dtype=torch.float32)\n",
    "        return sample, target\n",
    "\n",
    "##### Instantiate the Dataset class\n",
    "custom_dataset = CustomDataset(df)\n",
    "\n",
    "##### Instantiate the DataLoader class\n",
    "batch_size  = 3\n",
    "data_loader = DataLoader(dataset=custom_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "##### Obtain the batch\n",
    "i = 0\n",
    "for batch in data_loader:\n",
    "    print('Batch '+str(i))\n",
    "    i+=1\n",
    "    print(batch)\n",
    "    print('-' * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c38c885a",
   "metadata": {},
   "source": [
    "### An alternative is to use TensorDataset() directly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "6bbc1fcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e3828382",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x1: tensor([ 1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10., 11., 12.])\n",
      "x2: tensor([13., 14., 15., 16., 17., 18., 19., 20., 21., 22., 23., 24.])\n",
      "y: tensor([0., 1., 0., 1., 1., 0., 0., 1., 1., 0., 1., 0.])\n"
     ]
    }
   ],
   "source": [
    "x1 = torch.from_numpy(df['x1'].values).float()\n",
    "x2 = torch.from_numpy(df['x2'].values).float()\n",
    "y  = torch.from_numpy(df['y'].values).float()\n",
    "print(\"x1:\", x1)\n",
    "print(\"x2:\", x2)\n",
    "print(\"y:\", y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "0989dcbc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1., 13.],\n",
       "        [ 2., 14.],\n",
       "        [ 3., 15.],\n",
       "        [ 4., 16.],\n",
       "        [ 5., 17.],\n",
       "        [ 6., 18.],\n",
       "        [ 7., 19.],\n",
       "        [ 8., 20.],\n",
       "        [ 9., 21.],\n",
       "        [10., 22.],\n",
       "        [11., 23.],\n",
       "        [12., 24.]])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = torch.stack([x1, x2], dim=1)\n",
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "bb029abb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 0\n",
      "[tensor([[ 1., 13.],\n",
      "        [ 2., 14.],\n",
      "        [ 3., 15.]]), tensor([0., 1., 0.])]\n",
      "------------------------------------------------------------\n",
      "Batch 1\n",
      "[tensor([[ 4., 16.],\n",
      "        [ 5., 17.],\n",
      "        [ 6., 18.]]), tensor([1., 1., 0.])]\n",
      "------------------------------------------------------------\n",
      "Batch 2\n",
      "[tensor([[ 7., 19.],\n",
      "        [ 8., 20.],\n",
      "        [ 9., 21.]]), tensor([0., 1., 1.])]\n",
      "------------------------------------------------------------\n",
      "Batch 3\n",
      "[tensor([[10., 22.],\n",
      "        [11., 23.],\n",
      "        [12., 24.]]), tensor([0., 1., 0.])]\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "##### Create Tensor dataset\n",
    "dataset     = TensorDataset(features, y)\n",
    "batch_size  = 3\n",
    "\n",
    "##### Instantiate the DataLoader class\n",
    "data_loader = DataLoader(dataset=dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "##### Obtain the batch\n",
    "i = 0\n",
    "for batch in data_loader:\n",
    "    print('Batch '+str(i))\n",
    "    i+=1\n",
    "    print(batch)\n",
    "    print('-' * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dace0dd4",
   "metadata": {},
   "source": [
    "### The two methods below are equivalent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d431af5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1., 13.],\n",
       "        [ 2., 14.],\n",
       "        [ 3., 15.],\n",
       "        [ 4., 16.],\n",
       "        [ 5., 17.],\n",
       "        [ 6., 18.],\n",
       "        [ 7., 19.],\n",
       "        [ 8., 20.],\n",
       "        [ 9., 21.],\n",
       "        [10., 22.],\n",
       "        [11., 23.],\n",
       "        [12., 24.]])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x1 = torch.from_numpy(df['x1'].values).float()\n",
    "x2 = torch.from_numpy(df['x2'].values).float()\n",
    "torch.stack([x1, x2], dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "724eebb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1, 13],\n",
       "        [ 2, 14],\n",
       "        [ 3, 15],\n",
       "        [ 4, 16],\n",
       "        [ 5, 17],\n",
       "        [ 6, 18],\n",
       "        [ 7, 19],\n",
       "        [ 8, 20],\n",
       "        [ 9, 21],\n",
       "        [10, 22],\n",
       "        [11, 23],\n",
       "        [12, 24]])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numpy_array = df[['x1', 'x2']].to_numpy()\n",
    "torch.from_numpy(numpy_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d42d5cc0",
   "metadata": {},
   "source": [
    "## 3.2 DataLoader\n",
    "### - batch_size: denotes the number of samples contained in each generated batch.\n",
    "### - shuffle: if set to True, we will get a new order of exploration at each pass (or just keep a linear exploration scheme otherwise). Shuffling the order in which examples are fed to the classifier is helpful so that batches between epochs do not look alike. Doing so will eventually make our model more robust.\n",
    "### - drop_last: set to True to drop the last incomplete batch, if the dataset size is not divisible by the batch size. If False and the size of dataset is not divisible by the batch size, then the last batch will be smaller. (default: False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "47cf3dc6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(dataset_sample[0]['x_data'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "b2fda99b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_sample = ReviewDataset.load_df_and_make_vectorizer(df_sample,50)\n",
    "batch_size     = 10\n",
    "shuffle        = True\n",
    "drop_last      = True\n",
    "dataloader     = DataLoader(dataset=dataset_sample, batch_size=batch_size,\n",
    "                            shuffle=shuffle, drop_last=drop_last)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "1ac53c3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x in one batch\n",
      "tensor([[1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 0., 0., 0., 0.,\n",
      "         1., 1., 0., 0., 0., 1., 0., 1., 0., 0.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 0., 1., 0., 1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0.,\n",
      "         1., 1., 1., 1., 0., 1., 1., 1., 1., 0.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 0.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 0., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 0., 1., 0., 0., 1., 0.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         0., 1., 1., 1., 1., 1., 1., 0., 1., 0.],\n",
      "        [1., 0., 1., 0., 1., 1., 0., 1., 0., 0., 1., 1., 0., 0., 0., 1., 0., 0.,\n",
      "         1., 0., 1., 1., 0., 1., 1., 0., 1., 0.],\n",
      "        [1., 0., 1., 0., 1., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 1., 1., 1.,\n",
      "         0., 0., 1., 0., 0., 0., 0., 0., 1., 0.]])\n",
      "size of x_data: torch.Size([10, 28])\n",
      "------------------------------------------------------------\n",
      "y in one batch\n",
      "tensor([1, 0, 0, 1, 0, 0, 1, 0, 1, 1])\n",
      "size of y_data: torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "one_batch = next(iter(dataloader))\n",
    "print('x in one batch')\n",
    "print(one_batch['x_data'])\n",
    "print('size of x_data:', one_batch['x_data'].shape)\n",
    "print('-' * 60)\n",
    "print('y in one batch')\n",
    "print(one_batch['y_target'])\n",
    "print('size of y_data:', one_batch['y_target'].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efe7622b",
   "metadata": {},
   "source": [
    "### In this example, dataloader utilizes the return from the \\_\\_getitem\\_\\_() method, which extracts related rows from the _target_df of dataset, with _target_size=65. Also, batch_size=10, and drop_last=True so there are 6 batches created (the last 5 rows are dropped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "37215098",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of rows in the target_df:  63\n",
      "number of rows in the target_df:  63\n",
      "The number of batches is: 6\n"
     ]
    }
   ],
   "source": [
    "print('number of rows in the target_df: ', len(dataset_sample._target_df))\n",
    "print('number of rows in the target_df: ', dataset_sample._target_size)\n",
    "print(\"The number of batches is:\",dataset_sample.get_num_batches(batch_size = 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "bcf58a3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 0\n",
      "{'x_data': tensor([[1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0.,\n",
      "         1., 1., 1., 1., 1., 1., 0., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 0., 1., 1.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "        [1., 0., 1., 0., 1., 0., 1., 1., 0., 0., 1., 0., 1., 0., 1., 0., 0., 1.,\n",
      "         1., 1., 0., 1., 0., 1., 0., 1., 0., 1.],\n",
      "        [1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0.,\n",
      "         0., 0., 0., 1., 1., 0., 0., 0., 0., 1.],\n",
      "        [1., 1., 1., 0., 1., 1., 0., 1., 1., 0., 0., 1., 1., 0., 1., 1., 0., 1.,\n",
      "         1., 0., 0., 0., 0., 0., 1., 1., 0., 0.],\n",
      "        [1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 0., 1., 1., 1., 0., 1., 0.,\n",
      "         1., 1., 0., 0., 0., 1., 0., 0., 1., 1.],\n",
      "        [1., 1., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1.,\n",
      "         1., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 0., 1., 0., 1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 0., 1., 1., 1., 0., 0., 1., 0., 0., 1., 1., 0., 0., 1., 0.,\n",
      "         1., 1., 0., 1., 0., 1., 0., 0., 0., 1.]]), 'y_target': tensor([1, 0, 1, 0, 1, 0, 0, 0, 0, 0])}\n",
      "torch.Size([10, 28])\n",
      "------------------------------------------------------------\n",
      "Batch 1\n",
      "{'x_data': tensor([[1., 0., 1., 0., 1., 1., 0., 1., 0., 0., 1., 0., 1., 0., 0., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 0., 1., 0., 1., 0., 0.],\n",
      "        [1., 0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 1., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [1., 0., 1., 1., 1., 1., 0., 1., 0., 1., 0., 0., 1., 1., 0., 1., 1., 0.,\n",
      "         0., 1., 1., 1., 1., 1., 0., 0., 1., 0.],\n",
      "        [1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 0., 0., 0., 1., 1., 0., 0., 0.],\n",
      "        [1., 0., 1., 1., 0., 0., 1., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
      "         1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 0., 0., 0., 0.,\n",
      "         1., 1., 0., 0., 0., 1., 0., 1., 0., 0.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         0., 1., 1., 1., 1., 1., 1., 0., 1., 0.],\n",
      "        [1., 0., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 1., 0.]]), 'y_target': tensor([0, 0, 0, 1, 1, 0, 0, 1, 0, 0])}\n",
      "torch.Size([10, 28])\n",
      "------------------------------------------------------------\n",
      "Batch 2\n",
      "{'x_data': tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1.,\n",
      "         1., 1., 1., 0., 1., 1., 1., 1., 1., 1.],\n",
      "        [1., 0., 1., 0., 1., 1., 1., 1., 0., 0., 0., 1., 1., 0., 1., 1., 1., 1.,\n",
      "         1., 0., 1., 1., 0., 1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 0., 0., 1., 0., 1.,\n",
      "         1., 0., 0., 0., 0., 1., 0., 0., 1., 0.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 0., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0.,\n",
      "         1., 1., 1., 1., 0., 1., 1., 1., 1., 0.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 0., 1., 0., 1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 0., 1., 1., 1., 1., 0., 0., 0., 0., 1., 1., 0., 1., 1., 0.,\n",
      "         1., 0., 0., 0., 1., 1., 1., 1., 0., 0.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 0., 1., 0., 0., 1., 0.],\n",
      "        [1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 0.,\n",
      "         0., 1., 1., 1., 1., 1., 1., 0., 1., 1.]]), 'y_target': tensor([0, 1, 0, 0, 0, 0, 0, 1, 1, 1])}\n",
      "torch.Size([10, 28])\n",
      "------------------------------------------------------------\n",
      "Batch 3\n",
      "{'x_data': tensor([[1., 0., 1., 0., 1., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 1., 1., 1.,\n",
      "         0., 0., 1., 0., 0., 0., 0., 0., 1., 0.],\n",
      "        [1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0., 0., 1., 1., 1., 0., 1., 1.,\n",
      "         1., 1., 1., 1., 0., 1., 0., 1., 0., 0.],\n",
      "        [1., 0., 1., 1., 1., 1., 1., 0., 0., 0., 1., 0., 1., 0., 1., 0., 0., 1.,\n",
      "         0., 1., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
      "        [1., 0., 1., 0., 1., 0., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 0., 1., 0., 0., 0., 0., 1., 0., 0.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 1., 1., 1., 0., 0., 1.,\n",
      "         1., 1., 1., 0., 0., 1., 1., 1., 0., 1.],\n",
      "        [1., 0., 1., 0., 1., 1., 0., 1., 0., 0., 1., 1., 0., 0., 0., 1., 0., 0.,\n",
      "         1., 0., 1., 1., 0., 1., 1., 0., 1., 0.],\n",
      "        [1., 0., 1., 1., 1., 1., 0., 1., 0., 0., 1., 0., 1., 1., 1., 1., 0., 0.,\n",
      "         0., 0., 1., 1., 1., 0., 0., 0., 0., 0.],\n",
      "        [1., 1., 0., 0., 1., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 1., 0., 1., 0., 1., 0., 0., 0., 0.],\n",
      "        [1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 0., 1., 1., 1., 1., 1., 0., 1., 1.],\n",
      "        [1., 1., 1., 1., 1., 1., 0., 0., 1., 0., 0., 0., 0., 1., 0., 1., 1., 0.,\n",
      "         0., 0., 1., 0., 1., 1., 0., 0., 0., 1.]]), 'y_target': tensor([1, 0, 1, 1, 0, 1, 1, 1, 0, 0])}\n",
      "torch.Size([10, 28])\n",
      "------------------------------------------------------------\n",
      "Batch 4\n",
      "{'x_data': tensor([[1., 0., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1.,\n",
      "         0., 0., 0., 0., 1., 1., 1., 0., 0., 1.],\n",
      "        [1., 0., 1., 1., 1., 0., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 0., 1., 0., 0., 1., 1., 1., 1., 1.],\n",
      "        [1., 1., 0., 0., 1., 1., 1., 0., 1., 0., 1., 0., 1., 0., 0., 1., 0., 0.,\n",
      "         0., 1., 0., 1., 1., 1., 0., 1., 1., 1.],\n",
      "        [1., 0., 1., 1., 1., 1., 1., 1., 0., 0., 1., 0., 1., 0., 1., 0., 1., 0.,\n",
      "         1., 0., 1., 1., 1., 1., 0., 0., 0., 0.],\n",
      "        [1., 0., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0.,\n",
      "         0., 0., 1., 1., 1., 0., 0., 0., 1., 0.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 0.],\n",
      "        [1., 0., 1., 1., 1., 1., 0., 1., 0., 0., 1., 0., 1., 1., 0., 0., 1., 1.,\n",
      "         0., 0., 0., 1., 1., 0., 0., 0., 1., 0.],\n",
      "        [1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 0., 1., 1., 1.,\n",
      "         1., 1., 1., 0., 1., 1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 0., 0., 1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 0., 0., 1., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 1., 0.]]), 'y_target': tensor([1, 0, 0, 1, 1, 1, 1, 0, 1, 0])}\n",
      "torch.Size([10, 28])\n",
      "------------------------------------------------------------\n",
      "Batch 5\n",
      "{'x_data': tensor([[1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 1., 0., 0., 0., 1., 0.],\n",
      "        [1., 0., 1., 1., 1., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 1., 1., 1., 1., 0., 0., 0.],\n",
      "        [1., 0., 1., 0., 0., 1., 1., 1., 0., 0., 0., 0., 1., 0., 1., 0., 1., 0.,\n",
      "         0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
      "        [1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0.,\n",
      "         0., 0., 1., 1., 0., 1., 1., 1., 1., 0.],\n",
      "        [1., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 1., 1., 0.,\n",
      "         0., 1., 0., 0., 1., 1., 1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "        [1., 0., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0.,\n",
      "         1., 1., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
      "        [1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1., 0., 0., 1., 1., 0.,\n",
      "         1., 1., 0., 0., 0., 1., 0., 0., 1., 0.],\n",
      "        [1., 0., 1., 1., 1., 0., 0., 1., 0., 0., 1., 1., 1., 1., 1., 0., 1., 0.,\n",
      "         1., 1., 1., 0., 1., 0., 0., 0., 0., 0.],\n",
      "        [1., 0., 1., 0., 1., 1., 1., 1., 0., 1., 0., 1., 1., 0., 0., 1., 0., 1.,\n",
      "         1., 1., 1., 0., 0., 1., 1., 1., 1., 1.]]), 'y_target': tensor([1, 0, 0, 1, 1, 0, 1, 0, 1, 1])}\n",
      "torch.Size([10, 28])\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "for data_dict in dataloader:\n",
    "    print('Batch '+str(i))\n",
    "    i+=1\n",
    "    print(data_dict)\n",
    "    print(data_dict['x_data'].shape)\n",
    "    print('-' * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2433c26",
   "metadata": {},
   "source": [
    "### This is equvalent to defining and using the generator function generate_batches()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "b396fd0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 0\n",
      "{'x_data': tensor([[1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0.,\n",
      "         1., 1., 1., 1., 0., 1., 1., 1., 1., 0.],\n",
      "        [1., 0., 1., 1., 1., 0., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 0., 1., 0., 0., 1., 1., 1., 1., 1.],\n",
      "        [1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "        [1., 0., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 0., 1., 1.],\n",
      "        [1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 1., 0., 0., 0., 1., 0.],\n",
      "        [1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0.,\n",
      "         1., 1., 1., 1., 1., 1., 0., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 0., 0., 0., 1., 1., 0., 0., 0.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 0., 1., 0., 0., 1., 0.]]), 'y_target': tensor([0, 0, 1, 0, 0, 1, 1, 1, 0, 1])}\n",
      "torch.Size([10, 28])\n",
      "------------------------------------------------------------\n",
      "Batch 1\n",
      "{'x_data': tensor([[1., 1., 1., 1., 1., 1., 0., 0., 1., 0., 0., 0., 0., 1., 0., 1., 1., 0.,\n",
      "         0., 0., 1., 0., 1., 1., 0., 0., 0., 1.],\n",
      "        [1., 0., 1., 1., 1., 1., 0., 1., 0., 1., 0., 0., 1., 1., 0., 1., 1., 0.,\n",
      "         0., 1., 1., 1., 1., 1., 0., 0., 1., 0.],\n",
      "        [1., 0., 1., 1., 1., 1., 0., 1., 0., 0., 1., 0., 1., 1., 0., 0., 1., 1.,\n",
      "         0., 0., 0., 1., 1., 0., 0., 0., 1., 0.],\n",
      "        [1., 0., 1., 0., 1., 1., 0., 1., 0., 0., 1., 0., 1., 0., 0., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 0., 1., 0., 1., 0., 0.],\n",
      "        [1., 0., 1., 1., 1., 1., 1., 0., 0., 0., 1., 0., 1., 0., 1., 0., 0., 1.,\n",
      "         0., 1., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
      "        [1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 0., 1., 1., 1., 0., 1., 0.,\n",
      "         1., 1., 0., 0., 0., 1., 0., 0., 1., 1.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         0., 1., 1., 1., 1., 1., 1., 0., 1., 0.],\n",
      "        [1., 0., 1., 1., 0., 0., 1., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
      "         1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [1., 1., 1., 0., 1., 1., 1., 0., 0., 1., 0., 0., 1., 1., 0., 0., 1., 0.,\n",
      "         1., 1., 0., 1., 0., 1., 0., 0., 0., 1.],\n",
      "        [1., 1., 1., 0., 1., 1., 1., 1., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.,\n",
      "         1., 0., 1., 1., 0., 1., 0., 1., 0., 1.]]), 'y_target': tensor([0, 1, 1, 0, 1, 0, 0, 0, 0, 0])}\n",
      "torch.Size([10, 28])\n",
      "------------------------------------------------------------\n",
      "Batch 2\n",
      "{'x_data': tensor([[1., 1., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1.,\n",
      "         1., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [1., 1., 1., 0., 1., 1., 0., 1., 1., 0., 0., 1., 1., 0., 1., 1., 0., 1.,\n",
      "         1., 0., 0., 0., 0., 0., 1., 1., 0., 0.],\n",
      "        [1., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 1., 1., 0.,\n",
      "         0., 1., 0., 0., 1., 1., 1., 0., 1., 1.],\n",
      "        [1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1., 0., 0., 1., 1., 0.,\n",
      "         1., 1., 0., 0., 0., 1., 0., 0., 1., 0.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1.,\n",
      "         1., 1., 1., 0., 1., 1., 1., 1., 1., 1.],\n",
      "        [1., 0., 1., 0., 1., 1., 1., 1., 0., 0., 0., 1., 1., 0., 1., 1., 1., 1.,\n",
      "         1., 0., 1., 1., 0., 1., 1., 1., 1., 1.],\n",
      "        [1., 0., 1., 0., 1., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 1., 1., 1.,\n",
      "         0., 0., 1., 0., 0., 0., 0., 0., 1., 0.],\n",
      "        [1., 1., 1., 0., 1., 1., 1., 1., 0., 0., 0., 0., 1., 1., 0., 1., 1., 0.,\n",
      "         1., 0., 0., 0., 1., 1., 1., 1., 0., 0.],\n",
      "        [1., 0., 1., 1., 1., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 1., 1., 1., 1., 0., 0., 0.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 0.]]), 'y_target': tensor([0, 0, 1, 0, 0, 1, 1, 1, 0, 1])}\n",
      "torch.Size([10, 28])\n",
      "------------------------------------------------------------\n",
      "Batch 3\n",
      "{'x_data': tensor([[1., 1., 1., 0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 0., 0., 1., 0., 1.,\n",
      "         1., 0., 0., 0., 0., 1., 0., 0., 1., 0.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 0., 1., 1.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 0., 1., 0., 1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 0., 0., 1., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
      "        [1., 0., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0.,\n",
      "         1., 1., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
      "        [1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 0., 1., 1., 1.,\n",
      "         1., 1., 1., 0., 1., 1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0.,\n",
      "         0., 0., 1., 1., 0., 1., 1., 1., 1., 0.],\n",
      "        [1., 0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 1., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
      "        [1., 0., 1., 0., 1., 0., 1., 1., 0., 0., 1., 0., 1., 0., 1., 0., 0., 1.,\n",
      "         1., 1., 0., 1., 0., 1., 0., 1., 0., 1.]]), 'y_target': tensor([0, 0, 0, 0, 0, 1, 0, 1, 0, 0])}\n",
      "torch.Size([10, 28])\n",
      "------------------------------------------------------------\n",
      "Batch 4\n",
      "{'x_data': tensor([[1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 0., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "        [1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "        [1., 0., 1., 0., 1., 0., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 0., 1., 0., 0., 0., 0., 1., 0., 0.],\n",
      "        [1., 0., 1., 0., 1., 1., 1., 1., 0., 1., 0., 1., 1., 0., 0., 1., 0., 1.,\n",
      "         1., 1., 1., 0., 0., 1., 1., 1., 1., 1.],\n",
      "        [1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 0., 0., 0., 0.,\n",
      "         1., 1., 0., 0., 0., 1., 0., 1., 0., 0.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 1., 1., 1., 0., 0., 1.,\n",
      "         1., 1., 1., 0., 0., 1., 1., 1., 0., 1.],\n",
      "        [1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 0., 1., 1., 1., 1., 1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1.,\n",
      "         0., 0., 0., 0., 1., 1., 1., 0., 0., 1.],\n",
      "        [1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0.,\n",
      "         0., 0., 0., 1., 1., 0., 0., 0., 0., 1.]]), 'y_target': tensor([0, 1, 1, 1, 1, 0, 0, 1, 0, 1])}\n",
      "torch.Size([10, 28])\n",
      "------------------------------------------------------------\n",
      "Batch 5\n",
      "{'x_data': tensor([[1., 0., 1., 0., 1., 1., 0., 1., 0., 0., 1., 1., 0., 0., 0., 1., 0., 0.,\n",
      "         1., 0., 1., 1., 0., 1., 1., 0., 1., 0.],\n",
      "        [1., 0., 1., 1., 1., 0., 0., 1., 0., 0., 1., 1., 1., 1., 1., 0., 1., 0.,\n",
      "         1., 1., 1., 0., 1., 0., 0., 0., 0., 0.],\n",
      "        [1., 0., 1., 1., 1., 1., 0., 1., 0., 0., 1., 0., 1., 1., 1., 1., 0., 0.,\n",
      "         0., 0., 1., 1., 1., 0., 0., 0., 0., 0.],\n",
      "        [1., 0., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0.,\n",
      "         0., 0., 1., 1., 1., 0., 0., 0., 1., 0.],\n",
      "        [1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 0., 0., 1., 1., 1., 1., 1.],\n",
      "        [1., 1., 0., 0., 1., 1., 1., 0., 1., 0., 1., 0., 1., 0., 0., 1., 0., 0.,\n",
      "         0., 1., 0., 1., 1., 1., 0., 1., 1., 1.],\n",
      "        [1., 1., 0., 0., 1., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 1., 0., 1., 0., 1., 0., 0., 0., 0.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 0., 1., 0., 1., 1., 1., 1., 1.],\n",
      "        [1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 0.,\n",
      "         0., 1., 1., 1., 1., 1., 1., 0., 1., 1.]]), 'y_target': tensor([1, 1, 1, 1, 1, 0, 1, 0, 0, 1])}\n",
      "torch.Size([10, 28])\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "for data_dict in dataloader:\n",
    "    print('Batch '+str(i))\n",
    "    i+=1\n",
    "    print(data_dict)\n",
    "    print(data_dict['x_data'].shape)\n",
    "    print('-' * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd0743de",
   "metadata": {},
   "source": [
    "## 3.3 Generator\n",
    "### - Generator functions declare a function that behaves like an iterator, i.e. it can be used in a for loop.\n",
    "### - A generator function is defined just like a normal function, but whenever it needs to generate a value, it does so with the yield keyword rather than return. \n",
    "### - Yield is used in Python generators. If the body of a def contains yield, the function automatically becomes a generator function. \n",
    "### - *return* sends a specified value back to its caller whereas *yield* can produce a sequence of values. We should use *yield* when we want to iterate over a sequence, but don’t want to store the entire sequence in memory."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "372a01ec",
   "metadata": {},
   "source": [
    "### Consider a task to calculate the sum of the first n integers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "c313379f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4950"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##### The function below builds the full list in memory\n",
    "def first_n(n):\n",
    "    num, nums = 0, []\n",
    "    while num < n:\n",
    "        nums.append(num)\n",
    "        num += 1\n",
    "    return nums\n",
    "sum(first_n(100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "ac676abf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vars(a): {'n': 10, 'num': 0}\n",
      "sum(a): 45\n"
     ]
    }
   ],
   "source": [
    "##### The following implements generator as an iterable object.\n",
    "class first_n(object):\n",
    "\n",
    "    def __init__(self, n):\n",
    "        self.n = n\n",
    "        self.num = 0\n",
    "\n",
    "    def __iter__(self):\n",
    "        return self\n",
    "\n",
    "    # Python 3 compatibility\n",
    "    def __next__(self):\n",
    "        return self.next()\n",
    "\n",
    "    def next(self):\n",
    "        if self.num < self.n:\n",
    "            cur, self.num = self.num, self.num+1\n",
    "            return cur\n",
    "        raise StopIteration\n",
    "        \n",
    "a = first_n(10)\n",
    "print('vars(a):', vars(a))\n",
    "print('sum(a):', sum(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "55b34e8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "next(a): 0\n",
      "sum(a): 45\n",
      "next(a): None\n"
     ]
    }
   ],
   "source": [
    "##### a generator that yields items instead of returning a list\n",
    "\n",
    "def first_n(n):\n",
    "    num = 0\n",
    "    while num < n:\n",
    "        yield num\n",
    "        num += 1\n",
    "\n",
    "a = first_n(10)\n",
    "\n",
    "print('next(a):', next(a))\n",
    "print('sum(a):', sum(a))\n",
    "##### If the generator has already produced all its values, calling next() \n",
    "##### again will raise a StopIteration exception, indicating that the \n",
    "##### generator has been exhausted. use next(generator, default) to \n",
    "##### provide a default value, avoiding the occurrence of an exception.\n",
    "print('next(a):', next(a,None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "8999326e",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Now next(a) = None so the code will not print anything \n",
    "for i in a:\n",
    "    print (i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "c06edf5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "##### using a new generator\n",
    "for i in first_n(10):\n",
    "    print (i)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
