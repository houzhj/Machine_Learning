{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fddef8d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import collections\n",
    "from collections import Counter\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2a2f0873",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all = pd.read_csv(\"reviews_with_splits_lite.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c5e82b8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of the data:  (56000, 3)\n",
      "------------------------------------------------------------\n",
      "     rating                                             review  split\n",
      "0  negative  terrible place to work for i just heard a stor...  train\n",
      "1  negative   hours , minutes total time for an extremely s...  train\n",
      "2  negative  my less than stellar review is for service . w...  train\n",
      "3  negative  i m granting one star because there s no way t...  train\n",
      "4  negative  the food here is mediocre at best . i went aft...  train\n"
     ]
    }
   ],
   "source": [
    "print(\"shape of the data: \", df_all.shape)\n",
    "print('-'*60)\n",
    "print(df_all.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d804fc58",
   "metadata": {},
   "source": [
    "# 1. Vocabulary class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ebd1f64a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Vocabulary(object):\n",
    "    \n",
    "    def __init__(self, token_to_idx=None, add_unk=True, unk_token=\"<UNK>\"):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            token_to_idx (dict): a pre-existing map of tokens to indices\n",
    "            add_unk (bool): a flag that indicates whether to add the UNK token\n",
    "            unk_token (str): the UNK token to add into the Vocabulary\n",
    "        \"\"\"\n",
    "        if token_to_idx is None:\n",
    "            token_to_idx = {}\n",
    "        self._token_to_idx = token_to_idx\n",
    "        self._idx_to_token = {idx: token \n",
    "                              for token, idx in self._token_to_idx.items()}\n",
    "        \n",
    "        self._add_unk   = add_unk\n",
    "        self._unk_token = unk_token      \n",
    "        self.unk_index  = -999\n",
    "        ### the unk_token, i.e, \"<UNK>\" is the first added token if add_unk=True\n",
    "        ### self.unk_index is changed from -999 to 0\n",
    "        if add_unk:\n",
    "            self.unk_index = self.add_token(unk_token) \n",
    "\n",
    "    def add_token(self, token):\n",
    "        \"\"\"Update mapping dicts based on the token.\n",
    "\n",
    "        Args:\n",
    "            token (str): the item to add into the Vocabulary\n",
    "        Returns:\n",
    "            index (int): the integer corresponding to the token\n",
    "        \"\"\"\n",
    "        if token in self._token_to_idx:\n",
    "            index = self._token_to_idx[token]\n",
    "        else:\n",
    "            index = len(self._token_to_idx)\n",
    "            ### add a new element to _token_to_idx\n",
    "            self._token_to_idx[token] = index\n",
    "            ### add a new element to _idx_to_token\n",
    "            self._idx_to_token[index] = token\n",
    "        return index\n",
    "   \n",
    "    def lookup_token(self, token):\n",
    "        \"\"\"Retrieve the index associated with the token \n",
    "          or the UNK index if token isn't present.\n",
    "        \n",
    "        Args:\n",
    "            token (str): the token to look up \n",
    "        Returns:\n",
    "            index (int): the index corresponding to the token\n",
    "        Notes:\n",
    "            `unk_index` needs to be >=0 (having been added into the Vocabulary) \n",
    "              for the UNK functionality \n",
    "        \"\"\"\n",
    "        if self.unk_index >= 0:\n",
    "            ### .get(): return self.unk_index if the key \"token\" does not exist. \n",
    "            return self._token_to_idx.get(token, self.unk_index)\n",
    "        else:\n",
    "            return self._token_to_idx[token]\n",
    "    \n",
    "    def lookup_index(self, index):\n",
    "        \"\"\"Return the token associated with the index\n",
    "        \n",
    "        Args: \n",
    "            index (int): the index to look up\n",
    "        Returns:\n",
    "            token (str): the token corresponding to the index\n",
    "        Raises:\n",
    "            KeyError: if the index is not in the Vocabulary\n",
    "        \"\"\"\n",
    "        if index not in self._idx_to_token:\n",
    "            raise KeyError(\"the index (%d) is not in the Vocabulary\" % index)\n",
    "        return self._idx_to_token[index]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self._token_to_idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41ba2ede",
   "metadata": {},
   "source": [
    "# 2. Instantiate the Vocabulary from the training data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d40957aa",
   "metadata": {},
   "source": [
    "## (1) The vocabulary for the ratings - rating_vocab"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c270d79f",
   "metadata": {},
   "source": [
    "### The corpus of ratings - apparently, the vocabulary for the ratings is ['positive','negative']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "694a8632",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        negative\n",
       "1        negative\n",
       "2        negative\n",
       "3        negative\n",
       "4        negative\n",
       "           ...   \n",
       "55995    positive\n",
       "55996    positive\n",
       "55997    positive\n",
       "55998    positive\n",
       "55999    positive\n",
       "Name: rating, Length: 56000, dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all.rating"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80367acb",
   "metadata": {},
   "source": [
    "### Initializing rating_vocab.\n",
    "### The unk_token, i.e,  \"UNK\" (unknown word), is the first added token if add_unk=True. \n",
    "### After the initialization, there is only one token stored in the object - UNK, and the index of this token in rating_vocab is 0 (changed from -999 to 0). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b322bc24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'_token_to_idx': {'<UNK>': 0},\n",
       " '_idx_to_token': {0: '<UNK>'},\n",
       " '_add_unk': True,\n",
       " '_unk_token': '<UNK>',\n",
       " 'unk_index': 0}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rating_vocab = Vocabulary(add_unk=True)\n",
    "vars(rating_vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5446e44",
   "metadata": {},
   "source": [
    "### Add tokens appear in the ratings to rating_vocab. \n",
    "### Actually there are only two tokens in the corpus of ratings. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d4b6546b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['negative', 'positive']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(set(df_all.rating))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f88bea55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'_token_to_idx': {'<UNK>': 0, 'negative': 1, 'positive': 2},\n",
       " '_idx_to_token': {0: '<UNK>', 1: 'negative', 2: 'positive'},\n",
       " '_add_unk': True,\n",
       " '_unk_token': '<UNK>',\n",
       " 'unk_index': 0}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rating_vocab = Vocabulary(add_unk=True)\n",
    "for rating in sorted(set(df_all.rating)):\n",
    "    rating_vocab.add_token(rating)\n",
    "vars(rating_vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af07dc34",
   "metadata": {},
   "source": [
    "## (2) The vocabulary for the reviews"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80af11a3",
   "metadata": {},
   "source": [
    "### The corpus - the difference between reviews and ratings is that the corpus for the reviews includes much more words (tokens) than that for the reviews. \n",
    "### So there is one additional step for creating the vocabulary for reviews - couting the tokens appeared in the reviews, and add frequent tokens that apprear more than a pre-specified number to review_vocab, while treat infrequent tokens as UNK."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "42de8ea3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        terrible place to work for i just heard a stor...\n",
       "1         hours , minutes total time for an extremely s...\n",
       "2        my less than stellar review is for service . w...\n",
       "3        i m granting one star because there s no way t...\n",
       "4        the food here is mediocre at best . i went aft...\n",
       "                               ...                        \n",
       "55995    great food . wonderful , friendly service . i ...\n",
       "55996    charlotte should be the new standard for moder...\n",
       "55997    get the encore sandwich ! ! make sure to get i...\n",
       "55998    i m a pretty big ice cream gelato fan . pretty...\n",
       "55999    where else can you find all the parts and piec...\n",
       "Name: review, Length: 56000, dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all.review"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74b45019",
   "metadata": {},
   "source": [
    "### Initializing rating_vocab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8b6a7413",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'_token_to_idx': {'<UNK>': 0},\n",
       " '_idx_to_token': {0: '<UNK>'},\n",
       " '_add_unk': True,\n",
       " '_unk_token': '<UNK>',\n",
       " 'unk_index': 0}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review_vocab = Vocabulary(add_unk=True)\n",
    "vars(review_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "adb3e839",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_counts=Counter()\n",
    "for review in df_all.review:\n",
    "    for word in review.split(\" \"):\n",
    "        if word not in string.punctuation:\n",
    "            word_counts[word] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "de9f2bb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The 20 most frequent words\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('the', 339990),\n",
       " ('and', 231288),\n",
       " ('i', 225732),\n",
       " ('to', 185031),\n",
       " ('a', 179478),\n",
       " ('was', 117940),\n",
       " ('it', 106288),\n",
       " ('of', 103076),\n",
       " ('for', 83622),\n",
       " ('in', 82762),\n",
       " ('is', 82250),\n",
       " ('n', 75090),\n",
       " ('that', 73885),\n",
       " ('my', 70406),\n",
       " ('they', 61324),\n",
       " ('this', 58229),\n",
       " ('you', 57180),\n",
       " ('with', 53761),\n",
       " ('t', 52863),\n",
       " ('but', 52479)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"The 20 most frequent words\")\n",
    "word_counts.most_common(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d16f054a",
   "metadata": {},
   "source": [
    "### Only the token with more than 1000 (a pre-specified number) counts will be added to the vocabulary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3458b4fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "cut_off = 1000\n",
    "for word, count in word_counts.items():\n",
    "    if count > cut_off:\n",
    "        review_vocab.add_token(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "232e1de5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "When cut_off = 1000, 776 tokens added into review_vocab\n"
     ]
    }
   ],
   "source": [
    "print(f\"When cut_off = {cut_off}, {len(review_vocab._token_to_idx)} tokens added into review_vocab\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaadc1ca",
   "metadata": {},
   "source": [
    "### If cut_off = 10000, there are less tokens added to the review_vocab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "04c8b9ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "When cut_off = 10000, 104 tokens added into review_vocab\n"
     ]
    }
   ],
   "source": [
    "review_vocab = Vocabulary(add_unk=True)\n",
    "cut_off = 10000\n",
    "for word, count in word_counts.items():\n",
    "    if count > cut_off:\n",
    "        review_vocab.add_token(word)\n",
    "print(f\"When cut_off = {cut_off}, {len(review_vocab._token_to_idx)} tokens added into review_vocab\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93527692",
   "metadata": {},
   "source": [
    "# 3. Attributes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0537983",
   "metadata": {},
   "source": [
    "### ._token_to_idx: a mapping of index and token added to the Vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "39830ded",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Print out 20 tokens in the vocabulary\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('<UNK>', 0),\n",
       " ('place', 1),\n",
       " ('to', 2),\n",
       " ('for', 3),\n",
       " ('i', 4),\n",
       " ('just', 5),\n",
       " ('a', 6),\n",
       " ('of', 7),\n",
       " ('them', 8),\n",
       " ('over', 9),\n",
       " ('her', 10),\n",
       " ('in', 11),\n",
       " ('there', 12),\n",
       " ('she', 13),\n",
       " ('t', 14),\n",
       " ('said', 15),\n",
       " ('which', 16),\n",
       " ('and', 17),\n",
       " ('they', 18),\n",
       " ('the', 19)]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Print out 20 tokens in the vocabulary\")\n",
    "list(review_vocab._token_to_idx.items())[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7417ec4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Print a few elements in review_vocab._token_to_idx\n",
      "The index for \"place\" is 1\n",
      "The index for \"and\" is 17\n",
      "The index for \"follow\" is 0\n",
      "The index for \"good\" is 78\n"
     ]
    }
   ],
   "source": [
    "tokens  = ['place','and','follow','good']\n",
    "mapping = review_vocab._token_to_idx\n",
    "print(\"Print a few elements in review_vocab._token_to_idx\")\n",
    "for i in tokens:\n",
    "    print(f'The index for \"{i}\" is {mapping.get(i,0)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db5ad486",
   "metadata": {},
   "source": [
    "### ._idx_to_token: a mapping of index and token added to the Vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "64b0569c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Print out 20 tokens in the vocabulary\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(0, '<UNK>'),\n",
       " (1, 'place'),\n",
       " (2, 'to'),\n",
       " (3, 'for'),\n",
       " (4, 'i'),\n",
       " (5, 'just'),\n",
       " (6, 'a'),\n",
       " (7, 'of'),\n",
       " (8, 'them'),\n",
       " (9, 'over'),\n",
       " (10, 'her'),\n",
       " (11, 'in'),\n",
       " (12, 'there'),\n",
       " (13, 'she'),\n",
       " (14, 't'),\n",
       " (15, 'said'),\n",
       " (16, 'which'),\n",
       " (17, 'and'),\n",
       " (18, 'they'),\n",
       " (19, 'the')]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Print out 20 tokens in the vocabulary\")\n",
    "list(review_vocab._idx_to_token.items())[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c97b0252",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Print a few elements in review_vocab._idx_to_token\n",
      "The token for index=0 is <UNK>\n",
      "The token for index=2 is to\n",
      "The token for index=6 is a\n",
      "The token for index=100 is always\n"
     ]
    }
   ],
   "source": [
    "indices  = [0,2,6,100]\n",
    "mapping = review_vocab._idx_to_token\n",
    "print(\"Print a few elements in review_vocab._idx_to_token\")\n",
    "for i in indices:\n",
    "    print(f'The token for index={i} is {mapping.get(i,0)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c66cef5",
   "metadata": {},
   "source": [
    "# 4. Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f5cdc72",
   "metadata": {},
   "source": [
    "### add_token(token): Update mapping dicts based on the token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "40e60fe5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'_token_to_idx': {'<UNK>': 0},\n",
       " '_idx_to_token': {0: '<UNK>'},\n",
       " '_add_unk': True,\n",
       " '_unk_token': '<UNK>',\n",
       " 'unk_index': 0}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_vocab = Vocabulary(add_unk=True)\n",
    "vars(example_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "176db67a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Add one token apple\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'_token_to_idx': {'<UNK>': 0, 'apple': 1},\n",
       " '_idx_to_token': {0: '<UNK>', 1: 'apple'},\n",
       " '_add_unk': True,\n",
       " '_unk_token': '<UNK>',\n",
       " 'unk_index': 0}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_token = 'apple'\n",
    "example_vocab.add_token(new_token)\n",
    "print(f\"Add one token {new_token}\")\n",
    "print('-'*60)\n",
    "vars(example_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c1ce9533",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Add one token banana\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'_token_to_idx': {'<UNK>': 0, 'apple': 1, 'banana': 2},\n",
       " '_idx_to_token': {0: '<UNK>', 1: 'apple', 2: 'banana'},\n",
       " '_add_unk': True,\n",
       " '_unk_token': '<UNK>',\n",
       " 'unk_index': 0}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_token = 'banana'\n",
    "example_vocab.add_token(new_token)\n",
    "print(f\"Add one token {new_token}\")\n",
    "print('-'*60)\n",
    "vars(example_vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbec5871",
   "metadata": {},
   "source": [
    "### lookup_token(token): Retrieve the index associated with the token or the UNK index if token isn't present."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d1b5cb1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'_token_to_idx': {'<UNK>': 0},\n",
       " '_idx_to_token': {0: '<UNK>'},\n",
       " '_add_unk': True,\n",
       " '_unk_token': '<UNK>',\n",
       " 'unk_index': 0}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_vocab = Vocabulary(add_unk=True)\n",
    "vars(example_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7fe5e79a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "apple added\n",
      "banana added\n",
      "peach added\n",
      "orange added\n",
      "coconut added\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'_token_to_idx': {'<UNK>': 0,\n",
       "  'apple': 1,\n",
       "  'banana': 2,\n",
       "  'peach': 3,\n",
       "  'orange': 4,\n",
       "  'coconut': 5},\n",
       " '_idx_to_token': {0: '<UNK>',\n",
       "  1: 'apple',\n",
       "  2: 'banana',\n",
       "  3: 'peach',\n",
       "  4: 'orange',\n",
       "  5: 'coconut'},\n",
       " '_add_unk': True,\n",
       " '_unk_token': '<UNK>',\n",
       " 'unk_index': 0}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens_to_add = ['apple','banana','peach','orange','coconut']\n",
    "for i in tokens_to_add:\n",
    "    example_vocab.add_token(i)\n",
    "    print(i + ' added')\n",
    "vars(example_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7634d002",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The index for orange is 4\n",
      "The index for rice is 0\n"
     ]
    }
   ],
   "source": [
    "tokens_list = ['orange','rice']\n",
    "for i in tokens_list:\n",
    "    print(f\"The index for {i} is {example_vocab.lookup_token(i)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4d2166ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The index for orange is 4\n",
      "The index for rice is 0\n"
     ]
    }
   ],
   "source": [
    "### Equivalent codes\n",
    "for i in tokens_list:\n",
    "    print(f\"The index for {i} is {Vocabulary.lookup_token(example_vocab,i)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13f5e2f7",
   "metadata": {},
   "source": [
    "### lookup_index(index): Return the token associated with the index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fc06f521",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The token with index=1 is apple\n",
      "The token with index=4 is orange\n"
     ]
    }
   ],
   "source": [
    "indices_list = [1,4]\n",
    "for i in indices_list:\n",
    "    print(f\"The token with index={i} is {example_vocab.lookup_index(i)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9b8800d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The token with index=1 is apple\n",
      "The token with index=4 is orange\n"
     ]
    }
   ],
   "source": [
    "### Equivalent codes\n",
    "for i in indices_list:\n",
    "    print(f\"The token with index={i} is {Vocabulary.lookup_index(example_vocab,i)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28a1a705",
   "metadata": {},
   "source": [
    "### \\_\\_len\\_\\_(): Return the length of _token_to_idx (i.e, the number of tokens in the vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "84349006",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: '<UNK>', 1: 'token1', 2: 'token2', 3: 'token3', 4: 'token4'}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_vocab = Vocabulary(add_unk=True)\n",
    "tokens_to_add = ['token1','token2','token3','token4']\n",
    "for i in tokens_to_add:\n",
    "    example_vocab.add_token(i)\n",
    "example_vocab._idx_to_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "af5eee36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(example_vocab)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
