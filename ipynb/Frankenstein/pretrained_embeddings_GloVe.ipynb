{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":986425,"sourceType":"datasetVersion","datasetId":540042}],"dockerImageVersionId":30673,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport torch\nimport torch.nn as nn\nfrom annoy import AnnoyIndex\nimport numpy as np\nimport random\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\nembedding_file = '/kaggle/input/glove6b100dtxt/glove.6B.100d.txt'","metadata":{"execution":{"iopub.status.busy":"2024-05-08T14:26:52.592100Z","iopub.execute_input":"2024-05-08T14:26:52.592798Z","iopub.status.idle":"2024-05-08T14:26:57.497990Z","shell.execute_reply.started":"2024-05-08T14:26:52.592762Z","shell.execute_reply":"2024-05-08T14:26:57.496701Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":"# 1. PreTrainedEmbeddings class\n### Details are in the following subsections ","metadata":{}},{"cell_type":"code","source":"class PreTrainedEmbeddings(object):\n    \"\"\" A wrapper around pre-trained word vectors and their use \"\"\"\n    def __init__(self, word_to_index, word_vectors):\n        \"\"\"\n        Args:\n            word_to_index (dict): mapping from word to integers\n            word_vectors (list of numpy arrays)\n        \"\"\"\n        self.word_to_index = word_to_index\n        self.word_vectors  = word_vectors\n        self.index_to_word = {v: k for k, v in self.word_to_index.items()}\n\n        self.index = AnnoyIndex(len(word_vectors[0]), metric='euclidean')\n        print(\"Building Index!\")\n        for _, i in self.word_to_index.items():\n            self.index.add_item(i, self.word_vectors[i])\n        self.index.build(50)\n        print(\"Finished!\")\n        \n    @classmethod\n    def from_embeddings_file(cls, embedding_file):\n        \"\"\"Instantiate from pre-trained vector file.\n        Vector file should be of the format:\n            word0 x0_0 x0_1 x0_2 x0_3 ... x0_N\n            word1 x1_0 x1_1 x1_2 x1_3 ... x1_N\n        Args:\n            embedding_file (str): location of the file\n        Returns: \n            instance of PretrainedEmbeddigns\n        \"\"\"\n        word_to_index = {}\n        word_vectors = []\n\n        with open(embedding_file) as fp:\n            for line in fp.readlines():\n                line = line.split(\" \")\n                word = line[0]\n                vec = np.array([float(x) for x in line[1:]])\n                \n                word_to_index[word] = len(word_to_index)\n                word_vectors.append(vec)\n                \n        return cls(word_to_index, word_vectors)\n    \n    def get_embedding(self, word):\n        \"\"\"\n        Args:\n            word (str)\n        Returns\n            an embedding (numpy.ndarray)\n        \"\"\"\n        return self.word_vectors[self.word_to_index[word]]\n\n    def get_closest_to_vector(self, vector, n=1):\n        \"\"\"Given a vector, return its n nearest neighbors\n        \n        Args:\n            vector (np.ndarray): should match the size of the vectors \n                in the Annoy index\n            n (int): the number of neighbors to return\n        Returns:\n            [str, str, ...]: words that are nearest to the given vector. \n                The words are not ordered by distance \n        \"\"\"\n        nn_indices = self.index.get_nns_by_vector(vector, n)\n        return [self.index_to_word[neighbor] for neighbor in nn_indices]\n    \n    def compute_and_print_analogy(self, word1, word2, word3):\n        \"\"\"Prints the solutions to analogies using word embeddings\n\n        Analogies are word1 is to word2 as word3 is to __\n        This method will print: word1 : word2 :: word3 : word4\n        \n        Args:\n            word1 (str)\n            word2 (str)\n            word3 (str)\n        \"\"\"\n        vec1 = self.get_embedding(word1)\n        vec2 = self.get_embedding(word2)\n        vec3 = self.get_embedding(word3)\n\n        # now compute the fourth word's embedding!\n        spatial_relationship = vec2 - vec1\n        vec4 = vec3 + spatial_relationship\n\n        closest_words = self.get_closest_to_vector(vec4, n=4)\n        existing_words = set([word1, word2, word3])\n        closest_words = [word for word in closest_words \n                             if word not in existing_words] \n\n        if len(closest_words) == 0:\n            print(\"Could not find nearest neighbors for the computed vector!\")\n            return\n        \n        for word4 in closest_words:\n            print(\"{} : {} :: {} : {}\".format(word1, word2, word3, word4))","metadata":{"execution":{"iopub.status.busy":"2024-05-08T14:26:57.500286Z","iopub.execute_input":"2024-05-08T14:26:57.500790Z","iopub.status.idle":"2024-05-08T14:26:57.515992Z","shell.execute_reply.started":"2024-05-08T14:26:57.500754Z","shell.execute_reply":"2024-05-08T14:26:57.514674Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"## 1.1 \\_\\_init\\_\\_(self, word_to_index, word_vectors)\n### Read the pre-trained word embedding vectors from [Stanford’s GLoVe](https://nlp.stanford.edu/projects/glove/). \n### - GloVe, developed by Stanford, is an algorithm used for generating word embeddings, based on the Global Vectors model. GloVe (Global Vectors for Word Representation) is a word embedding model that represents words as high-dimensional vectors and encodes the semantic information of words into vector space.\n### - glove.6B.zip is a pre-trained version of the Stanford GloVe model. It is a word embedding model that has been trained on large-scale corpora and can be directly used for natural language processing (NLP) tasks such as word similarity calculation, text classification, sentiment analysis, etc. Pre-trained GloVe models typically include vector representations of millions of words, with each word corresponding to a high-dimensional vector. It has 6B tokens and a vocabulary of 400K words.\n### - The glove.6B.zip file in glove.6B.zip contains pre-trained vector files of the GloVe model. It includes the following files:\n**1. glove.6B.50d.txt: contains 50-dimensional word vectors** \n\n**2. glove.6B.100d.txt: contains 100-dimensional word vectors**\n\n**3. glove.6B.200d.txt: contains 200-dimensional word vectors**\n\n**4. glove.6B.300d.txt: contains 300-dimensional word vectors**\n### - Information\n**1. Number of tokens: 6B**\n\n**2. Number of words in the vocabulary: 400K**\n\n**3. Dimension of the representation: 50, 100, 200, 300 (100 is used below)**\n\n","metadata":{}},{"cell_type":"code","source":"### Print the first 3 lines in \"glove.6B.100d.txt\"\nwith open(embedding_file, 'r') as file:\n    for i in range(3):  \n        line = file.readline()\n        print(line)\n        print(type(line))","metadata":{"execution":{"iopub.status.busy":"2024-05-08T14:26:57.517488Z","iopub.execute_input":"2024-05-08T14:26:57.517897Z","iopub.status.idle":"2024-05-08T14:26:57.548335Z","shell.execute_reply.started":"2024-05-08T14:26:57.517859Z","shell.execute_reply":"2024-05-08T14:26:57.547244Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"the -0.038194 -0.24487 0.72812 -0.39961 0.083172 0.043953 -0.39141 0.3344 -0.57545 0.087459 0.28787 -0.06731 0.30906 -0.26384 -0.13231 -0.20757 0.33395 -0.33848 -0.31743 -0.48336 0.1464 -0.37304 0.34577 0.052041 0.44946 -0.46971 0.02628 -0.54155 -0.15518 -0.14107 -0.039722 0.28277 0.14393 0.23464 -0.31021 0.086173 0.20397 0.52624 0.17164 -0.082378 -0.71787 -0.41531 0.20335 -0.12763 0.41367 0.55187 0.57908 -0.33477 -0.36559 -0.54857 -0.062892 0.26584 0.30205 0.99775 -0.80481 -3.0243 0.01254 -0.36942 2.2167 0.72201 -0.24978 0.92136 0.034514 0.46745 1.1079 -0.19358 -0.074575 0.23353 -0.052062 -0.22044 0.057162 -0.15806 -0.30798 -0.41625 0.37972 0.15006 -0.53212 -0.2055 -1.2526 0.071624 0.70565 0.49744 -0.42063 0.26148 -1.538 -0.30223 -0.073438 -0.28312 0.37104 -0.25217 0.016215 -0.017099 -0.38984 0.87424 -0.72569 -0.51058 -0.52028 -0.1459 0.8278 0.27062\n\n<class 'str'>\n, -0.10767 0.11053 0.59812 -0.54361 0.67396 0.10663 0.038867 0.35481 0.06351 -0.094189 0.15786 -0.81665 0.14172 0.21939 0.58505 -0.52158 0.22783 -0.16642 -0.68228 0.3587 0.42568 0.19021 0.91963 0.57555 0.46185 0.42363 -0.095399 -0.42749 -0.16567 -0.056842 -0.29595 0.26037 -0.26606 -0.070404 -0.27662 0.15821 0.69825 0.43081 0.27952 -0.45437 -0.33801 -0.58184 0.22364 -0.5778 -0.26862 -0.20425 0.56394 -0.58524 -0.14365 -0.64218 0.0054697 -0.35248 0.16162 1.1796 -0.47674 -2.7553 -0.1321 -0.047729 1.0655 1.1034 -0.2208 0.18669 0.13177 0.15117 0.7131 -0.35215 0.91348 0.61783 0.70992 0.23955 -0.14571 -0.37859 -0.045959 -0.47368 0.2385 0.20536 -0.18996 0.32507 -1.1112 -0.36341 0.98679 -0.084776 -0.54008 0.11726 -1.0194 -0.24424 0.12771 0.013884 0.080374 -0.35414 0.34951 -0.7226 0.37549 0.4441 -0.99059 0.61214 -0.35111 -0.83155 0.45293 0.082577\n\n<class 'str'>\n. -0.33979 0.20941 0.46348 -0.64792 -0.38377 0.038034 0.17127 0.15978 0.46619 -0.019169 0.41479 -0.34349 0.26872 0.04464 0.42131 -0.41032 0.15459 0.022239 -0.64653 0.25256 0.043136 -0.19445 0.46516 0.45651 0.68588 0.091295 0.21875 -0.70351 0.16785 -0.35079 -0.12634 0.66384 -0.2582 0.036542 -0.13605 0.40253 0.14289 0.38132 -0.12283 -0.45886 -0.25282 -0.30432 -0.11215 -0.26182 -0.22482 -0.44554 0.2991 -0.85612 -0.14503 -0.49086 0.0082973 -0.17491 0.27524 1.4401 -0.21239 -2.8435 -0.27958 -0.45722 1.6386 0.78808 -0.55262 0.65 0.086426 0.39012 1.0632 -0.35379 0.48328 0.346 0.84174 0.098707 -0.24213 -0.27053 0.045287 -0.40147 0.11395 0.0062226 0.036673 0.018518 -1.0213 -0.20806 0.64072 -0.068763 -0.58635 0.33476 -1.1432 -0.1148 -0.25091 -0.45907 -0.096819 -0.17946 -0.063351 -0.67412 -0.068895 0.53604 -0.87773 0.31802 -0.39242 -0.23394 0.47298 -0.028803\n\n<class 'str'>\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### 1.1.1 Define \"word_to_index\" and \"word_vectors\"","metadata":{}},{"cell_type":"code","source":"##### For demonstration purposes, we'll only use the first 10 lines of glove.6B.100d.txt, \n##### which correspond to the embeddings of the first 10 words.\n\n### a disctionary that stores the matching from a word to its index\nword_to_index  = {}\n### a list that stores the embedding vectors for all the words in the vocabulary\nword_vectors   = []\n\nwith open(embedding_file) as fp:\n    for i,line in enumerate(fp.readlines()):\n        ### For demonstration purposes, here only read the first 10 lines of glove.6B.100d.txt,\n        if i >=10: \n            break\n        \"\"\"\n            Originally, each line is a str object, like \"the -0.038194 -0.24487 ... 0.27062\".\n            Using the .split(\" \") method, split the string into substrings based on the specified \n            delimiter \" \", and return a list containing the substrings.\n            In particular, each line contains 101 elements: 1 word + 100-dimension vector\n        \"\"\"\n        line = line.split(\" \")\n        \n        ### the first element in the list (i.e., the first word in the original line) is the word \n        word = line[0]\n        \n        ### the remaining elements in the list are 100-dimension vectors \n        ### transferring str to float\n        vec  = np.array([float(x) for x in line[1:]])\n        \n        ### store the the ith element in word_to_index\n        word_to_index[word] = len(word_to_index)\n        \n        ### store the ith element in word_vectors\n        word_vectors.append(vec)","metadata":{"execution":{"iopub.status.busy":"2024-05-08T14:26:57.551181Z","iopub.execute_input":"2024-05-08T14:26:57.551954Z","iopub.status.idle":"2024-05-08T14:27:03.899394Z","shell.execute_reply.started":"2024-05-08T14:26:57.551921Z","shell.execute_reply":"2024-05-08T14:27:03.898253Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"print('word_to_index')\nprint(word_to_index)\nprint('-'*100)\nprint(\"word_to_index['to'] - the index of 'to'\")\nprint(word_to_index['to'])\nprint('-'*100)\nprint(\"word_to_index['apple'] - the index of 'apple. Note 'apple' is not in the vocabulary\")\ntry:\n    print(word_to_index['apple'])\nexcept Exception as e:\n    print (e)","metadata":{"execution":{"iopub.status.busy":"2024-05-08T14:27:03.900638Z","iopub.execute_input":"2024-05-08T14:27:03.900978Z","iopub.status.idle":"2024-05-08T14:27:03.908820Z","shell.execute_reply.started":"2024-05-08T14:27:03.900947Z","shell.execute_reply":"2024-05-08T14:27:03.907506Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"word_to_index\n{'the': 0, ',': 1, '.': 2, 'of': 3, 'to': 4, 'and': 5, 'in': 6, 'a': 7, '\"': 8, \"'s\": 9}\n----------------------------------------------------------------------------------------------------\nword_to_index['to'] - the index of 'to'\n4\n----------------------------------------------------------------------------------------------------\nword_to_index['apple'] - the index of 'apple. Note 'apple' is not in the vocabulary\n'apple'\n","output_type":"stream"}]},{"cell_type":"code","source":"### A disctionary that stores the matching from an index to the word\nindex_to_word = {v: k for k, v in word_to_index.items()}\nindex_to_word","metadata":{"execution":{"iopub.status.busy":"2024-05-08T14:27:03.910270Z","iopub.execute_input":"2024-05-08T14:27:03.910801Z","iopub.status.idle":"2024-05-08T14:27:03.927338Z","shell.execute_reply.started":"2024-05-08T14:27:03.910770Z","shell.execute_reply":"2024-05-08T14:27:03.925988Z"},"trusted":true},"execution_count":6,"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"{0: 'the',\n 1: ',',\n 2: '.',\n 3: 'of',\n 4: 'to',\n 5: 'and',\n 6: 'in',\n 7: 'a',\n 8: '\"',\n 9: \"'s\"}"},"metadata":{}}]},{"cell_type":"code","source":"print('word_vectors (for the first two words)')\nword_vectors[:2]","metadata":{"execution":{"iopub.status.busy":"2024-05-08T14:27:03.928965Z","iopub.execute_input":"2024-05-08T14:27:03.929705Z","iopub.status.idle":"2024-05-08T14:27:03.944961Z","shell.execute_reply.started":"2024-05-08T14:27:03.929662Z","shell.execute_reply":"2024-05-08T14:27:03.943637Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"word_vectors (for the first two words)\n","output_type":"stream"},{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"[array([-0.038194, -0.24487 ,  0.72812 , -0.39961 ,  0.083172,  0.043953,\n        -0.39141 ,  0.3344  , -0.57545 ,  0.087459,  0.28787 , -0.06731 ,\n         0.30906 , -0.26384 , -0.13231 , -0.20757 ,  0.33395 , -0.33848 ,\n        -0.31743 , -0.48336 ,  0.1464  , -0.37304 ,  0.34577 ,  0.052041,\n         0.44946 , -0.46971 ,  0.02628 , -0.54155 , -0.15518 , -0.14107 ,\n        -0.039722,  0.28277 ,  0.14393 ,  0.23464 , -0.31021 ,  0.086173,\n         0.20397 ,  0.52624 ,  0.17164 , -0.082378, -0.71787 , -0.41531 ,\n         0.20335 , -0.12763 ,  0.41367 ,  0.55187 ,  0.57908 , -0.33477 ,\n        -0.36559 , -0.54857 , -0.062892,  0.26584 ,  0.30205 ,  0.99775 ,\n        -0.80481 , -3.0243  ,  0.01254 , -0.36942 ,  2.2167  ,  0.72201 ,\n        -0.24978 ,  0.92136 ,  0.034514,  0.46745 ,  1.1079  , -0.19358 ,\n        -0.074575,  0.23353 , -0.052062, -0.22044 ,  0.057162, -0.15806 ,\n        -0.30798 , -0.41625 ,  0.37972 ,  0.15006 , -0.53212 , -0.2055  ,\n        -1.2526  ,  0.071624,  0.70565 ,  0.49744 , -0.42063 ,  0.26148 ,\n        -1.538   , -0.30223 , -0.073438, -0.28312 ,  0.37104 , -0.25217 ,\n         0.016215, -0.017099, -0.38984 ,  0.87424 , -0.72569 , -0.51058 ,\n        -0.52028 , -0.1459  ,  0.8278  ,  0.27062 ]),\n array([-0.10767  ,  0.11053  ,  0.59812  , -0.54361  ,  0.67396  ,\n         0.10663  ,  0.038867 ,  0.35481  ,  0.06351  , -0.094189 ,\n         0.15786  , -0.81665  ,  0.14172  ,  0.21939  ,  0.58505  ,\n        -0.52158  ,  0.22783  , -0.16642  , -0.68228  ,  0.3587   ,\n         0.42568  ,  0.19021  ,  0.91963  ,  0.57555  ,  0.46185  ,\n         0.42363  , -0.095399 , -0.42749  , -0.16567  , -0.056842 ,\n        -0.29595  ,  0.26037  , -0.26606  , -0.070404 , -0.27662  ,\n         0.15821  ,  0.69825  ,  0.43081  ,  0.27952  , -0.45437  ,\n        -0.33801  , -0.58184  ,  0.22364  , -0.5778   , -0.26862  ,\n        -0.20425  ,  0.56394  , -0.58524  , -0.14365  , -0.64218  ,\n         0.0054697, -0.35248  ,  0.16162  ,  1.1796   , -0.47674  ,\n        -2.7553   , -0.1321   , -0.047729 ,  1.0655   ,  1.1034   ,\n        -0.2208   ,  0.18669  ,  0.13177  ,  0.15117  ,  0.7131   ,\n        -0.35215  ,  0.91348  ,  0.61783  ,  0.70992  ,  0.23955  ,\n        -0.14571  , -0.37859  , -0.045959 , -0.47368  ,  0.2385   ,\n         0.20536  , -0.18996  ,  0.32507  , -1.1112   , -0.36341  ,\n         0.98679  , -0.084776 , -0.54008  ,  0.11726  , -1.0194   ,\n        -0.24424  ,  0.12771  ,  0.013884 ,  0.080374 , -0.35414  ,\n         0.34951  , -0.7226   ,  0.37549  ,  0.4441   , -0.99059  ,\n         0.61214  , -0.35111  , -0.83155  ,  0.45293  ,  0.082577 ])]"},"metadata":{}}]},{"cell_type":"markdown","source":"### 1.1.2 Define “index” using AnnoyIndex\n### - Library for approximate nearest neighbors: [Annoy](https://pypi.org/project/annoy/). Annoy was built by [Erik Bernhardsson](https://erikbern.com/).\n\n### - Annoy ([Approximate Nearest Neighbors](https://en.wikipedia.org/wiki/Nearest_neighbor_search#Approximate_nearest_neighbor) Oh Yeah) is a C++ library with Python bindings to search for points in space that are close to a given query point. It also creates large read-only file-based data structures that are [mmap](https://en.wikipedia.org/wiki/Mmap)ped into memory so that many processes may share the same data.\n\n### - Useful functions:\n1) **AnnoyIndex(f, metric)**: returns a new index that’s read-write and stores vector of f dimensions. Metric can be \"angular\", \"euclidean\", \"manhattan\", \"hamming\", or \"dot\".\n\n2) **a.get_n_items()**: returns the number of items in the index.\n\n3) **a.get_item_vector(i)**: returns the vector for item i that was previously added.\n\n4) **a.add_item(i, v)**: adds item i (any nonnegative integer) with vector v. Note that it will allocate memory for max(i)+1 items - for example, if \"a\" has 2 existing items, numbered 0 and 1, a.add_item(4,...) will add one new item and allocate it to the (4+1)th item, and the items with skipped numbers will be assigned with vector of zeroes.\n\n5) **a.build(n_trees, n_jobs=-1)**: builds a forest of n_trees trees. More trees gives higher precision when querying. After calling build, no more items can be added. n_jobs specifies the number of threads used to build the trees. n_jobs=-1 uses all available CPU cores.\n\n6) **a.get_distance(i, j)**: returns the distance between items i and j. NOTE: this used to return the squared distance, but has been changed as of Aug 2016.\n\n7) **a.get_nns_by_item(i, n, search_k=-1, include_distances=False)**: returns the n closest items. During the query it will inspect up to search_k nodes which defaults to n_trees * n if not provided. search_k gives you a run-time tradeoff between better accuracy and speed. If you set include_distances to True, it will return a 2 element tuple with two lists in it: the second one containing all corresponding distances.\n\n8) **a.get_nns_by_vector(v, n, search_k=-1, include_distances=False)**: same but query by vector v.","metadata":{}},{"cell_type":"markdown","source":"### Initialize an index object","metadata":{}},{"cell_type":"code","source":"##### The first argument of AnnoyIndex() is the dimension of the vectors, which means\n##### all the vectors to be written and stored in the index should have this dimension.\n\nindex_temp = AnnoyIndex(10, metric='euclidean')\nprint('Type of “index”')\nprint(type(index_temp))\nprint('-'*60)\nprint('All properties and methods of “index”')\ndir(index_temp)","metadata":{"execution":{"iopub.status.busy":"2024-05-08T14:27:03.947016Z","iopub.execute_input":"2024-05-08T14:27:03.947827Z","iopub.status.idle":"2024-05-08T14:27:03.960695Z","shell.execute_reply.started":"2024-05-08T14:27:03.947781Z","shell.execute_reply":"2024-05-08T14:27:03.959554Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"Type of “index”\n<class 'annoy.Annoy'>\n------------------------------------------------------------\nAll properties and methods of “index”\n","output_type":"stream"},{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"['__class__',\n '__delattr__',\n '__dir__',\n '__doc__',\n '__eq__',\n '__format__',\n '__ge__',\n '__getattribute__',\n '__gt__',\n '__hash__',\n '__init__',\n '__init_subclass__',\n '__le__',\n '__lt__',\n '__ne__',\n '__new__',\n '__reduce__',\n '__reduce_ex__',\n '__repr__',\n '__setattr__',\n '__sizeof__',\n '__str__',\n '__subclasshook__',\n 'add_item',\n 'build',\n 'f',\n 'get_distance',\n 'get_item_vector',\n 'get_n_items',\n 'get_n_trees',\n 'get_nns_by_item',\n 'get_nns_by_vector',\n 'load',\n 'on_disk_build',\n 'save',\n 'set_seed',\n 'unbuild',\n 'unload',\n 'verbose']"},"metadata":{}}]},{"cell_type":"markdown","source":"### Add items to the the index ","metadata":{"execution":{"iopub.status.busy":"2024-03-25T02:36:22.872274Z","iopub.execute_input":"2024-03-25T02:36:22.872931Z","iopub.status.idle":"2024-03-25T02:36:22.882092Z","shell.execute_reply.started":"2024-03-25T02:36:22.872894Z","shell.execute_reply":"2024-03-25T02:36:22.880447Z"}}},{"cell_type":"code","source":"index_temp = AnnoyIndex(10, metric='euclidean')\nprint(\"Number of items in index_temp: {}\".format(index_temp.get_n_items()))\n##### Before using add_item to assign values, index_temp does not have any item.\ntry:\n    index_temp.get_item_vector(0)\nexcept Exception as e:\n    print(e)","metadata":{"execution":{"iopub.status.busy":"2024-05-08T14:27:03.962071Z","iopub.execute_input":"2024-05-08T14:27:03.963097Z","iopub.status.idle":"2024-05-08T14:27:03.977334Z","shell.execute_reply.started":"2024-05-08T14:27:03.963055Z","shell.execute_reply":"2024-05-08T14:27:03.976065Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"Number of items in index_temp: 0\nItem index larger than the largest item index\n","output_type":"stream"}]},{"cell_type":"code","source":"##### Add two items - a n=10 array of 0s and a n=10 array of 1s\n\nindex_temp.add_item(0,np.ones(10)*0)\nprint(\"The first item (numbered 0) in index_temp\")\nprint(index_temp.get_item_vector(0))\nprint(\"Number of items in index_temp: {}\".format(index_temp.get_n_items()))\nprint('-'*60)\n\nindex_temp.add_item(1,np.ones(10)*1)\nprint(\"The second item (numbered 1) in index_temp\")\nprint(index_temp.get_item_vector(1))\nprint(\"Number of items in index_temp: {}\".format(index_temp.get_n_items()))","metadata":{"execution":{"iopub.status.busy":"2024-05-08T14:27:03.981779Z","iopub.execute_input":"2024-05-08T14:27:03.982149Z","iopub.status.idle":"2024-05-08T14:27:03.991035Z","shell.execute_reply.started":"2024-05-08T14:27:03.982119Z","shell.execute_reply":"2024-05-08T14:27:03.989768Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"The first item (numbered 0) in index_temp\n[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\nNumber of items in index_temp: 1\n------------------------------------------------------------\nThe second item (numbered 1) in index_temp\n[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]\nNumber of items in index_temp: 2\n","output_type":"stream"}]},{"cell_type":"code","source":"##### Add one item - a n=10 array of 4s\nindex_temp.add_item(4,np.ones(10)*4)\n\nprint(\"The third item (numbered 2) in index_temp\")\nprint(index_temp.get_item_vector(2))\nprint(\"Number of items in index_temp: {}\".format(index_temp.get_n_items()))\nprint('-'*60)\nprint(\"The fourth item (numbered 3) in index_temp\")\nprint(index_temp.get_item_vector(3))\nprint(\"Number of items in index_temp: {}\".format(index_temp.get_n_items()))\nprint('-'*60)\nprint(\"The fifth item (numbered 4) in index_temp\")\nprint(index_temp.get_item_vector(4))\nprint(\"Number of items in index_temp: {}\".format(index_temp.get_n_items()))","metadata":{"execution":{"iopub.status.busy":"2024-05-08T14:27:03.993015Z","iopub.execute_input":"2024-05-08T14:27:03.993373Z","iopub.status.idle":"2024-05-08T14:27:04.003937Z","shell.execute_reply.started":"2024-05-08T14:27:03.993338Z","shell.execute_reply":"2024-05-08T14:27:04.002936Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stdout","text":"The third item (numbered 2) in index_temp\n[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\nNumber of items in index_temp: 5\n------------------------------------------------------------\nThe fourth item (numbered 3) in index_temp\n[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\nNumber of items in index_temp: 5\n------------------------------------------------------------\nThe fifth item (numbered 4) in index_temp\n[4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0]\nNumber of items in index_temp: 5\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### Add all the vectors from word_vectors to index and build the index (tree)","metadata":{}},{"cell_type":"code","source":"index = AnnoyIndex(len(word_vectors[0]), metric='euclidean')\nfor _, i in word_to_index.items():\n    index.add_item(i,word_vectors[i])\n### \nindex.build(50)\nprint(index.get_n_items())","metadata":{"execution":{"iopub.status.busy":"2024-05-08T14:27:04.004897Z","iopub.execute_input":"2024-05-08T14:27:04.006076Z","iopub.status.idle":"2024-05-08T14:27:04.016260Z","shell.execute_reply.started":"2024-05-08T14:27:04.006032Z","shell.execute_reply":"2024-05-08T14:27:04.015110Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stdout","text":"10\n","output_type":"stream"}]},{"cell_type":"code","source":"print(\"The first item (numbered 0) in index\")\nprint(index.get_item_vector(0))","metadata":{"execution":{"iopub.status.busy":"2024-05-08T14:27:04.017386Z","iopub.execute_input":"2024-05-08T14:27:04.017776Z","iopub.status.idle":"2024-05-08T14:27:04.028541Z","shell.execute_reply.started":"2024-05-08T14:27:04.017742Z","shell.execute_reply":"2024-05-08T14:27:04.027215Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"The first item (numbered 0) in index\n[-0.03819400072097778, -0.24487000703811646, 0.7281200289726257, -0.3996100127696991, 0.08317200094461441, 0.043953001499176025, -0.3914099931716919, 0.3343999981880188, -0.5754500031471252, 0.08745899796485901, 0.28786998987197876, -0.06730999797582626, 0.3090600073337555, -0.263839989900589, -0.13231000304222107, -0.20757000148296356, 0.333950012922287, -0.33847999572753906, -0.3174299895763397, -0.4833599925041199, 0.14640000462532043, -0.37303999066352844, 0.345770001411438, 0.05204100161790848, 0.4494599997997284, -0.46970999240875244, 0.026280000805854797, -0.5415499806404114, -0.15518000721931458, -0.14106999337673187, -0.03972199931740761, 0.2827700078487396, 0.14393000304698944, 0.2346400022506714, -0.3102099895477295, 0.08617299795150757, 0.20397000014781952, 0.5262399911880493, 0.17163999378681183, -0.08237800002098083, -0.7178699970245361, -0.41530999541282654, 0.2033499926328659, -0.12762999534606934, 0.41367000341415405, 0.5518699884414673, 0.5790799856185913, -0.33476999402046204, -0.36559000611305237, -0.5485699772834778, -0.06289199739694595, 0.26583999395370483, 0.30204999446868896, 0.9977499842643738, -0.8048099875450134, -3.0243000984191895, 0.012539999559521675, -0.36941999197006226, 2.2167000770568848, 0.7220100164413452, -0.24977999925613403, 0.9213600158691406, 0.03451399877667427, 0.46744999289512634, 1.1079000234603882, -0.1935800015926361, -0.07457499951124191, 0.23352999985218048, -0.05206200107932091, -0.22044000029563904, 0.057162001729011536, -0.1580599993467331, -0.3079800009727478, -0.41624999046325684, 0.379720002412796, 0.1500599980354309, -0.5321199893951416, -0.20550000667572021, -1.2525999546051025, 0.07162400335073471, 0.7056499719619751, 0.49744001030921936, -0.42063000798225403, 0.2614800035953522, -1.5379999876022339, -0.30223000049591064, -0.07343800365924835, -0.2831200063228607, 0.3710399866104126, -0.25216999650001526, 0.016215000301599503, -0.01709900051355362, -0.3898400068283081, 0.874239981174469, -0.7256900072097778, -0.5105800032615662, -0.5202800035476685, -0.14589999616146088, 0.8277999758720398, 0.2706199884414673]\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### 1.1.3 Calculate the distance from the item (numbered 4)","metadata":{}},{"cell_type":"code","source":"##### Calculate the distance using a.get_distance()\ndistances_from_4 = pd.DataFrame(index=range(index.get_n_items()), \n                                columns=['i', 'distance'], \n                                data=None)\nfor i in range(index.get_n_items()):\n    distances_from_4.iloc[i,0] = i\n    distances_from_4.iloc[i,1] = index.get_distance(4,i)\ndistances_from_4","metadata":{"execution":{"iopub.status.busy":"2024-05-08T14:27:04.029566Z","iopub.execute_input":"2024-05-08T14:27:04.029889Z","iopub.status.idle":"2024-05-08T14:27:04.058252Z","shell.execute_reply.started":"2024-05-08T14:27:04.029855Z","shell.execute_reply":"2024-05-08T14:27:04.057070Z"},"trusted":true},"execution_count":14,"outputs":[{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"   i  distance\n0  0  4.408458\n1  1  4.915794\n2  2  4.384933\n3  3  5.519794\n4  4       0.0\n5  5  4.434967\n6  6  4.824089\n7  7   5.05785\n8  8  6.302962\n9  9  5.491484","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>i</th>\n      <th>distance</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>4.408458</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>4.915794</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>4.384933</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>5.519794</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>5</td>\n      <td>4.434967</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>6</td>\n      <td>4.824089</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>7</td>\n      <td>5.05785</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>8</td>\n      <td>6.302962</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>9</td>\n      <td>5.491484</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"##### Calculate the distance using np.linalg.norm(), obtain the same results\n_distances_from_4 = pd.DataFrame(index=range(index.get_n_items()), \n                                columns=['i', 'distance'], \n                                data=None)\nfor i in range(index.get_n_items()):\n    _distances_from_4.iloc[i,0] = i\n    _distances_from_4.iloc[i,1] = np.linalg.norm(np.array(index.get_item_vector(i)) \\\n                                                 - np.array(index.get_item_vector(4)))\n_distances_from_4","metadata":{"execution":{"iopub.status.busy":"2024-05-08T14:27:04.059872Z","iopub.execute_input":"2024-05-08T14:27:04.060298Z","iopub.status.idle":"2024-05-08T14:27:04.076252Z","shell.execute_reply.started":"2024-05-08T14:27:04.060261Z","shell.execute_reply":"2024-05-08T14:27:04.075060Z"},"trusted":true},"execution_count":15,"outputs":[{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"   i  distance\n0  0  4.408458\n1  1  4.915794\n2  2  4.384933\n3  3  5.519794\n4  4       0.0\n5  5  4.434967\n6  6  4.824089\n7  7   5.05785\n8  8  6.302962\n9  9  5.491485","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>i</th>\n      <th>distance</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>4.408458</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>4.915794</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>4.384933</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>5.519794</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>5</td>\n      <td>4.434967</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>6</td>\n      <td>4.824089</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>7</td>\n      <td>5.05785</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>8</td>\n      <td>6.302962</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>9</td>\n      <td>5.491485</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"distances_from_4.sort_values('distance')","metadata":{"execution":{"iopub.status.busy":"2024-05-08T14:27:04.077979Z","iopub.execute_input":"2024-05-08T14:27:04.079004Z","iopub.status.idle":"2024-05-08T14:27:04.092554Z","shell.execute_reply.started":"2024-05-08T14:27:04.078970Z","shell.execute_reply":"2024-05-08T14:27:04.091552Z"},"trusted":true},"execution_count":16,"outputs":[{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"   i  distance\n4  4       0.0\n2  2  4.384933\n0  0  4.408458\n5  5  4.434967\n6  6  4.824089\n1  1  4.915794\n7  7   5.05785\n9  9  5.491484\n3  3  5.519794\n8  8  6.302962","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>i</th>\n      <th>distance</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>4.384933</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>4.408458</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>5</td>\n      <td>4.434967</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>6</td>\n      <td>4.824089</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>4.915794</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>7</td>\n      <td>5.05785</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>9</td>\n      <td>5.491484</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>5.519794</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>8</td>\n      <td>6.302962</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"### returns the n closest items of word_vectors[4], using a.get_nns_by_item()\nindex.get_nns_by_item(4,5,include_distances=True)","metadata":{"execution":{"iopub.status.busy":"2024-05-08T14:27:04.093728Z","iopub.execute_input":"2024-05-08T14:27:04.094475Z","iopub.status.idle":"2024-05-08T14:27:04.105637Z","shell.execute_reply.started":"2024-05-08T14:27:04.094444Z","shell.execute_reply":"2024-05-08T14:27:04.104314Z"},"trusted":true},"execution_count":17,"outputs":[{"execution_count":17,"output_type":"execute_result","data":{"text/plain":"([4, 2, 0, 5, 6],\n [0.0,\n  4.384932518005371,\n  4.408458232879639,\n  4.434966564178467,\n  4.8240885734558105])"},"metadata":{}}]},{"cell_type":"code","source":"### returns the n closest items of word_vectors[4], using a.get_nns_by_vector()\nindex.get_nns_by_vector(word_vectors[4],5,include_distances=True)","metadata":{"execution":{"iopub.status.busy":"2024-05-08T14:27:04.107370Z","iopub.execute_input":"2024-05-08T14:27:04.107967Z","iopub.status.idle":"2024-05-08T14:27:04.117042Z","shell.execute_reply.started":"2024-05-08T14:27:04.107935Z","shell.execute_reply":"2024-05-08T14:27:04.116297Z"},"trusted":true},"execution_count":18,"outputs":[{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"([4, 2, 0, 5, 6],\n [0.0,\n  4.384932518005371,\n  4.408458232879639,\n  4.434966564178467,\n  4.8240885734558105])"},"metadata":{}}]},{"cell_type":"markdown","source":"## 1.2 from_embeddings_file()\n### Instantiate from pre-trained vector file","metadata":{}},{"cell_type":"code","source":"embeddings = PreTrainedEmbeddings.from_embeddings_file(embedding_file)","metadata":{"execution":{"iopub.status.busy":"2024-05-08T14:27:04.118222Z","iopub.execute_input":"2024-05-08T14:27:04.118680Z","iopub.status.idle":"2024-05-08T14:27:33.397045Z","shell.execute_reply.started":"2024-05-08T14:27:04.118653Z","shell.execute_reply":"2024-05-08T14:27:33.395790Z"},"trusted":true},"execution_count":19,"outputs":[{"name":"stdout","text":"Building Index!\nFinished!\n","output_type":"stream"}]},{"cell_type":"code","source":"type(embeddings)","metadata":{"execution":{"iopub.status.busy":"2024-05-08T14:27:33.398412Z","iopub.execute_input":"2024-05-08T14:27:33.398742Z","iopub.status.idle":"2024-05-08T14:27:33.405586Z","shell.execute_reply.started":"2024-05-08T14:27:33.398713Z","shell.execute_reply":"2024-05-08T14:27:33.404439Z"},"trusted":true},"execution_count":20,"outputs":[{"execution_count":20,"output_type":"execute_result","data":{"text/plain":"__main__.PreTrainedEmbeddings"},"metadata":{}}]},{"cell_type":"code","source":"dir(embeddings)","metadata":{"execution":{"iopub.status.busy":"2024-05-08T14:27:33.407043Z","iopub.execute_input":"2024-05-08T14:27:33.407396Z","iopub.status.idle":"2024-05-08T14:27:33.419825Z","shell.execute_reply.started":"2024-05-08T14:27:33.407366Z","shell.execute_reply":"2024-05-08T14:27:33.418490Z"},"trusted":true},"execution_count":21,"outputs":[{"execution_count":21,"output_type":"execute_result","data":{"text/plain":"['__class__',\n '__delattr__',\n '__dict__',\n '__dir__',\n '__doc__',\n '__eq__',\n '__format__',\n '__ge__',\n '__getattribute__',\n '__gt__',\n '__hash__',\n '__init__',\n '__init_subclass__',\n '__le__',\n '__lt__',\n '__module__',\n '__ne__',\n '__new__',\n '__reduce__',\n '__reduce_ex__',\n '__repr__',\n '__setattr__',\n '__sizeof__',\n '__str__',\n '__subclasshook__',\n '__weakref__',\n 'compute_and_print_analogy',\n 'from_embeddings_file',\n 'get_closest_to_vector',\n 'get_embedding',\n 'index',\n 'index_to_word',\n 'word_to_index',\n 'word_vectors']"},"metadata":{}}]},{"cell_type":"code","source":"dir(embeddings.index)","metadata":{"execution":{"iopub.status.busy":"2024-05-08T14:27:33.421190Z","iopub.execute_input":"2024-05-08T14:27:33.421616Z","iopub.status.idle":"2024-05-08T14:27:33.432883Z","shell.execute_reply.started":"2024-05-08T14:27:33.421575Z","shell.execute_reply":"2024-05-08T14:27:33.431695Z"},"trusted":true},"execution_count":22,"outputs":[{"execution_count":22,"output_type":"execute_result","data":{"text/plain":"['__class__',\n '__delattr__',\n '__dir__',\n '__doc__',\n '__eq__',\n '__format__',\n '__ge__',\n '__getattribute__',\n '__gt__',\n '__hash__',\n '__init__',\n '__init_subclass__',\n '__le__',\n '__lt__',\n '__ne__',\n '__new__',\n '__reduce__',\n '__reduce_ex__',\n '__repr__',\n '__setattr__',\n '__sizeof__',\n '__str__',\n '__subclasshook__',\n 'add_item',\n 'build',\n 'f',\n 'get_distance',\n 'get_item_vector',\n 'get_n_items',\n 'get_n_trees',\n 'get_nns_by_item',\n 'get_nns_by_vector',\n 'load',\n 'on_disk_build',\n 'save',\n 'set_seed',\n 'unbuild',\n 'unload',\n 'verbose']"},"metadata":{}}]},{"cell_type":"markdown","source":"## 1.3 from_embeddings_file(word)\n### Get the embedding (vector reporesentation) of a word","metadata":{}},{"cell_type":"code","source":"##### To use this function, the input word must be included in word_vectors\nword_now = 'apple'\nvec_now  = embeddings.get_embedding(word_now)\nprint('Example word:')\nprint(word_now)\nprint('-'*60)\nprint('Pre-trained vector of the example word:')\nprint('A vector with dimension = {}'.format(len(vec_now)))\nprint(vec_now)","metadata":{"execution":{"iopub.status.busy":"2024-05-08T14:27:33.434759Z","iopub.execute_input":"2024-05-08T14:27:33.435226Z","iopub.status.idle":"2024-05-08T14:27:33.444846Z","shell.execute_reply.started":"2024-05-08T14:27:33.435186Z","shell.execute_reply":"2024-05-08T14:27:33.443664Z"},"trusted":true},"execution_count":23,"outputs":[{"name":"stdout","text":"Example word:\napple\n------------------------------------------------------------\nPre-trained vector of the example word:\nA vector with dimension = 100\n[-0.5985    -0.46321    0.13001   -0.019576   0.4603    -0.3018\n  0.8977    -0.65634    0.66858   -0.49164    0.037557  -0.050889\n  0.6451    -0.53882   -0.3765    -0.04312    0.51384    0.17783\n  0.28596    0.92063   -0.49349   -0.48583    0.61321    0.78211\n  0.19254    0.91228   -0.055596  -0.12512   -0.65688    0.068557\n  0.55629    1.611     -0.0073642 -0.48879    0.45493    0.96105\n -0.063369   0.17432    0.9814    -1.3125    -0.15801   -0.54301\n -0.13888   -0.26146   -0.3691     0.26844   -0.24375   -0.19484\n  0.62583   -0.7377     0.38351   -0.75004   -0.39053    0.091498\n -0.36591   -1.4715    -0.45228    0.2256     1.1412    -0.38526\n -0.06716    0.57288   -0.39191    0.31302   -0.29235   -0.96157\n  0.15154   -0.21659    0.25103    0.096967   0.2843     1.4296\n -0.50565   -0.51374   -0.47218    0.32036    0.023149   0.22623\n -0.09725    0.82126    0.92599   -1.0086    -0.38639    0.86408\n -1.206     -0.28528    0.2265    -0.38773    0.40879    0.59303\n  0.30769    0.83804   -0.63655   -0.44639   -0.43406   -0.79364\n -0.28675   -0.034398   1.3431     0.34904  ]\n","output_type":"stream"}]},{"cell_type":"code","source":"##### If the input is not in word_vectors...\ntry:\n    embeddings.get_embedding('aaaaaaa')\nexcept Exception as e:\n    print(e)","metadata":{"execution":{"iopub.status.busy":"2024-05-08T14:27:33.446653Z","iopub.execute_input":"2024-05-08T14:27:33.446964Z","iopub.status.idle":"2024-05-08T14:27:33.456764Z","shell.execute_reply.started":"2024-05-08T14:27:33.446931Z","shell.execute_reply":"2024-05-08T14:27:33.455589Z"},"trusted":true},"execution_count":24,"outputs":[{"name":"stdout","text":"'aaaaaaa'\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## 1.4 get_closest_to_vector(self, vector, n=1)\n### Given a vector, return its n nearest neighbors","metadata":{}},{"cell_type":"code","source":"word_now  = 'friend'\nvec_now   = embeddings.get_embedding(word_now)\nnearest_n = 3\nnn_indices = embeddings.index.get_nns_by_vector(vec_now, nearest_n) \nnn_indices ","metadata":{"execution":{"iopub.status.busy":"2024-05-08T14:27:33.458149Z","iopub.execute_input":"2024-05-08T14:27:33.458507Z","iopub.status.idle":"2024-05-08T14:27:33.469879Z","shell.execute_reply.started":"2024-05-08T14:27:33.458470Z","shell.execute_reply":"2024-05-08T14:27:33.468896Z"},"trusted":true},"execution_count":25,"outputs":[{"execution_count":25,"output_type":"execute_result","data":{"text/plain":"[1409, 1327, 629]"},"metadata":{}}]},{"cell_type":"code","source":"i = 0\nfor neighbor in nn_indices:\n    i+=1\n    print('neighbor' + str(i))\n    print(embeddings.index_to_word[neighbor])\n    print('-'*60)","metadata":{"execution":{"iopub.status.busy":"2024-05-08T14:27:33.471226Z","iopub.execute_input":"2024-05-08T14:27:33.471595Z","iopub.status.idle":"2024-05-08T14:27:33.481074Z","shell.execute_reply.started":"2024-05-08T14:27:33.471563Z","shell.execute_reply":"2024-05-08T14:27:33.480236Z"},"trusted":true},"execution_count":26,"outputs":[{"name":"stdout","text":"neighbor1\nfriend\n------------------------------------------------------------\nneighbor2\nhusband\n------------------------------------------------------------\nneighbor3\nfather\n------------------------------------------------------------\n","output_type":"stream"}]},{"cell_type":"code","source":"##### Find the closest neighbors to random samples of the words in glove.6B.100d.txt\nn_words     = 5\nn_neighbors = 5\nwords = random.sample(embeddings.word_to_index.keys(), n_words)\nfor w in words:\n    print(w)\n    print(embeddings.get_closest_to_vector(embeddings.get_embedding(w),n_neighbors))\n    print('-'*60)","metadata":{"execution":{"iopub.status.busy":"2024-05-08T14:27:33.482265Z","iopub.execute_input":"2024-05-08T14:27:33.483224Z","iopub.status.idle":"2024-05-08T14:27:33.508588Z","shell.execute_reply.started":"2024-05-08T14:27:33.483192Z","shell.execute_reply":"2024-05-08T14:27:33.507123Z"},"trusted":true},"execution_count":27,"outputs":[{"name":"stdout","text":"prezzo\n['prezzo', 'bilen', 'boom-boom', 'gnus', 'half-orcs']\n------------------------------------------------------------\npuhs\n['puhs', 'preh', 'gooz', 'zeef', 'tooj']\n------------------------------------------------------------\nccne\n['ccne', 'lcme', 'accp', 'dtf', 'ncse']\n------------------------------------------------------------\nnakagami\n['nakagami', 'spasov', 'emosi', 'kranenburg', 'kakizaki']\n------------------------------------------------------------\nroll-on\n['roll-on', '4-seater', 'muzzleloader', 'torpedo-bomber', 'five-seater']\n------------------------------------------------------------\n","output_type":"stream"}]},{"cell_type":"code","source":"##### Find the closest neighbors to example words\nwords = ['star','banana','boy','model','sky']\nfor w in words:\n    print(w)\n    print(embeddings.get_closest_to_vector(embeddings.get_embedding(w),n_neighbors))\n    print('-'*60)","metadata":{"execution":{"iopub.status.busy":"2024-05-08T14:27:33.514375Z","iopub.execute_input":"2024-05-08T14:27:33.515458Z","iopub.status.idle":"2024-05-08T14:27:33.522666Z","shell.execute_reply.started":"2024-05-08T14:27:33.515417Z","shell.execute_reply":"2024-05-08T14:27:33.521598Z"},"trusted":true},"execution_count":28,"outputs":[{"name":"stdout","text":"star\n['star', 'stars', 'superstar', 'legend', 'hero']\n------------------------------------------------------------\nbanana\n['banana', 'mango', 'coconut', 'bananas', 'potato']\n------------------------------------------------------------\nboy\n['boy', 'girl', 'kid', 'man', 'boys']\n------------------------------------------------------------\nmodel\n['model', 'models', 'concept', 'design', 'introduced']\n------------------------------------------------------------\nsky\n['sky', 'skies', 'horizon', 'bright', 'shadows']\n------------------------------------------------------------\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## 1.4 compute_and_print_analogy(self, word1, word2, word3)\n### Prints the solutions to analogies using word embeddings","metadata":{}},{"cell_type":"code","source":"word1, word2, word3 = 'cat', 'kitten', 'dog'","metadata":{"execution":{"iopub.status.busy":"2024-05-08T14:27:33.524118Z","iopub.execute_input":"2024-05-08T14:27:33.524655Z","iopub.status.idle":"2024-05-08T14:27:33.531906Z","shell.execute_reply.started":"2024-05-08T14:27:33.524619Z","shell.execute_reply":"2024-05-08T14:27:33.530935Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"### Simple hypothesis: Analogy is a spatial relationship \n### vec1 - vec2 = vec3 - vec4\n### vec4 = vec3 - (vec1 - vec2)\nvec1 = embeddings.get_embedding(word1) \nvec2 = embeddings.get_embedding(word2) \nvec3 = embeddings.get_embedding(word3)\nvec4 = vec3 - (vec1 - vec2)","metadata":{"execution":{"iopub.status.busy":"2024-05-08T14:27:33.533743Z","iopub.execute_input":"2024-05-08T14:27:33.534459Z","iopub.status.idle":"2024-05-08T14:27:33.544913Z","shell.execute_reply.started":"2024-05-08T14:27:33.534425Z","shell.execute_reply":"2024-05-08T14:27:33.543920Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"closest_words = embeddings.get_closest_to_vector(vec4, n=4)\nprint('closest_words')\nprint(closest_words)\nprint('-'*60)\nexisting_words = set([word1, word2, word3])\nprint('existing_words')\nprint(existing_words)\nprint('-'*60)\nsolution_words = [word for word in closest_words if word not in existing_words]\nprint('solution_words')\nprint(solution_words)\nprint('-'*60)\nprint('Solution')\nfor word4 in solution_words:\n    print(\"{} : {} :: {} : {}\".format(word1, word2, word3, word4))","metadata":{"execution":{"iopub.status.busy":"2024-05-08T14:27:33.546341Z","iopub.execute_input":"2024-05-08T14:27:33.547078Z","iopub.status.idle":"2024-05-08T14:27:33.559784Z","shell.execute_reply.started":"2024-05-08T14:27:33.547042Z","shell.execute_reply":"2024-05-08T14:27:33.558456Z"},"trusted":true},"execution_count":31,"outputs":[{"name":"stdout","text":"closest_words\n['kitten', 'puppy', 'furry', 'mannequin']\n------------------------------------------------------------\nexisting_words\n{'dog', 'kitten', 'cat'}\n------------------------------------------------------------\nsolution_words\n['puppy', 'furry', 'mannequin']\n------------------------------------------------------------\nSolution\ncat : kitten :: dog : puppy\ncat : kitten :: dog : furry\ncat : kitten :: dog : mannequin\n","output_type":"stream"}]},{"cell_type":"code","source":"embeddings.compute_and_print_analogy('man', 'he', 'woman')","metadata":{"execution":{"iopub.status.busy":"2024-05-08T14:27:33.561249Z","iopub.execute_input":"2024-05-08T14:27:33.561943Z","iopub.status.idle":"2024-05-08T14:27:33.572298Z","shell.execute_reply.started":"2024-05-08T14:27:33.561910Z","shell.execute_reply":"2024-05-08T14:27:33.571085Z"},"trusted":true},"execution_count":32,"outputs":[{"name":"stdout","text":"man : he :: woman : she\nman : he :: woman : never\n","output_type":"stream"}]},{"cell_type":"code","source":"embeddings.compute_and_print_analogy('man', 'king', 'woman')","metadata":{"execution":{"iopub.status.busy":"2024-05-08T14:27:33.574263Z","iopub.execute_input":"2024-05-08T14:27:33.575102Z","iopub.status.idle":"2024-05-08T14:27:33.585786Z","shell.execute_reply.started":"2024-05-08T14:27:33.575059Z","shell.execute_reply":"2024-05-08T14:27:33.584638Z"},"trusted":true},"execution_count":33,"outputs":[{"name":"stdout","text":"man : king :: woman : queen\nman : king :: woman : monarch\nman : king :: woman : elizabeth\n","output_type":"stream"}]},{"cell_type":"code","source":"embeddings.compute_and_print_analogy('fast', 'fastest', 'small')","metadata":{"execution":{"iopub.status.busy":"2024-05-08T14:27:33.587125Z","iopub.execute_input":"2024-05-08T14:27:33.588070Z","iopub.status.idle":"2024-05-08T14:27:33.596951Z","shell.execute_reply.started":"2024-05-08T14:27:33.588035Z","shell.execute_reply":"2024-05-08T14:27:33.596150Z"},"trusted":true},"execution_count":34,"outputs":[{"name":"stdout","text":"fast : fastest :: small : smallest\nfast : fastest :: small : largest\nfast : fastest :: small : large\n","output_type":"stream"}]},{"cell_type":"code","source":"embeddings.compute_and_print_analogy('blue', 'democrat', 'red')","metadata":{"execution":{"iopub.status.busy":"2024-05-08T14:27:33.598313Z","iopub.execute_input":"2024-05-08T14:27:33.598651Z","iopub.status.idle":"2024-05-08T14:27:33.607702Z","shell.execute_reply.started":"2024-05-08T14:27:33.598615Z","shell.execute_reply":"2024-05-08T14:27:33.606405Z"},"trusted":true},"execution_count":35,"outputs":[{"name":"stdout","text":"blue : democrat :: red : republican\nblue : democrat :: red : congressman\nblue : democrat :: red : senator\n","output_type":"stream"}]},{"cell_type":"code","source":"embeddings.compute_and_print_analogy('blue', 'color', 'dog')","metadata":{"execution":{"iopub.status.busy":"2024-05-08T14:27:33.609602Z","iopub.execute_input":"2024-05-08T14:27:33.609984Z","iopub.status.idle":"2024-05-08T14:27:33.621949Z","shell.execute_reply.started":"2024-05-08T14:27:33.609947Z","shell.execute_reply":"2024-05-08T14:27:33.620796Z"},"trusted":true},"execution_count":36,"outputs":[{"name":"stdout","text":"blue : color :: dog : animal\nblue : color :: dog : breed\nblue : color :: dog : dogs\n","output_type":"stream"}]},{"cell_type":"code","source":"embeddings.compute_and_print_analogy('cat', 'kitten', 'dog')","metadata":{"execution":{"iopub.status.busy":"2024-05-08T14:27:33.623130Z","iopub.execute_input":"2024-05-08T14:27:33.623574Z","iopub.status.idle":"2024-05-08T14:27:33.634079Z","shell.execute_reply.started":"2024-05-08T14:27:33.623535Z","shell.execute_reply":"2024-05-08T14:27:33.632909Z"},"trusted":true},"execution_count":37,"outputs":[{"name":"stdout","text":"cat : kitten :: dog : puppy\ncat : kitten :: dog : furry\ncat : kitten :: dog : mannequin\n","output_type":"stream"}]}]}