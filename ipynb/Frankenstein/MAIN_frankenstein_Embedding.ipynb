{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b6dc0fe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm_notebook\n",
    "import random\n",
    "\n",
    "from argparse import Namespace\n",
    "import os\n",
    "import collections\n",
    "from collections import Counter\n",
    "\n",
    "import string\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e55b875",
   "metadata": {},
   "source": [
    "# @@@@@ 0. Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7faf4eb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### 'TRAIN' a new model or 'LOAD' an existing model \n",
    "get_model = 'TRAIN'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8602f075",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = Namespace(\n",
    "    # Training or loading\n",
    "    get_model   = get_model,\n",
    "    \n",
    "    # Data and Path information\n",
    "    input_path  = os.getcwd(),\n",
    "    output_path = os.getcwd()+'/OUTPUT/',\n",
    "    save_model_name = 'frankenstein_model.pth',\n",
    "    # Training hyperparameters\n",
    "    embedding_size  = 50,\n",
    "    learning_rate   = 0.0001,\n",
    "    batch_size      = 32,\n",
    "    device          = 'cpu',\n",
    "    num_epochs      = 100,\n",
    "    early_stopping_criteria = 5\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f07b94d6",
   "metadata": {},
   "source": [
    "# @@@@@ 1. Data Preparation\n",
    "## The data preparation part is to perform a text-to-vectorized-minibatch pipeline: converting text inputs to vectorized minibatches.\n",
    "- ### Step 1: Creating a Vocabulary - mapping each token (words in the context of contexts) in the Frankenstein data to a numerical version of itself.\n",
    "- ### Step 2: Vectorization - going from a text dataset to a vector. The Vectorizer turns different contexts to vectors of integers with the same length.\n",
    "- ### Step 3: Group the vectorized data points into batches."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d9520c8",
   "metadata": {},
   "source": [
    "## 1.1 - Read Data\n",
    "### [Creation of the CBOW data \"frankenstein_with_splits.csv\"](https://github.com/houzhj/Machine_Learning/blob/main/ipynb/Frankenstein/frankenstein_CBOW_data.ipynb)\n",
    "\n",
    "### **Train partition**: a dataset to derive the model parameters\n",
    "### **Valid partition**: a dataset for selecting among hyperparameters and making modeling decisions\n",
    "### **Test partition**: a dataset for final evaluation and reporting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "14f85213",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>context</th>\n",
       "      <th>target</th>\n",
       "      <th>split</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>78479</th>\n",
       "      <td>head , and saw the print</td>\n",
       "      <td>i</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78352</th>\n",
       "      <td>rhone , but .</td>\n",
       "      <td>vainly</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57617</th>\n",
       "      <td>had promised to me wherever i</td>\n",
       "      <td>follow</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76671</th>\n",
       "      <td>, and that required him to</td>\n",
       "      <td>i</td>\n",
       "      <td>val</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72742</th>\n",
       "      <td>my misery , will only wonder</td>\n",
       "      <td>you</td>\n",
       "      <td>val</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             context  target  split\n",
       "78479       head , and saw the print       i   test\n",
       "78352                 rhone , but .   vainly   test\n",
       "57617  had promised to me wherever i  follow  train\n",
       "76671     , and that required him to       i    val\n",
       "72742   my misery , will only wonder     you    val"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all = pd.read_csv('frankenstein_with_splits.csv')\n",
    "df_all.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "798012d5",
   "metadata": {},
   "source": [
    "## 1.2 - The Vocabulary class\n",
    "### [A walkthrough of codes](https://github.com/houzhj/Machine_Learning/blob/main/ipynb/Frankenstein/class_Vocabulary.ipynb)\n",
    "### - Creating a mapping between the tokens and integers, in terms of dictionaries. To make this mapping reversible, create two dictionaries, one is from-token-to-index, one is from-index-to-token. Then encapsulate this mapping (bijection) into a Vocabulary class.\n",
    "### - By using the UNK token, we can handle tokens at test time that were never seen in training.\n",
    "### - There is one additional optional step for creating the vocabulary - couting the tokens appeared in the \"context\" and \"target\" columns , and ONLY add frequent tokens that apprear more than a pre-specified number to the Vocabulary, while treat infrequent tokens as UNK.  See an example with cutoff = 25 [here](https://github.com/houzhj/Machine_Learning/blob/main/ipynb/Yelp_Reviews/yelp_perceptron.ipynb).. \n",
    "### - Expected behaviors:\n",
    "#### (1) add_token(): to add new tokens to the Vocabulary\n",
    "#### (2) lookup_token(): to retrieve the index for a token\n",
    "#### (3) lookup_index(): to retrieve the token corresponding to a specific index.\n",
    "### - The Vocabulary objects will be used in the Vectorization step (discussed next). \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "81917ab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Vocabulary(object):\n",
    "    \"\"\"Class to process text and extract vocabulary for mapping\"\"\"\n",
    "    def __init__(self, token_to_idx=None, \n",
    "                 mask_token=\"<MASK>\", add_unk=True, \n",
    "                 unk_token=\"<UNK>\"):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            token_to_idx (dict): a pre-existing map of tokens to indices\n",
    "            mask_token (str): the MASK token to add into the Vocabulary; indicates\n",
    "                a position that will not be used in updating the model's parameters\n",
    "            add_unk (bool): a flag that indicates whether to add the UNK token\n",
    "            unk_token (str): the UNK token to add into the Vocabulary\n",
    "        \"\"\"\n",
    "        if token_to_idx is None:\n",
    "            token_to_idx = {}\n",
    "        self._token_to_idx = token_to_idx\n",
    "        self._idx_to_token = {idx: token \n",
    "                              for token, idx in self._token_to_idx.items()}\n",
    "        \n",
    "        self._add_unk   = add_unk\n",
    "        self._unk_token = unk_token    \n",
    "        self._mask_token = mask_token\n",
    "        \n",
    "        ### the mask_token, i.e, \"<MASK>\" is the first added token\n",
    "        self.mask_index = self.add_token(self._mask_token)\n",
    "        \n",
    "        self.unk_index  = -999\n",
    "        ### the unk_token, i.e, \"<UNK>\" is the second added token if add_unk=True\n",
    "        ### self.unk_index is changed from -999 to 1\n",
    "        if add_unk:\n",
    "            self.unk_index = self.add_token(unk_token) \n",
    "        \n",
    "\n",
    "    def add_token(self, token):\n",
    "        \"\"\"Update mapping dicts based on the token.\n",
    "\n",
    "        Args:\n",
    "            token (str): the item to add into the Vocabulary\n",
    "        Returns:\n",
    "            index (int): the integer corresponding to the token\n",
    "        \"\"\"\n",
    "        if token in self._token_to_idx:\n",
    "            index = self._token_to_idx[token]\n",
    "        else:\n",
    "            index = len(self._token_to_idx)\n",
    "            ### add a new element to _token_to_idx\n",
    "            self._token_to_idx[token] = index\n",
    "            ### add a new element to _idx_to_token\n",
    "            self._idx_to_token[index] = token\n",
    "        return index\n",
    "   \n",
    "    def lookup_token(self, token):\n",
    "        \"\"\"Retrieve the index associated with the token \n",
    "          or the UNK index if token isn't present.\n",
    "        \n",
    "        Args:\n",
    "            token (str): the token to look up \n",
    "        Returns:\n",
    "            index (int): the index corresponding to the token\n",
    "        Notes:\n",
    "            `unk_index` needs to be >=0 (having been added into the Vocabulary) \n",
    "              for the UNK functionality \n",
    "        \"\"\"\n",
    "        if self.unk_index >= 0:\n",
    "            ### .get(): return self.unk_index if the key \"token\" does not exist. \n",
    "            return self._token_to_idx.get(token, self.unk_index)\n",
    "        else:\n",
    "            return self._token_to_idx[token]\n",
    "    \n",
    "    def lookup_index(self, index):\n",
    "        \"\"\"Return the token associated with the index\n",
    "        \n",
    "        Args: \n",
    "            index (int): the index to look up\n",
    "        Returns:\n",
    "            token (str): the token corresponding to the index\n",
    "        Raises:\n",
    "            KeyError: if the index is not in the Vocabulary\n",
    "        \"\"\"\n",
    "        if index not in self._idx_to_token:\n",
    "            raise KeyError(\"the index (%d) is not in the Vocabulary\" % index)\n",
    "        return self._idx_to_token[index]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self._token_to_idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e927454b",
   "metadata": {},
   "source": [
    "## 1.3 - Vectorization\n",
    "### [A walkthrough of codes](https://github.com/houzhj/Machine_Learning/blob/main/ipynb/Frankenstein/class_Vectorizer.ipynb)\n",
    "### - The class method **from_dataframe()** is used to instantiate a CBOWVectorizer object from a dataframe.\n",
    "### - The cbow_vocab will be used as the reference for vector representation, which is a vector of integers representing the indices of the context.\n",
    "### - The class method **vectorize()** is the core functionality of the Vectorizer. It takes as an argument a string representing a row of cbow_df (joined comment and target) and returns a vectorized representation (a vector) of the string. The length of the vectors is equal to the number of tokens in the longest contexts in the data. The vectorized representation of texts with different lengths should have the same length.       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e520fc1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CBOWVectorizer(object):\n",
    "    \"\"\" The Vectorizer which coordinates the Vocabularies and puts them to use\"\"\"\n",
    "    def __init__(self, cbow_vocab):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            cbow_vocab (Vocabulary): maps words to integers\n",
    "        \"\"\"\n",
    "        self.cbow_vocab = cbow_vocab\n",
    "         \n",
    "    @classmethod\n",
    "    def from_dataframe(cls, cbow_df):\n",
    "        \"\"\"Instantiate the vectorizer from the dataset dataframe\n",
    "        \n",
    "        Args:\n",
    "            cbow_df (pandas.DataFrame): the target dataset\n",
    "        Returns:\n",
    "            an instance of the CBOWVectorizer\n",
    "        \"\"\"\n",
    "        cbow_vocab = Vocabulary()\n",
    "\n",
    "        ########## Add tokens to cbow_vocab\n",
    "        for index, row in cbow_df.iterrows():\n",
    "            for token in row.context.split(' '):\n",
    "                cbow_vocab.add_token(token)\n",
    "            cbow_vocab.add_token(row.target)\n",
    "            \n",
    "        return cls(cbow_vocab)\n",
    "\n",
    "    ### This is the key functionality of the Vectorizer.\n",
    "    ### It takes as an argument a string representing a text,\n",
    "    ### and returns a vectorized representation of the text.\n",
    "    def vectorize(self, context, vector_length=-1):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            context (str): the string of words separated by a space\n",
    "            vector_length (int): an argument for forcing the length of index vector\n",
    "        \"\"\"\n",
    "\n",
    "        indices = [self.cbow_vocab.lookup_token(token) for token in context.split(' ')]\n",
    "        if vector_length < 0:\n",
    "            vector_length = len(indices)\n",
    "        \n",
    "        ### if vector_length = len(indices), out_vector = indices\n",
    "        ### if vector_length != len(indices), the out_vector is defined in the following lines\n",
    "        out_vector = np.zeros(vector_length, dtype=np.int64)\n",
    "        out_vector[:len(indices)] = indices\n",
    "        out_vector[len(indices):] = self.cbow_vocab.mask_index\n",
    "\n",
    "        return out_vector"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cf1416d",
   "metadata": {},
   "source": [
    "## 1.4 - Batches\n",
    "### [A walkthrough of codes](https://github.com/houzhj/Machine_Learning/blob/main/ipynb/Frankenstein/batch_generator.ipynb)\n",
    "\n",
    "### - Group the vectorized data points into batches. \n",
    "### - The grouping is conducted throught the built in class **[DataLoader](https://pytorch.org/docs/stable/data.html)** in PyTorch. \n",
    "### - The class CBOWDataset inherits from the [**Dataset**](https://pytorch.org/vision/0.16/datasets.html) class. Instances of the derived class **CBOWDataset** can then be used with data loading tools like **DataLoader()** for efficient batch loading during model training.\n",
    "### - The methods \\_\\_len\\_\\_(), and \\_\\_getitem\\_\\_() are defined in class **CBOWDataset** - these magic functions are expected by the **DataLoader()**. An object equipped with \\_\\_len\\_\\_() can be passed to the len() Python build-in function. For objects equipped with \\_\\_getitem\\_\\_() we can use the standard subscript for indexing tuples and lists to access individual items. \n",
    "### - The **DataLoader()** function utilizes the return results of the \\_\\_getitem\\_\\_() method in the dataset to construct batches of data. In each iteration, **DataLoader()** calls the \\_\\_getitem\\_\\_() method of the dataset to retrieve a sample, and then combines these samples into a batch. \n",
    "### - In **DataLoader()**, the \\_\\_getitem\\_\\_() method uses an index generated by the **Sampler** object. The **Sampler** is responsible for determining the indices of samples in each batch. This index may be generated sequentially or randomly, depending on the setting of the shuffle parameter.\n",
    "### - Define a batch generator function that wraps the DataLoader and switch the data between the CPU and the GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4eb3e2be",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CBOWDataset(Dataset):\n",
    "    def __init__(self,cbow_df,vectorizer):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            cbow_df (pandas.DataFrame): the dataset\n",
    "            vectorizer (CBOWVectorizer): vectorizer instatiated from dataset\n",
    "        \"\"\"\n",
    "        self.cbow_df     = cbow_df\n",
    "        self._vectorizer = vectorizer\n",
    "        \n",
    "        ### CBOWVectorizer.vectorize() with be used with the parameter \n",
    "        ### vector_length = self._max_seq_length (the max length among all comments),\n",
    "        ### so that the vectors for different rows will have the same length.\n",
    "        measure_len = lambda context: len(context.split(\" \"))\n",
    "        self._max_seq_length = max(map(measure_len, cbow_df.context))\n",
    "        \n",
    "        self.train_df    = self.cbow_df[self.cbow_df.split=='train']\n",
    "        self.train_size  = len(self.train_df)\n",
    "\n",
    "        self.val_df      = self.cbow_df[self.cbow_df.split=='val']\n",
    "        self.validation_size = len(self.val_df)\n",
    "\n",
    "        self.test_df     = self.cbow_df[self.cbow_df.split=='test']\n",
    "        self.test_size   = len(self.test_df)\n",
    "        \n",
    "        self._lookup_dict = {'train': (self.train_df, self.train_size),\n",
    "                             'val'  : (self.val_df, self.validation_size),\n",
    "                             'test' : (self.test_df, self.test_size)}\n",
    "        self.set_split('train')\n",
    "        \n",
    "    @classmethod\n",
    "    def load_csv_and_make_vectorizer(cls,cbow_csv):\n",
    "        \"\"\"Load dataset and make a new vectorizer from scratch\n",
    "        Args:\n",
    "            cbow_csv (str): location of the dataset\n",
    "        Returns:\n",
    "            an instance of CBOWDataset\n",
    "        \"\"\"\n",
    "        cbow_csv = pd.read_csv(cbow_csv)\n",
    "        ### make vectorizer using training dataset\n",
    "        train_cbow_df   = cbow_df[cbow_df.split=='train']\n",
    "        new_vectorizer  = CBOWVectorizer.from_dataframe(train_cbow_df)\n",
    "        return cls(cbow_df,new_vectorizer)\n",
    "    \n",
    "    @classmethod\n",
    "    def load_df_and_make_vectorizer(cls,cbow_df):\n",
    "        \"\"\"Load dataset and make a new vectorizer from scratch\n",
    "        Args:\n",
    "            cbow_df: dataset\n",
    "        Returns:\n",
    "            an instance of CBOWDataset\n",
    "        \"\"\"\n",
    "        ### make vectorizer using training dataset\n",
    "        train_cbow_df  = cbow_df[cbow_df.split=='train']\n",
    "        new_vectorizer = CBOWVectorizer.from_dataframe(train_cbow_df)\n",
    "        return cls(cbow_df,new_vectorizer)\n",
    "    \n",
    "    def set_split(self, split=\"train\"):\n",
    "        \"\"\" selects the splits in the dataset using a column in the dataframe \n",
    "        Args:\n",
    "            split (str): one of \"train\", \"val\", or \"test\"\n",
    "        \"\"\"\n",
    "        self._target_split = split\n",
    "        ### when split = 'train', _target_df means the training set\n",
    "        self._target_df, self._target_size = self._lookup_dict[split]\n",
    "        \n",
    "    def __len__(self):\n",
    "        ### _target_size is defined in set_split() \n",
    "        return self._target_size        \n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"the primary entry point method for PyTorch datasets\n",
    "        \n",
    "        Args:\n",
    "            index (int): the index to the data point \n",
    "        Returns:\n",
    "            a dictionary holding the data point's features (x_data) and label (y_target)\n",
    "        \"\"\"\n",
    "        \n",
    "        row = self._target_df.iloc[index]\n",
    "\n",
    "        context_vector = \\\n",
    "            self._vectorizer.vectorize(row.context, self._max_seq_length)\n",
    "\n",
    "        target_index   = self._vectorizer.cbow_vocab.lookup_token(row.target)\n",
    "\n",
    "        return {'x_data': context_vector,\n",
    "                'y_target': target_index}\n",
    "\n",
    "    def get_vectorizer(self):\n",
    "        \"\"\" returns the vectorizer \"\"\"\n",
    "        return self._vectorizer\n",
    "    \n",
    "    def get_num_batches(self, batch_size):\n",
    "        \"\"\"Given a batch size, return the number of batches in the dataset\n",
    "        Args:\n",
    "            batch_size (int)\n",
    "        Returns:\n",
    "            number of batches in the dataset\n",
    "        \"\"\"\n",
    "        return len(self) // batch_size  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5984bd82",
   "metadata": {},
   "source": [
    "### Generator Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6f45c825",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_batches(dataset, batch_size, shuffle=True,\n",
    "                     drop_last=True, device='cpu'):\n",
    "    \"\"\"\n",
    "    A generator function which wraps the PyTorch DataLoader. It will \n",
    "      ensure each tensor is on the write device location.\n",
    "    \"\"\"\n",
    "    dataloader = DataLoader(dataset=dataset, batch_size=batch_size,\n",
    "                            shuffle=shuffle, drop_last=drop_last)\n",
    "\n",
    "    for data_dict in dataloader:\n",
    "        out_data_dict = {}\n",
    "        for name, tensor in data_dict.items():\n",
    "            out_data_dict[name] = data_dict[name].to(device)\n",
    "        yield out_data_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2085e54b",
   "metadata": {},
   "source": [
    "### An example of one data batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b81f40db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x in one batch\n",
      "tensor([[ 28,  74,  12,  27,   0,   0],\n",
      "        [ 86,  87,  88,  89,   6,   7],\n",
      "        [165, 234,  35, 235,   0,   0],\n",
      "        [187,  17, 188,   0,   0,   0],\n",
      "        [ 17,  96,  97,   7,   0,   0],\n",
      "        [  9,  10,  11,  12,   9,   0],\n",
      "        [ 14,  15,  16,  17,  18,  19],\n",
      "        [ 28, 170,   2, 171, 109, 172],\n",
      "        [134, 135,  21, 136,   6,   7],\n",
      "        [150,   2, 151,  21,  35, 152]])\n",
      "size of x_data: torch.Size([10, 6])\n",
      "------------------------------------------------------------\n",
      "y in one batch\n",
      "tensor([ 75,  86,  83,  27,   6,  13,  20,   9, 137, 112])\n",
      "size of y_data: torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "df_sample      = df_all.sample(100,random_state=100)\n",
    "dataset_sample = CBOWDataset.load_df_and_make_vectorizer(df_sample)\n",
    "batch_size     = 10\n",
    "shuffle        = True\n",
    "drop_last      = True\n",
    "dataloader     = DataLoader(dataset=dataset_sample, batch_size=batch_size,\n",
    "                            shuffle=shuffle, drop_last=drop_last)\n",
    "one_batch = next(iter(dataloader))\n",
    "print('x in one batch')\n",
    "print(one_batch['x_data'])\n",
    "print('size of x_data:', one_batch['x_data'].shape)\n",
    "print('-' * 60)\n",
    "print('y in one batch')\n",
    "print(one_batch['y_target'])\n",
    "print('size of y_data:', one_batch['y_target'].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d392d05",
   "metadata": {},
   "source": [
    "# @@@@@ 2. Model / Optimizer / Loss\n",
    "## 2.1 - The model (with nn.Embedding layer) and activate function (Softmax)\n",
    "### - The **CBOWClassifier** inherits from PyTorch’s **Module** and creates CNN classifier. The model is created using [nn.Sequential()](https://pytorch.org/docs/stable/generated/torch.nn.Sequential.html).\n",
    "### - The CBOWClassifier has three essential steps: \n",
    "- #### Indices representing the words of the context are used with an nn.Embedding(.) layer to create vectors for each word in the context.\n",
    "- #### Combine the vectors in some way such that it captures the overall context. In the example below, we sum over the vectors. However, other options include taking the max, the average, or even using a Multilayer Perceptron on top. \n",
    "- #### The context vector is used with a nn.Linear(.) layer to compute a prediction vector. This prediction vector is a probability distribution over the entire vocabulary. The largest (most probable) value in the prediction vector indicates the likely prediction for the target word—the center word missing from the context.\n",
    "\n",
    "### - The  [nn.Embedding( )](https://pytorch.org/docs/stable/generated/torch.nn.Embedding.html) layer is parameterized primarily by two numbers\n",
    "- #### the number of embeddings (size of the vocabulary)\n",
    "- #### the size of the embeddings (embedding dimension)\n",
    "\n",
    "### - Some details about embedding layers is discussed [in this study](https://github.com/houzhj/Machine_Learning/blob/main/ipynb/Frankenstein/Embedding_layer.ipynb).\n",
    "\n",
    "### - In PyTorch, the **nn.Module** class implements the **\\_\\_call\\_\\_** method, enabling model instances to be invoked like functions. Calling an instance from nn.Module with a set of arguments ends up calling a method named forward with the same argument. The forward function executes the forward computation, while **\\_\\_call\\_\\_** does other important chores before and after calling forward. In general, the correct way to call the module as a function is to use **Classifier(input)**, rather than **Classifier.forward(input)**, although they will produce the same outputs (silient errors, since there are steps not called properly if just using **forward(...)** directly).\n",
    "### - The **forward()** method allows for the softmax function (working as the nonlinear activation function) to be optionally applied. Here the default is do not apply the softmax function. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7aae807a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CBOWClassifier(nn.Module):\n",
    "    \n",
    "    def __init__(self, vocabulary_size, embedding_size, padding_idx=0):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            vocabulary_size (int): number of vocabulary items, controls the\n",
    "                                   number of embeddings and prediction vector size\n",
    "                                   \n",
    "            embedding_size (int): size of the embeddings (embedding dimension)\n",
    "            \n",
    "            padding_idx (int): default 0; Embedding will not use this index.\n",
    "                               Used as a sentinel value to the Embedding \n",
    "                               layer for situations where the data points might \n",
    "                               not all be the same length. The layer forces both the \n",
    "                               vector corresponding to that index and its gradients \n",
    "                               to be all 0s.\n",
    "        \"\"\"\n",
    "        super(CBOWClassifier, self).__init__()\n",
    "        \n",
    "        self.embedding =  nn.Embedding(num_embeddings = vocabulary_size, \n",
    "                                       embedding_dim  = embedding_size,\n",
    "                                       padding_idx    = padding_idx)\n",
    "        self.fc1 = nn.Linear(in_features=embedding_size,\n",
    "                             out_features=vocabulary_size)\n",
    "\n",
    "    def forward(self, x_in, apply_softmax=False):\n",
    "        \"\"\"The forward pass of the classifier\n",
    "        \n",
    "        Args:\n",
    "            x_in (torch.Tensor): an input data tensor. \n",
    "                x_in.shape should be (batch, input_dim)\n",
    "            apply_softmax (bool): a flag for the softmax activation\n",
    "                should be false if used with the Cross Entropy losses\n",
    "        Returns:\n",
    "            the resulting tensor. tensor.shape should be (batch, output_dim)\n",
    "        \"\"\"\n",
    "        x_embedded_sum = F.dropout(input = self.embedding(x_in).sum(dim=1), \n",
    "                                   p     = 0.3)\n",
    "        y_out          = self.fc1(x_embedded_sum)\n",
    "        \n",
    "        if apply_softmax:\n",
    "            y_out = F.softmax(y_out, dim=1)\n",
    "            \n",
    "        return y_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9da99870",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset    = CBOWDataset.load_df_and_make_vectorizer(df_all)\n",
    "dataloader = DataLoader(dataset = dataset,\n",
    "                        batch_size = 128,\n",
    "                        shuffle    = True,\n",
    "                        drop_last  = True)\n",
    "vectorizer = dataset.get_vectorizer()\n",
    "\n",
    "classifier = CBOWClassifier(vocabulary_size = len(vectorizer.cbow_vocab), \n",
    "                            embedding_size  = args.embedding_size, \n",
    "                            padding_idx     = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b160b93",
   "metadata": {},
   "source": [
    "## 2.2 - The loss function (Binary Cross-Entropy)\n",
    "### - The loss - \"how far off\" the model predictions are from the target.\n",
    "### - The gradient of the loss function - a signal for “how much” the parameters should change (according to \"how much\" each parameter contributed to the loss function).\n",
    "### - As mentioned, the loss function should be appropriate for the activation function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ab10c362",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_func = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e9667bd",
   "metadata": {},
   "source": [
    "## 2.3 - The optimizer and scheduler\n",
    "### The initialized state of the classifier\n",
    "### Using [torch.nn.Module.parameters](https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module.parameters)\n",
    "#### These are the tensors that the optimizer will get. After calling **model.backward()** the parameters are populated with their grad, and the optimizer then updates their values accordingly during the **optimizer.step()** call.\n",
    "#### The requires_grad = True argument is telling PyTorch to track the entire family tree of tensors resulting from operations on *parameters*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c4c05c30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CBOWClassifier(\n",
       "  (embedding): Embedding(6138, 50, padding_idx=0)\n",
       "  (fc1): Linear(in_features=50, out_features=6138, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c0c7c5f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classifier.parameters() includes 3 sets of parameters.\n",
      "------------------------------------------------------------\n",
      "Parameter 1: embedding.weight\n",
      "Shape: [6138, 50]\n",
      "------------------------------------------------------------\n",
      "Parameter 2: fc1.weight\n",
      "Shape: [6138, 50]\n",
      "------------------------------------------------------------\n",
      "Parameter 3: fc1.bias\n",
      "Shape: [6138]\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "n_param = len(list(classifier.parameters()))\n",
    "print(f\"classifier.parameters() includes {n_param} sets of parameters.\")\n",
    "print(\"-\"*60)\n",
    "\n",
    "i = 1\n",
    "for name, param in classifier.named_parameters():\n",
    "    print(f\"Parameter {i}: {name}\")\n",
    "    i+=1\n",
    "    print(\"Shape:\", list(param.shape))\n",
    "    print(\"-\"*60)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b27ee849",
   "metadata": {},
   "source": [
    "### Define the [Adam](https://pytorch.org/docs/stable/generated/torch.optim.Adam.html) optimizer \n",
    "#### - the learning rate is set adaptively\n",
    "#### - it is not sensitive to the scaling of the parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8367a469",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(classifier.parameters(), lr=args.learning_rate)"
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "id": "bb07e0f5",
   "metadata": {},
   "source": [
    "### Apply a scheduler for adjusting learning rate\n",
    "### - [torch.optim.lr_scheduler](https://pytorch.org/docs/stable/optim.html) provides several methods to adjust the learning rate based on the number of epochs.\n",
    "### - [torch.optim.lr_scheduler.ReduceLROnPlateau](https://pytorch.org/docs/stable/generated/torch.optim.lr_scheduler.ReduceLROnPlateau.html#torch.optim.lr_scheduler.ReduceLROnPlateau) allows dynamic learning rate reducing based on some validation measurements.\n",
    "### - This scheduler reads a metrics quantity and if no improvement is seen for a ‘patience’ number of epochs, the learning rate is reduced.\n",
    "### - Parameters:\n",
    "1. **mode(str)**: In \"min\" mode, lr will be reduced when the quantity monitored has stopped decreasing; in \"max\" mode it will be reduced when the quantity monitored has stopped increasing. Default: 0.1.\n",
    "2. **factor(float)**: Factor by which the learning rate will be reduced. new_lr = lr * factor. Default: 0.1.\n",
    "3. **patience (int)**: Number of epochs with no improvement after which learning rate will be reduced. For example, if patience = 2, then we will ignore the first 2 epochs with no improvement, and will only decrease the LR after the 3rd epoch if the loss still hasn’t improved then. Default: 10.\n",
    "4. **threshold (float)** – Threshold for measuring the new optimum, to only focus on significant changes. Default: 1e-4.\n",
    "\n",
    "### - A **scheduler.step(val_loss)** method is called at the end of each epoch to execute the update of the learning rate. The parameters “val_loss” represents the loss (or other monitoring metric) computed for the model on the validation set. This loss value is typically used by the scheduler to assess the model's performance on the validation set and update the learning rate accordingly.\n",
    "![image.png](attachment:image.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "55f32949",
   "metadata": {},
   "outputs": [],
   "source": [
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer=optimizer,\n",
    "                                                 mode='min', \n",
    "                                                 factor=0.5,\n",
    "                                                 patience=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc5c8df3",
   "metadata": {},
   "source": [
    "# @@@@@ 3. Training Routine\n",
    "## 3.1 - Helper function: tracking the training state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cc8e7181",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_train_state(args):\n",
    "    train_state_dict = {'stop_early'    : False,\n",
    "                        'early_stopping_step'     : 0,\n",
    "                        'early_stopping_best_val' : 1e8,\n",
    "                        'learning_rate' : args.learning_rate,\n",
    "                        'epoch_index'   : 0,\n",
    "                        'train_loss'    : [],\n",
    "                        'train_acc'     : [],\n",
    "                        'val_loss'      : [],\n",
    "                        'val_acc'       : [],\n",
    "                        'test_loss'     : -1,\n",
    "                        'test_acc'      : -1,\n",
    "                        'model_filename': args.save_model_name\n",
    "                       }\n",
    "    return train_state_dict\n",
    "\n",
    "def update_train_state(args, model, train_state):\n",
    "    \"\"\"\n",
    "    Handle the training state updates.\n",
    "     - Early Stopping: Prevent overfitting.\n",
    "     - Model Checkpoint: Model is saved if the model is better\n",
    "    \n",
    "    Args:\n",
    "        args:  arguments\n",
    "        model: model to train\n",
    "        train_state: a dictionary representing the training state values\n",
    "    \n",
    "    Returns:\n",
    "        a new train_state\n",
    "    \"\"\"\n",
    "\n",
    "    # Save the first model\n",
    "    if train_state['epoch_index'] == 0:\n",
    "        torch.save(model.state_dict(), train_state['model_filename'])\n",
    "        train_state['stop_early'] = False\n",
    "\n",
    "    # Save model if performance improved\n",
    "    elif train_state['epoch_index'] >= 1:\n",
    "        loss_tm1, loss_t = train_state['val_loss'][-2:]\n",
    "\n",
    "        # If loss increased (not a better model)\n",
    "        if loss_t >= train_state['early_stopping_best_val']:\n",
    "            # Update early_stopping_step\n",
    "            train_state['early_stopping_step'] += 1\n",
    "        # If loss decreased\n",
    "        else:\n",
    "            # Save the best model and update the early_stopping_best_val\n",
    "            if loss_t < train_state['early_stopping_best_val']:\n",
    "                torch.save(model.state_dict(), train_state['model_filename'])\n",
    "                train_state['early_stopping_best_val'] = loss_t\n",
    "\n",
    "            # Reset early stopping step\n",
    "            train_state['early_stopping_step'] = 0\n",
    "\n",
    "        # Stop early ?\n",
    "        # In the main training loop, if train_state['stop_early']: break\n",
    "        train_state['stop_early'] = \\\n",
    "            train_state['early_stopping_step'] >= args.early_stopping_criteria\n",
    "\n",
    "    return train_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7a7cf65c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'stop_early': False,\n",
       " 'early_stopping_step': 0,\n",
       " 'early_stopping_best_val': 100000000.0,\n",
       " 'learning_rate': 0.0001,\n",
       " 'epoch_index': 0,\n",
       " 'train_loss': [],\n",
       " 'train_acc': [],\n",
       " 'val_loss': [],\n",
       " 'val_acc': [],\n",
       " 'test_loss': -1,\n",
       " 'test_acc': -1,\n",
       " 'model_filename': 'frankenstein_model.pth'}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_state = init_train_state(args)\n",
    "train_state"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d030c5e",
   "metadata": {},
   "source": [
    "## 3.2 - Helper function: compute accurary rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "46fc6736",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_accuracy(y_pred, y_target, device):\n",
    "    y_target = y_target.to(device)\n",
    "\n",
    "    ##### tensor.max(dim=1): the results include two output tensors (max, max_indices)\n",
    "    _, y_pred_indices = y_pred.to(device).max(dim=1)\n",
    "    n_correct = torch.eq(y_pred_indices, y_target).sum().item()\n",
    "    return n_correct / len(y_pred_indices) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "13a95ceb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.return_types.max(\n",
       "values=tensor([5.2722, 7.3006, 5.5701, 5.4444, 5.4436, 5.4143, 6.1194, 5.3457, 5.7081,\n",
       "        6.4271, 6.3084, 6.0750, 6.7630, 8.5870, 6.2919, 5.6349, 5.2500, 7.0565,\n",
       "        5.9402, 3.2230, 6.5936, 5.3287, 5.1957, 6.2334, 4.7405, 7.4073, 9.2119,\n",
       "        5.5677, 6.4290, 8.3720, 4.8541, 5.6777, 4.4416, 6.5876, 5.4766, 6.6695,\n",
       "        4.7666, 7.5417, 6.1707, 4.5058, 5.6723, 6.4595, 6.7786, 5.9955, 4.2386,\n",
       "        4.8079, 6.6088, 6.7569, 6.0849, 6.0443, 8.3187, 7.5443, 5.4498, 5.7531,\n",
       "        6.2160, 3.8766, 7.1031, 4.5173, 5.8951, 6.6530, 4.5719, 6.4872, 4.5321,\n",
       "        9.2828, 5.0392, 5.4881, 3.9562, 7.2280, 4.5088, 5.5356, 4.8340, 5.0083,\n",
       "        5.4542, 4.3606, 6.4480, 3.8827, 6.3926, 4.6454, 4.2581, 4.1192, 4.6736,\n",
       "        5.7860, 8.6144, 5.4454, 5.6326, 5.1133, 7.7902, 7.4259, 5.4869, 6.4529,\n",
       "        6.1982, 5.1840, 5.0882, 5.0448, 5.4651, 5.9979, 4.1397, 6.0450, 4.1738,\n",
       "        7.0834, 6.1960, 4.5911, 6.7608, 5.9308, 4.7050, 5.7375, 5.9477, 4.6540,\n",
       "        6.5337, 7.2684, 6.8376, 5.6587, 6.5876, 5.5461, 5.9609, 4.9102, 7.4257,\n",
       "        6.0685, 6.5730, 4.8356, 7.4668, 5.5932, 5.6382, 5.4074, 6.0798, 6.9974,\n",
       "        5.6896, 4.9243], grad_fn=<MaxBackward0>),\n",
       "indices=tensor([2221, 3181, 4644, 4475, 1122, 1245, 2760, 4473, 4366,  522,  727, 1079,\n",
       "        2752, 2286, 1991,  677, 5715, 2623, 3397, 3437,  912, 3779, 5645, 1832,\n",
       "         602, 4576, 3394, 1177, 5150, 3577, 6012, 5426, 5445, 4086, 5946, 1933,\n",
       "         352, 5308,  927, 2526,  187, 5847, 5948,   13, 3410, 5279, 5235, 3185,\n",
       "        3262, 5426, 5423, 5081, 3253, 1173,  470, 2125, 4501, 2614, 5673,  690,\n",
       "        2672, 2986,   82,  853, 5003, 2916, 5445, 3115, 2418, 1325, 4242, 3654,\n",
       "        5478, 1946, 1205, 2807, 4407, 3532,  752, 1015, 4705, 5428, 3195, 3211,\n",
       "        4311, 5347, 3154, 1981, 2388,  175, 3297, 2568, 3154, 2241, 4388,  205,\n",
       "         993,  519, 4158, 3854, 1567, 3607, 4835, 1369, 4218, 1891, 4864,  376,\n",
       "        3577,  782, 4463, 5760, 3198, 5323, 1224, 5275,  176,  402, 2013, 5240,\n",
       "         489, 5200,  804, 3714, 3157, 3955, 4737,  339]))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##### An example - using classifier with initialized (random) parameters\n",
    "one_batch = next(iter(dataloader))\n",
    "classifier(one_batch['x_data']).max(dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f99765d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "targets: tensor([   4, 2926,  398, 3277, 3379, 3407,  796,   50,   36, 5114, 2406,   72,\n",
      "         319, 2104,  326,  225, 4969,  215,   23,   44,  225,  319,   30, 4048,\n",
      "         349,   27,  290,  292, 2993,   33,    2,  239, 5784,   23,  319,    8,\n",
      "        1169, 3370,    2, 5072,  160,  909,  390, 4643,  326,   15,   48, 4123,\n",
      "        3349, 1388, 1168,   23, 1452,   85,   50,   37,   19,   34, 1810,  417,\n",
      "        2540,  215,  941,   33, 1291,   90,   49, 4236,   15, 3372, 2142, 4816,\n",
      "         123, 3288,    2, 1868, 1288,   90,  358,   44,   49,   48,  319,   15,\n",
      "           2,  230,    2,   19, 1445, 2821, 1003,   85,  620,   44,  215,   50,\n",
      "         331,    2,   33,  225,   60,   49,    4, 1849, 2920,  760, 1789,    4,\n",
      "           8, 2241,   72, 1175,  144, 1291,  239, 1466,  715,   19,  230, 3036,\n",
      "          72,  806,  666,  282,   72,   30,  298,   15])\n",
      "--------------------------------------------------------------------------------\n",
      "pred: tensor([1515, 5581, 5502, 3462, 3798, 1245, 5372, 4453, 6016,  522, 2328, 3617,\n",
      "        3572, 3577, 3320, 1367, 2374, 2623, 1746, 3253, 2640, 6039, 3017,  298,\n",
      "        1400, 5673, 5692, 6124, 4699, 6057, 5407, 3654, 2414,  990, 1327,  601,\n",
      "        3029, 1992, 5143, 1599, 5150, 5847, 2986, 5409,   81, 2052, 4672, 3643,\n",
      "        3262,  175, 5868, 1828, 2010, 2186,  750, 5420, 1054, 4479, 4794, 3998,\n",
      "        4317,  368,   82, 5328, 4939, 2916, 1501, 3396,  638, 2225, 1031, 5648,\n",
      "        4404, 3572, 1576, 4304, 4245, 5569, 1034, 1961, 1536,  811, 5195, 5178,\n",
      "        5839,  628, 4288, 3889, 3046, 5833,  589, 4552, 3396,   23,  167, 1931,\n",
      "        5514, 1763, 5529, 4866, 6133, 3613, 5211, 5668, 5286, 5663, 3631, 5230,\n",
      "        5486, 2160, 1155, 1031,  902,  366, 4897,  872,  942, 2555, 2340, 5920,\n",
      "         804, 5003, 3438, 5325, 4880, 2970, 4199,  339])\n",
      "--------------------------------------------------------------------------------\n",
      "accurary rate: 0.0\n"
     ]
    }
   ],
   "source": [
    "outputs = classifier(one_batch['x_data'])\n",
    "_, pred = outputs.max(dim=1)  \n",
    "targets = one_batch['y_target']\n",
    "print('targets:', targets)\n",
    "print('-'*80)\n",
    "print('pred:',pred)\n",
    "print('-'*80)\n",
    "print('accurary rate:',compute_accuracy(outputs,targets,device='cpu'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d3853f6",
   "metadata": {},
   "source": [
    "## 3.3 - Training loop\n",
    "### - The training loop updates the model parameters so that it improves over time.\n",
    "### - The training loop is composed of two loops: an inner loop over batches in the dataset, and an outer loop, which repeats the inner loop a number of times.\n",
    "### - The inner loop (batch), losses are computed for each batch, and the optimizer is used to update the model parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8ac0988e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_train_state(train_state):\n",
    "    print('Train Loss:',round(train_state['train_loss'][-1],5))\n",
    "    print('Train Accuracy:',round(train_state['train_acc'][-1],5))\n",
    "    print('Valid Loss:',round(train_state['val_loss'][-1],5))\n",
    "    print('Valid Accuracy:',round(train_state['val_acc'][-1],5))\n",
    "    print('early_stopping_best_val:',round(train_state['early_stopping_best_val'],5))\n",
    "    print('early_stopping_step:',train_state['early_stopping_step'])\n",
    "    print('stop_early:',train_state['stop_early'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3f069710",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------\n",
      "Epoch 0...\n",
      "Training Iteration...\n",
      "Validation Iteration...\n",
      "Current lr: 0.0001\n",
      "Train Loss: 8.94462\n",
      "Train Accuracy: 1.86649\n",
      "Valid Loss: 8.16521\n",
      "Valid Accuracy: 4.68382\n",
      "early_stopping_best_val: 100000000.0\n",
      "early_stopping_step: 0\n",
      "stop_early: False\n",
      "------------------------------------------------------------\n",
      "Epoch 1...\n",
      "Training Iteration...\n",
      "Validation Iteration...\n",
      "Current lr: 0.0001\n",
      "Train Loss: 7.70845\n",
      "Train Accuracy: 7.83613\n",
      "Valid Loss: 7.4813\n",
      "Valid Accuracy: 8.67647\n",
      "early_stopping_best_val: 7.4813\n",
      "early_stopping_step: 0\n",
      "stop_early: False\n",
      "------------------------------------------------------------\n",
      "Epoch 2...\n",
      "Training Iteration...\n",
      "Validation Iteration...\n",
      "Current lr: 0.0001\n",
      "Train Loss: 7.18826\n",
      "Train Accuracy: 9.77193\n",
      "Valid Loss: 7.22953\n",
      "Valid Accuracy: 9.74265\n",
      "early_stopping_best_val: 7.22953\n",
      "early_stopping_step: 0\n",
      "stop_early: False\n",
      "------------------------------------------------------------\n",
      "Epoch 3...\n",
      "Training Iteration...\n",
      "Validation Iteration...\n",
      "Current lr: 0.0001\n",
      "Train Loss: 6.86405\n",
      "Train Accuracy: 10.72644\n",
      "Valid Loss: 7.0521\n",
      "Valid Accuracy: 10.55882\n",
      "early_stopping_best_val: 7.0521\n",
      "early_stopping_step: 0\n",
      "stop_early: False\n",
      "------------------------------------------------------------\n",
      "Epoch 4...\n",
      "Training Iteration...\n",
      "Validation Iteration...\n",
      "Current lr: 0.0001\n",
      "Train Loss: 6.64485\n",
      "Train Accuracy: 11.42736\n",
      "Valid Loss: 6.92557\n",
      "Valid Accuracy: 11.27941\n",
      "early_stopping_best_val: 6.92557\n",
      "early_stopping_step: 0\n",
      "stop_early: False\n",
      "------------------------------------------------------------\n",
      "Epoch 5...\n",
      "Training Iteration...\n",
      "Validation Iteration...\n",
      "Current lr: 0.0001\n",
      "Train Loss: 6.46035\n",
      "Train Accuracy: 12.04795\n",
      "Valid Loss: 6.83149\n",
      "Valid Accuracy: 12.13235\n",
      "early_stopping_best_val: 6.83149\n",
      "early_stopping_step: 0\n",
      "stop_early: False\n",
      "------------------------------------------------------------\n",
      "Epoch 6...\n",
      "Training Iteration...\n",
      "Validation Iteration...\n",
      "Current lr: 0.0001\n",
      "Train Loss: 6.31334\n",
      "Train Accuracy: 12.75517\n",
      "Valid Loss: 6.77769\n",
      "Valid Accuracy: 11.94853\n",
      "early_stopping_best_val: 6.77769\n",
      "early_stopping_step: 0\n",
      "stop_early: False\n",
      "------------------------------------------------------------\n",
      "Epoch 7...\n",
      "Training Iteration...\n",
      "Validation Iteration...\n",
      "Current lr: 0.0001\n",
      "Train Loss: 6.19452\n",
      "Train Accuracy: 13.17099\n",
      "Valid Loss: 6.72598\n",
      "Valid Accuracy: 12.5\n",
      "early_stopping_best_val: 6.72598\n",
      "early_stopping_step: 0\n",
      "stop_early: False\n",
      "------------------------------------------------------------\n",
      "Epoch 8...\n",
      "Training Iteration...\n",
      "Validation Iteration...\n",
      "Current lr: 0.0001\n",
      "Train Loss: 6.09431\n",
      "Train Accuracy: 13.65927\n",
      "Valid Loss: 6.66011\n",
      "Valid Accuracy: 13.30147\n",
      "early_stopping_best_val: 6.66011\n",
      "early_stopping_step: 0\n",
      "stop_early: False\n",
      "------------------------------------------------------------\n",
      "Epoch 9...\n",
      "Training Iteration...\n",
      "Validation Iteration...\n",
      "Current lr: 0.0001\n",
      "Train Loss: 6.00044\n",
      "Train Accuracy: 13.91287\n",
      "Valid Loss: 6.65481\n",
      "Valid Accuracy: 13.5\n",
      "early_stopping_best_val: 6.65481\n",
      "early_stopping_step: 0\n",
      "stop_early: False\n",
      "------------------------------------------------------------\n",
      "Epoch 10...\n",
      "Training Iteration...\n",
      "Validation Iteration...\n",
      "Current lr: 0.0001\n",
      "Train Loss: 5.92071\n",
      "Train Accuracy: 14.0877\n",
      "Valid Loss: 6.59684\n",
      "Valid Accuracy: 13.60294\n",
      "early_stopping_best_val: 6.59684\n",
      "early_stopping_step: 0\n",
      "stop_early: False\n",
      "------------------------------------------------------------\n",
      "Epoch 11...\n",
      "Training Iteration...\n",
      "Validation Iteration...\n",
      "Current lr: 0.0001\n",
      "Train Loss: 5.84846\n",
      "Train Accuracy: 14.28459\n",
      "Valid Loss: 6.59429\n",
      "Valid Accuracy: 13.55882\n",
      "early_stopping_best_val: 6.59429\n",
      "early_stopping_step: 0\n",
      "stop_early: False\n",
      "------------------------------------------------------------\n",
      "Epoch 12...\n",
      "Training Iteration...\n",
      "Validation Iteration...\n",
      "Current lr: 0.0001\n",
      "Train Loss: 5.78386\n",
      "Train Accuracy: 14.4106\n",
      "Valid Loss: 6.57276\n",
      "Valid Accuracy: 14.01471\n",
      "early_stopping_best_val: 6.57276\n",
      "early_stopping_step: 0\n",
      "stop_early: False\n",
      "------------------------------------------------------------\n",
      "Epoch 13...\n",
      "Training Iteration...\n",
      "Validation Iteration...\n",
      "Current lr: 0.0001\n",
      "Train Loss: 5.72746\n",
      "Train Accuracy: 14.70042\n",
      "Valid Loss: 6.55492\n",
      "Valid Accuracy: 13.66176\n",
      "early_stopping_best_val: 6.55492\n",
      "early_stopping_step: 0\n",
      "stop_early: False\n",
      "------------------------------------------------------------\n",
      "Epoch 14...\n",
      "Training Iteration...\n",
      "Validation Iteration...\n",
      "Current lr: 0.0001\n",
      "Train Loss: 5.6707\n",
      "Train Accuracy: 14.79492\n",
      "Valid Loss: 6.53325\n",
      "Valid Accuracy: 14.25\n",
      "early_stopping_best_val: 6.53325\n",
      "early_stopping_step: 0\n",
      "stop_early: False\n",
      "------------------------------------------------------------\n",
      "Epoch 15...\n",
      "Training Iteration...\n",
      "Validation Iteration...\n",
      "Current lr: 0.0001\n",
      "Train Loss: 5.61621\n",
      "Train Accuracy: 14.9036\n",
      "Valid Loss: 6.52494\n",
      "Valid Accuracy: 14.21324\n",
      "early_stopping_best_val: 6.52494\n",
      "early_stopping_step: 0\n",
      "stop_early: False\n",
      "------------------------------------------------------------\n",
      "Epoch 16...\n",
      "Training Iteration...\n",
      "Validation Iteration...\n",
      "Current lr: 0.0001\n",
      "Train Loss: 5.57395\n",
      "Train Accuracy: 14.90675\n",
      "Valid Loss: 6.51635\n",
      "Valid Accuracy: 14.25\n",
      "early_stopping_best_val: 6.51635\n",
      "early_stopping_step: 0\n",
      "stop_early: False\n",
      "------------------------------------------------------------\n",
      "Epoch 17...\n",
      "Training Iteration...\n",
      "Validation Iteration...\n",
      "Current lr: 0.0001\n",
      "Train Loss: 5.52553\n",
      "Train Accuracy: 15.05166\n",
      "Valid Loss: 6.51147\n",
      "Valid Accuracy: 14.45588\n",
      "early_stopping_best_val: 6.51147\n",
      "early_stopping_step: 0\n",
      "stop_early: False\n",
      "------------------------------------------------------------\n",
      "Epoch 18...\n",
      "Training Iteration...\n",
      "Validation Iteration...\n",
      "Current lr: 0.0001\n",
      "Train Loss: 5.48663\n",
      "Train Accuracy: 15.13987\n",
      "Valid Loss: 6.47582\n",
      "Valid Accuracy: 14.25735\n",
      "early_stopping_best_val: 6.47582\n",
      "early_stopping_step: 0\n",
      "stop_early: False\n",
      "------------------------------------------------------------\n",
      "Epoch 19...\n",
      "Training Iteration...\n",
      "Validation Iteration...\n",
      "Current lr: 0.0001\n",
      "Train Loss: 5.44761\n",
      "Train Accuracy: 15.2517\n",
      "Valid Loss: 6.47392\n",
      "Valid Accuracy: 14.65441\n",
      "early_stopping_best_val: 6.47392\n",
      "early_stopping_step: 0\n",
      "stop_early: False\n",
      "------------------------------------------------------------\n",
      "Epoch 20...\n",
      "Training Iteration...\n",
      "Validation Iteration...\n",
      "Current lr: 0.0001\n",
      "Train Loss: 5.41509\n",
      "Train Accuracy: 15.41394\n",
      "Valid Loss: 6.47305\n",
      "Valid Accuracy: 14.56618\n",
      "early_stopping_best_val: 6.47305\n",
      "early_stopping_step: 0\n",
      "stop_early: False\n",
      "------------------------------------------------------------\n",
      "Epoch 21...\n",
      "Training Iteration...\n",
      "Validation Iteration...\n",
      "Current lr: 0.0001\n",
      "Train Loss: 5.37471\n",
      "Train Accuracy: 15.50214\n",
      "Valid Loss: 6.47597\n",
      "Valid Accuracy: 14.54412\n",
      "early_stopping_best_val: 6.47305\n",
      "early_stopping_step: 1\n",
      "stop_early: False\n",
      "------------------------------------------------------------\n",
      "Epoch 22...\n",
      "Training Iteration...\n",
      "Validation Iteration...\n",
      "Current lr: 0.0001\n",
      "Train Loss: 5.34374\n",
      "Train Accuracy: 15.45961\n",
      "Valid Loss: 6.46168\n",
      "Valid Accuracy: 14.69853\n",
      "early_stopping_best_val: 6.46168\n",
      "early_stopping_step: 0\n",
      "stop_early: False\n",
      "------------------------------------------------------------\n",
      "Epoch 23...\n",
      "Training Iteration...\n",
      "Validation Iteration...\n",
      "Current lr: 0.0001\n",
      "Train Loss: 5.31314\n",
      "Train Accuracy: 15.65965\n",
      "Valid Loss: 6.45959\n",
      "Valid Accuracy: 14.64706\n",
      "early_stopping_best_val: 6.45959\n",
      "early_stopping_step: 0\n",
      "stop_early: False\n",
      "------------------------------------------------------------\n",
      "Epoch 24...\n",
      "Training Iteration...\n",
      "Validation Iteration...\n",
      "Current lr: 0.0001\n",
      "Train Loss: 5.28489\n",
      "Train Accuracy: 15.60137\n",
      "Valid Loss: 6.44702\n",
      "Valid Accuracy: 14.75\n",
      "early_stopping_best_val: 6.44702\n",
      "early_stopping_step: 0\n",
      "stop_early: False\n",
      "------------------------------------------------------------\n",
      "Epoch 25...\n",
      "Training Iteration...\n",
      "Validation Iteration...\n",
      "Current lr: 0.0001\n",
      "Train Loss: 5.2586\n",
      "Train Accuracy: 15.63445\n",
      "Valid Loss: 6.45313\n",
      "Valid Accuracy: 14.94118\n",
      "early_stopping_best_val: 6.44702\n",
      "early_stopping_step: 1\n",
      "stop_early: False\n",
      "------------------------------------------------------------\n",
      "Epoch 26...\n",
      "Training Iteration...\n",
      "Validation Iteration...\n",
      "Current lr: 5e-05\n",
      "Train Loss: 5.22763\n",
      "Train Accuracy: 15.81401\n",
      "Valid Loss: 6.46232\n",
      "Valid Accuracy: 14.52941\n",
      "early_stopping_best_val: 6.44702\n",
      "early_stopping_step: 2\n",
      "stop_early: False\n",
      "------------------------------------------------------------\n",
      "Epoch 27...\n",
      "Training Iteration...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Iteration...\n",
      "Current lr: 5e-05\n",
      "Train Loss: 5.19339\n",
      "Train Accuracy: 15.91167\n",
      "Valid Loss: 6.43423\n",
      "Valid Accuracy: 14.94853\n",
      "early_stopping_best_val: 6.43423\n",
      "early_stopping_step: 0\n",
      "stop_early: False\n",
      "------------------------------------------------------------\n",
      "Epoch 28...\n",
      "Training Iteration...\n",
      "Validation Iteration...\n",
      "Current lr: 5e-05\n",
      "Train Loss: 5.17525\n",
      "Train Accuracy: 15.92269\n",
      "Valid Loss: 6.43914\n",
      "Valid Accuracy: 14.86765\n",
      "early_stopping_best_val: 6.43423\n",
      "early_stopping_step: 1\n",
      "stop_early: False\n",
      "------------------------------------------------------------\n",
      "Epoch 29...\n",
      "Training Iteration...\n",
      "Validation Iteration...\n",
      "Current lr: 2.5e-05\n",
      "Train Loss: 5.15914\n",
      "Train Accuracy: 16.05658\n",
      "Valid Loss: 6.43602\n",
      "Valid Accuracy: 14.80147\n",
      "early_stopping_best_val: 6.43423\n",
      "early_stopping_step: 2\n",
      "stop_early: False\n",
      "------------------------------------------------------------\n",
      "Epoch 30...\n",
      "Training Iteration...\n",
      "Validation Iteration...\n",
      "Current lr: 2.5e-05\n",
      "Train Loss: 5.14602\n",
      "Train Accuracy: 16.07548\n",
      "Valid Loss: 6.43068\n",
      "Valid Accuracy: 14.97059\n",
      "early_stopping_best_val: 6.43068\n",
      "early_stopping_step: 0\n",
      "stop_early: False\n",
      "------------------------------------------------------------\n",
      "Epoch 31...\n",
      "Training Iteration...\n",
      "Validation Iteration...\n",
      "Current lr: 2.5e-05\n",
      "Train Loss: 5.14068\n",
      "Train Accuracy: 15.89749\n",
      "Valid Loss: 6.42852\n",
      "Valid Accuracy: 14.94853\n",
      "early_stopping_best_val: 6.42852\n",
      "early_stopping_step: 0\n",
      "stop_early: False\n",
      "------------------------------------------------------------\n",
      "Epoch 32...\n",
      "Training Iteration...\n",
      "Validation Iteration...\n",
      "Current lr: 2.5e-05\n",
      "Train Loss: 5.13442\n",
      "Train Accuracy: 16.11486\n",
      "Valid Loss: 6.43603\n",
      "Valid Accuracy: 14.80147\n",
      "early_stopping_best_val: 6.42852\n",
      "early_stopping_step: 1\n",
      "stop_early: False\n",
      "------------------------------------------------------------\n",
      "Epoch 33...\n",
      "Training Iteration...\n",
      "Validation Iteration...\n",
      "Current lr: 1.25e-05\n",
      "Train Loss: 5.12674\n",
      "Train Accuracy: 16.22354\n",
      "Valid Loss: 6.43787\n",
      "Valid Accuracy: 14.99265\n",
      "early_stopping_best_val: 6.42852\n",
      "early_stopping_step: 2\n",
      "stop_early: False\n",
      "------------------------------------------------------------\n",
      "Epoch 34...\n",
      "Training Iteration...\n",
      "Validation Iteration...\n",
      "Current lr: 1.25e-05\n",
      "Train Loss: 5.11809\n",
      "Train Accuracy: 16.10068\n",
      "Valid Loss: 6.42628\n",
      "Valid Accuracy: 15.00735\n",
      "early_stopping_best_val: 6.42628\n",
      "early_stopping_step: 0\n",
      "stop_early: False\n",
      "------------------------------------------------------------\n",
      "Epoch 35...\n",
      "Training Iteration...\n",
      "Validation Iteration...\n",
      "Current lr: 1.25e-05\n",
      "Train Loss: 5.11711\n",
      "Train Accuracy: 16.0046\n",
      "Valid Loss: 6.42745\n",
      "Valid Accuracy: 14.61029\n",
      "early_stopping_best_val: 6.42628\n",
      "early_stopping_step: 1\n",
      "stop_early: False\n",
      "------------------------------------------------------------\n",
      "Epoch 36...\n",
      "Training Iteration...\n",
      "Validation Iteration...\n",
      "Current lr: 6.25e-06\n",
      "Train Loss: 5.11241\n",
      "Train Accuracy: 16.08335\n",
      "Valid Loss: 6.44235\n",
      "Valid Accuracy: 14.76471\n",
      "early_stopping_best_val: 6.42628\n",
      "early_stopping_step: 2\n",
      "stop_early: False\n",
      "------------------------------------------------------------\n",
      "Epoch 37...\n",
      "Training Iteration...\n",
      "Validation Iteration...\n",
      "Current lr: 6.25e-06\n",
      "Train Loss: 5.11109\n",
      "Train Accuracy: 16.14006\n",
      "Valid Loss: 6.43319\n",
      "Valid Accuracy: 14.79412\n",
      "early_stopping_best_val: 6.42628\n",
      "early_stopping_step: 3\n",
      "stop_early: False\n",
      "------------------------------------------------------------\n",
      "Epoch 38...\n",
      "Training Iteration...\n",
      "Validation Iteration...\n",
      "Current lr: 3.125e-06\n",
      "Train Loss: 5.10899\n",
      "Train Accuracy: 16.0802\n",
      "Valid Loss: 6.43334\n",
      "Valid Accuracy: 14.99265\n",
      "early_stopping_best_val: 6.42628\n",
      "early_stopping_step: 4\n",
      "stop_early: False\n",
      "------------------------------------------------------------\n",
      "Epoch 39...\n",
      "Training Iteration...\n",
      "Validation Iteration...\n",
      "Current lr: 3.125e-06\n",
      "Train Loss: 5.09848\n",
      "Train Accuracy: 16.26607\n",
      "Valid Loss: 6.43426\n",
      "Valid Accuracy: 15.02206\n",
      "early_stopping_best_val: 6.42628\n",
      "early_stopping_step: 5\n",
      "stop_early: True\n"
     ]
    }
   ],
   "source": [
    "if args.get_model == 'TRAIN':\n",
    "    ##### Get an initialized train_state\n",
    "    train_state = init_train_state(args)\n",
    "    \n",
    "    for epoch_index in range(args.num_epochs):\n",
    "        print('-'*60)\n",
    "        print(f'Epoch {epoch_index}...')\n",
    "        train_state['epoch_index'] = epoch_index\n",
    "\n",
    "        ##################################################\n",
    "        #####     Iterate over training dataset      #####\n",
    "        ##################################################\n",
    "        print('Training Iteration...')\n",
    "\n",
    "        ##### Create a batch_generator using training data\n",
    "        dataset.set_split('train')\n",
    "        batch_generator = generate_batches(dataset,\n",
    "                                           batch_size = args.batch_size,\n",
    "                                           device     = args.device)\n",
    "\n",
    "        ##### running_loss and running_acc are equivalent to the moving averages of loss and accuracy.\n",
    "        ##### when the loop ends, a moving average is just an average. \n",
    "        ##### In each epoch loop, they are reset to zero before the batch loop.\n",
    "        running_loss = 0.0\n",
    "        running_acc  = 0.0\n",
    "\n",
    "        ##### Indicate that the model is in “training mode” \n",
    "        # makes the model parameters mutable \n",
    "        # and enables regularization mechanisms like dropout\n",
    "        classifier.train()\n",
    "\n",
    "        for batch_index, batch_dict in enumerate(batch_generator):\n",
    "            # the training routine is these 5 steps:\n",
    "            # --------------------------------------\n",
    "            ##### STEP 1. zero the gradients\n",
    "            # Inside each batch iteration, the optimizer’s gradients are first reset\n",
    "            # Calling backward (step 4 below) will ACCUMULATE gradients, so if the backward()\n",
    "            # is called earlier, the new gradient is accumulated on top of the one computed \n",
    "            # in previous iterations, which leads to an incorrect value for the gradient.\n",
    "            # Therefore, use this zero_ method to reset the gradients.\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            ##### STEP 2. compute the output\n",
    "            \n",
    "            y_pred = classifier(x_in=batch_dict['x_data'])\n",
    "\n",
    "            ##### STEP 3. compute the loss\n",
    "            loss = loss_func(y_pred, batch_dict['y_target'])\n",
    "            loss_t = loss.item()\n",
    "            # update the moving average of loss, batch by batch\n",
    "            running_loss += (loss_t - running_loss) / (batch_index + 1)\n",
    "            \n",
    "\n",
    "            ##### STEP 4. use loss to produce gradients (gradients are propagated to each parameter)\n",
    "            # Calling backward() and the gradients at each leaf is ACCUMULATED, not stored.\n",
    "            # Note that the loss is the loss in train split. There is no valid_loss.backward()\n",
    "            # because we don't want to train the model on the validation data. \n",
    "            loss.backward()\n",
    "\n",
    "            ##### STEP 5. use optimizer to update parameters\n",
    "            # the optimizer uses the propagated gradients to perform parameter updates\n",
    "            # The value of classifier.parameters(), i.e., params is automatically updated in this step. \n",
    "            # In specific, the optimizer looks into params.grad and updates params, by substracting \n",
    "            # learning_rate * grad from it. \n",
    "            optimizer.step()\n",
    "\n",
    "            ##### Tracking the accuracy\n",
    "            # compute the accuracy\n",
    "            acc_t = compute_accuracy(y_pred, \n",
    "                                     batch_dict['y_target'],\n",
    "                                     args.device)\n",
    "            # update the moving average of acc, batch by batch\n",
    "            running_acc += (acc_t - running_acc) / (batch_index + 1)\n",
    "        ##### After this inner loop (training) ends\n",
    "        # Append the running_loss and running_acc to train_state\n",
    "        # (the average of loss and acc in all the batches in the current epoch)\n",
    "        train_state['train_loss'].append(running_loss)\n",
    "        train_state['train_acc'].append(running_acc)\n",
    "\n",
    "        ##################################################\n",
    "        #####     Iterate over validation dataset    #####\n",
    "        ##################################################\n",
    "        print('Validation Iteration...')\n",
    "\n",
    "        ##### Create a batch_generator using validation data\n",
    "        dataset.set_split('val')    \n",
    "        batch_generator = generate_batches(dataset, \n",
    "                                           batch_size=args.batch_size, \n",
    "                                           device=args.device)\n",
    "        ##### Create new running loss, and running accuracy\n",
    "        running_loss = 0.0\n",
    "        running_acc  = 0.0\n",
    "\n",
    "        ##### Indicate that the model is in “evaluation mode”\n",
    "        # makes the model parameters immutable \n",
    "        # disables dropout\n",
    "        # disables computation of the loss and propagation of gradients back to the parameters\n",
    "        classifier.eval()\n",
    "\n",
    "        for batch_index, batch_dict in enumerate(batch_generator):\n",
    "            ##### compute the output\n",
    "            y_pred = classifier(x_in=batch_dict['x_data'])\n",
    "\n",
    "            ##### STEP 3. compute the loss\n",
    "            loss = loss_func(y_pred, batch_dict['y_target'])\n",
    "            loss_t = loss.item()\n",
    "            running_loss += (loss_t - running_loss) / (batch_index + 1)\n",
    "\n",
    "            ##### compute the accuracy\n",
    "            acc_t = compute_accuracy(y_pred, \n",
    "                                     batch_dict['y_target'],\n",
    "                                     args.device)\n",
    "            running_acc += (acc_t - running_acc) / (batch_index + 1)\n",
    "\n",
    "        ##### After this inner loop (validation) ends\n",
    "        # Append the running_loss and running_acc to train_state\n",
    "        # (the average of loss and acc in all the batches in the current epoch)\n",
    "        train_state['val_loss'].append(running_loss)\n",
    "        train_state['val_acc'].append(running_acc)\n",
    "\n",
    "        ##### Update the status of Early Stopping and Model Checkpoint\n",
    "        # Input: the current classifier and current train_state (end of the current epoch loop)\n",
    "        # Update three items in train_state\n",
    "        # 1.\"early_stopping_step\" +=1 or reset to 0 (comparing val_loss and early_stopping_best_val)\n",
    "        # 2.\"early_stopping_best_val\" update to the current val_loss if it is the best model\n",
    "        # 3.\"stop_early\" if early_stopping_step reaches early_stopping_criteria. If True, break all loops below. \n",
    "        # Save a new model if the current model has early_stopping_best_val\n",
    "        train_state = update_train_state(args = args, model = classifier,\n",
    "                                         train_state = train_state)\n",
    "        \n",
    "        scheduler.step(train_state['val_loss'][-1])\n",
    "        print('Current lr:', optimizer.param_groups[0]['lr'])\n",
    "\n",
    "        print_train_state(train_state)\n",
    "\n",
    "        if train_state['stop_early']:\n",
    "            break\n",
    "\n",
    "elif args.get_model == 'LOAD':\n",
    "    classifier.load_state_dict(torch.load(train_state['model_filename']))\n",
    "    classifier = classifier.to(args.device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bb28397",
   "metadata": {},
   "source": [
    "# @@@@@ 4. Evaluation\n",
    "## 4.1 - Evaluation on Test Data\n",
    "### There are a few reasons why the result is not super high. \n",
    "### 1) In this illustrative example, there are many properties of the original implementation that have been left out because they add complexity unnecessary for learning (but necessary for optimal performance). \n",
    "### 2) The dataset we are using is minuscule. In contrast, state-of-the-art embeddings are typically trained on datasets with terabytes of text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ce843b9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 7.63775\n",
      "Test Accuracy: 13.57353\n"
     ]
    }
   ],
   "source": [
    "classifier = CBOWClassifier(vocabulary_size = len(vectorizer.cbow_vocab), \n",
    "                            embedding_size  = args.embedding_size, \n",
    "                            padding_idx     = 0)\n",
    "\n",
    "filename   = args.output_path+'/frankenstein_model.pth'\n",
    "classifier.load_state_dict(torch.load(filename))\n",
    "classifier = classifier.to(args.device)\n",
    "\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "\n",
    "##### Create a batch_generator using test data\n",
    "# The test set should be run as little as possible\n",
    "# Avoid make a new model decision based on the evaluation on test data\n",
    "# Otherwise the model might be biased toward the test data, and the test data will \n",
    "# become meaningless as an measure of truly held-out data.\n",
    "dataset.set_split('test')\n",
    "batch_generator = generate_batches(dataset, \n",
    "                                   batch_size = args.batch_size, \n",
    "                                   device     = args.device)\n",
    "\n",
    "##### Create new running loss, and running accuracy\n",
    "running_loss = 0.0\n",
    "running_acc  = 0.0\n",
    "\n",
    "##### Indicate that the model is in “evaluation mode”\n",
    "classifier.eval()\n",
    "\n",
    "for batch_index, batch_dict in enumerate(batch_generator):\n",
    "    # compute the output\n",
    "    y_pred = classifier(batch_dict['x_data'])\n",
    "\n",
    "    # compute the loss\n",
    "    loss   = loss_func(y_pred, batch_dict['y_target'])\n",
    "    loss_t = loss.item()\n",
    "    running_loss += (loss_t - running_loss) / (batch_index + 1)\n",
    "\n",
    "    # compute the accuracy\n",
    "    acc_t = compute_accuracy(y_pred, batch_dict['y_target'],args.device)\n",
    "    running_acc += (acc_t - running_acc) / (batch_index + 1)\n",
    "\n",
    "print(\"Test loss: {:.5f}\".format(running_loss))\n",
    "print(\"Test Accuracy: {:.5f}\".format(running_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a80d6d29",
   "metadata": {},
   "source": [
    "## 4.2 Generation a prediction for a given context (predicting the fourth word in a sentence containing seven words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8aa5843e",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = CBOWClassifier(vocabulary_size = len(vectorizer.cbow_vocab), \n",
    "                            embedding_size  = args.embedding_size, \n",
    "                            padding_idx     = 0)\n",
    "\n",
    "filename   = args.output_path+'/frankenstein_model.pth'\n",
    "classifier.load_state_dict(torch.load(filename))\n",
    "classifier = classifier.to(args.device)\n",
    "vectorizer = dataset.get_vectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ad7894b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = [\n",
    "    'the sun shines in the blue sky',\n",
    "    'rivers flow quietly through green valleys',\n",
    "    'children play and laugh in the park'\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "412ec32d",
   "metadata": {},
   "source": [
    "### Neural network models expect input tensors to have specific shapes. Typically, the input tensor to this model is a batch of data, containing multiple samples. When pass a single sample to the model, one needs to first wrap it in a batch of size 1.\n",
    "### Two approaches:\n",
    "### 1) The [.unsqueeze(dim=0) ](https://pytorch.org/docs/stable/generated/torch.unsqueeze.html)method adds a dimension at the specified dimension, effectively converting the original tensor into a batch of size 1. In this case, we're converting the tensor of a single sample into a batch tensor containing that single sample.\n",
    "### 2) The [.view(1, -1)](https://pytorch.org/docs/stable/generated/torch.Tensor.view.html) method reshape the original tensor into a batch tensor of size 1, where the first dimension is 1, and the other dimensions are automatically calculated based on the total number of elements in the original tensor. This allows you to pass a single sample to the model for prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "eeccf061",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Context: the sun shines the blue sky\n",
      "Target: in\n",
      "Output:\n",
      "tensor([[-13.7323, -13.6765,   2.9148,  ...,  -6.7064,  -7.4687, -13.7307]],\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Top 10 predicted words:\n",
      "['of', 'morning', 'which', 'i', 'had', ',', 'in', 'have', 'same', 'and']\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Context: rivers flow quietly green valleys\n",
      "Target: through\n",
      "Output:\n",
      "tensor([[-1.9722, -1.9154,  0.9696,  ...,  1.7022,  1.4645, -1.9709]],\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Top 10 predicted words:\n",
      "[nan, 'having', 'arrange', 'doting', 'tended', 'letting', 'cheering', 'era', 'merchants', 'thrush']\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Context: children play and in the park\n",
      "Target: laugh\n",
      "Output:\n",
      "tensor([[-10.6944, -10.6373,   2.3762,  ...,  -4.2826,  -3.6769, -10.6914]],\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Top 10 predicted words:\n",
      "['of', ',', 'to', 'the', 'natural', 'my', 'cottage', 'a', 'his', 'and']\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for sentence in sentences:\n",
    "    words   = sentence.split()\n",
    "    target  = words[3]\n",
    "    del words[3]\n",
    "    context = ' '.join(words)\n",
    "    print(\"Context:\", context)\n",
    "    print(\"Target:\", target)\n",
    "    print(\"Output:\")\n",
    "    ### Because the classifier includes a dropout layer with a p=0.3),\n",
    "    ### the output contains random variations.\n",
    "    output = classifier(torch.tensor(vectorizer.vectorize(context)).unsqueeze(dim=0))\n",
    "    ### Alternatively\n",
    "    # output = classifier(torch.tensor(vectorizer.vectorize(context)).view(1, -1))\n",
    "    print(output)\n",
    "    \n",
    "    n_top = 10\n",
    "    top_values, top_indices = torch.topk(output, k=n_top)\n",
    "    top_indices = top_indices.squeeze(0).numpy()\n",
    "    \n",
    "    top_pred_words = []\n",
    "    for i in top_indices:\n",
    "        top_pred_words += [dataset._vectorizer.cbow_vocab.lookup_index(i)]\n",
    "    print(f\"Top {n_top} predicted words:\")\n",
    "    print(top_pred_words)\n",
    "    print(\"-\"*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94617f11",
   "metadata": {},
   "source": [
    "## 4.3 Trained Embeddings\n",
    "### The analysis below find the nearest n words in the vocabulary (dataset._vectorizer.cbow_vocab) to the given word, where the distance between words is based on the [2-norm](https://pytorch.org/docs/stable/generated/torch.dist.html).\n",
    "\n",
    "### Like mentioned above, this is a simplified model and the training data is very limited. Therefore, the embedding obtained in this classifier is not a very good vector representation. A similar analysis ([see ipynb here](https://github.com/houzhj/Machine_Learning/blob/main/ipynb/Frankenstein/pretrained_embeddings_GloVe.ipynb)) was conducted using pre-trained embeddings (GloVe by Stanford)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6a706179",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = CBOWClassifier(vocabulary_size = len(vectorizer.cbow_vocab), \n",
    "                            embedding_size  = args.embedding_size, \n",
    "                            padding_idx     = 0)\n",
    "\n",
    "filename   = args.output_path+'/frankenstein_model.pth'\n",
    "classifier.load_state_dict(torch.load(filename))\n",
    "classifier = classifier.to(args.device)\n",
    "embeddings = classifier.embedding.weight.data\n",
    "\n",
    "vectorizer = dataset.get_vectorizer()\n",
    "word_to_idx = vectorizer.cbow_vocab._token_to_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a9c62357",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_closest(input_word, word_to_idx, embeddings, n=5):\n",
    "    \"\"\"\n",
    "    Get the n closest\n",
    "    words to your word.\n",
    "    \"\"\"\n",
    "\n",
    "    # Calculate distances (2-norm) to all other words\n",
    "    # \n",
    "    word_embedding = embeddings[word_to_idx[input_word.lower()]]\n",
    "    distances = []\n",
    "    for word, index in word_to_idx.items():\n",
    "        if word == \"<MASK>\" or word == input_word:\n",
    "            continue\n",
    "        distances.append((word, torch.dist(word_embedding, embeddings[index])))\n",
    "    \n",
    "    # Sorting the list using the sorted() function with a lambda function which\n",
    "    # specifies through the key parameter. The lambda function returns the second \n",
    "    # element of each tuple (2-norm value) as the sorting criterion.\n",
    "    results = sorted(distances, key=lambda x: x[1])[0:n+1]\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a875f306",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('picturesque', tensor(6.6047)),\n",
       " ('sentences', tensor(6.6982)),\n",
       " ('loathsome', tensor(6.8005)),\n",
       " ('walking', tensor(6.9838)),\n",
       " ('fatal', tensor(7.0117)),\n",
       " ('consoled', tensor(7.1081))]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_closest('monster', word_to_idx, embeddings, n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1b244321",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('imaginations', tensor(5.7929)),\n",
       " ('moonshine', tensor(6.1915)),\n",
       " ('wreck', tensor(6.2560)),\n",
       " ('caresses', tensor(6.3671)),\n",
       " ('conjectured', tensor(6.3714)),\n",
       " ('earth', tensor(6.4475))]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_closest('frankenstein', word_to_idx, embeddings, n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "db884785",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('removed', tensor(6.1792)),\n",
       " ('wail', tensor(6.2022)),\n",
       " ('returned', tensor(6.2720)),\n",
       " ('firmest', tensor(6.4226)),\n",
       " ('latter', tensor(6.4275)),\n",
       " ('fortifications', tensor(6.4317))]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_closest('happy', word_to_idx, embeddings, n=5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
